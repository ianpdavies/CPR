v1 = First try - standard NN, flood target feature includes permanent water (clouds = original)
v2 = Removed permanent water from flood target feature in all steps (clouds = original)
v3 = Used batch normalization, higher batch size, and cyclic scheduled learning rate (clouds = original)
v4 = Batch size testing - 256 (clouds = original)
v5 = Batch size testing - 512 (clouds = original)
v6 = Batch size testing - 1024 (clouds = original)
v7 = Batch size testing - 4096 (clouds = original)
v8 = Batch size testing - 8192 (clouds = original)
v9 = Batch size testing - 16385, but also using two layers in NN (v1-v8 accidentally only had one) (clouds = original)
v10 = Batch size testing - 16385, but with three layer NN (clouds = original)
v11 = Testing on all images using 2 layer NN, batch size = 4096 (clouds = original)
v12 = Testing on all images using 2 layer NN, batch size = 16385 (clouds = original)
v13 = Test on all images 5 random cloudmasks, to see if low performance is just randomness. Trial 1 (clouds = trial1)
v14 = Test on all images with 5 random cloudmasks, to see if low performance is just randomness. Trial 2 (clouds = trial2)

V15 AND ONWARDS: Bug where training data wasn't masked by clouds
THESE ARE ALL INVALID
v15 = Test on all images with 5 random cloudmasks, to see if low performance is just randomness. Trial 3
v16 = Test on all images with 5 random cloudmasks, to see if low performance is just randomness. Trial 4
v17 = Test on all images with 5 random cloudmasks, to see if low performance is just randomness. Trial 5
v18 = Testing on all images using 2 layer NN with smaller, thinner clouds.
v19 = Testing on all images using 2 layer NN with no validation data. Batch = 8192 (clouds = original?)
I actually think v19 may have been trained using small clouds ... not sure though because the metrics are very similar to v20 tested on original clouds
v20 = Testing on all images, 2 layer NN, with MCD uncertainty during prediction

REDONE
v21 = Testing on half of images at 40% cover WITH validation data + MCD dropout
v22 = Testing on half of images at 40% cover WITHOUT validation data + MCD dropout
v13-17 = random cloud trials at 10, 30, 50, 70, 90% cloud cover.

Then need a full run without MCD. Maybe just at odd% cloud covers to save time/space.

v23 = Testing on all images at 40% cover WITH validation data. No MCD.
v24 = Testing on all images at 40% cover WITHOUT validation data. No MCD.