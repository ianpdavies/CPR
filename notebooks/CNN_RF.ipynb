{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing CNN and RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than training RF on 30k sample points, this time I'm going to train it on the entire image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pickle\n",
    "import ee\n",
    "import os\n",
    "import rasterio\n",
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "path_clear = 'C:/Users/ipdavies/CPR/data/images/clear_4337_LC08_026038_20160325'\n",
    "path_clouds = 'C:/Users/ipdavies/CPR/data/images/clouds_4337_LC08_026038_20160325'\n",
    "model_path = 'C:/Users/ipdavies/CPR/data/models/'\n",
    "\n",
    "# Misc functions\n",
    "import time\n",
    "def timer(start,end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\rasterio\\__init__.py:160: FutureWarning: GDAL-style transforms are deprecated and will not be supported in Rasterio 1.0.\n",
      "  transform = guard_transform(transform)\n"
     ]
    }
   ],
   "source": [
    "# Stack exported tifs from GEE into one multiband tif\n",
    "\n",
    "def listdir_fullpath(d):\n",
    "    return [os.path.join(d, f) for f in os.listdir(d)]\n",
    "\n",
    "file_list = []\n",
    "for file in listdir_fullpath(path_clear):\n",
    "    if file.endswith('.tif'):\n",
    "        file_list.append(file)\n",
    "\n",
    "feat_list_files = list(map(lambda x: x.split('.')[-2], file_list)) # list of features in file order\n",
    "\n",
    "\n",
    "#=========== Want to rearrange the order of files so that target feature is last\n",
    "\n",
    "# Create list of features with target feature (flooded) last\n",
    "feat_list_new = ['aspect','curve', 'developed', 'distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "# Create 1 row df of file names where each col is a feature name, in the order files are stored locally\n",
    "file_arr = pd.DataFrame(data=[file_list], columns=feat_list_files)\n",
    "\n",
    "# Then index the file list by the ordered list of feature names used in training\n",
    "file_arr = file_arr.loc[:, feat_list_new]\n",
    "\n",
    "# The take this re-ordered row as a list - the new file_list\n",
    "file_list = list(file_arr.iloc[0,:])\n",
    "    \n",
    "# Read metadata of first file. This needs to be a band in float32 dtype, because it sets the metadata for the entire stack\n",
    "# and we are converting the other bands to float64\n",
    "with rasterio.open(file_list[1]) as src0:\n",
    "    meta = src0.meta\n",
    "    meta['dtype'] = 'float32'\n",
    "#         print(meta)\n",
    "\n",
    "# Update meta to reflect the number of layers\n",
    "meta.update(count = len(file_list))\n",
    "\n",
    "# Read each layer, convert to float, and write it to stack\n",
    "# There's also a gdal way to do this, but unsure how to convert to float: https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\n",
    "\n",
    "# Make new directory for stacked tif if it doesn't already exist\n",
    "try:\n",
    "    os.mkdir(path_clear+'/stack')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# Remove stack file if already exists\n",
    "try:\n",
    "    os.remove(path_clear + '/stack/stack.tif')\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "with rasterio.open(path_clear + '/stack/stack.tif', 'w', **meta) as dst:\n",
    "    for id, layer in enumerate(file_list, start=0):\n",
    "        with rasterio.open(layer) as src1:\n",
    "            dst.write_band(id+1, src1.read(1).astype('float32'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14000674"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess the array\n",
    "\n",
    "# Get local image\n",
    "with rasterio.open(path_clear + '/stack/stack.tif', 'r') as ds:\n",
    "    data = ds.read()\n",
    "    data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "\n",
    "# Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "\n",
    "# Convert -999999 to None\n",
    "data[data == -999999] = np.nan\n",
    "\n",
    "# Get indices of non-nan values. These are the indices of the original image array\n",
    "# data_ind = np.where(data[:,:,1] != None)\n",
    "data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "row, col = zip(np.where(~np.isnan(data[:,:,1]))) # image row and col of values\n",
    "len(*row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOLDOUT_FRACTION = 0.1\n",
    "\n",
    "# Reshape into a single vector of pixels.\n",
    "data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "# Remove NaNs\n",
    "data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "data_vector.shape\n",
    "\n",
    "# Shuffle data\n",
    "np.random.shuffle(data_vector)\n",
    "\n",
    "# Compute per-band means and standard deviations of the input bands.\n",
    "data_mean = training_data[:,0:14].mean(0)\n",
    "data_std = training_data[:,0:14].std(0)\n",
    "\n",
    "# Hold out a fraction of the labeled data for validation.\n",
    "training_size = int(data_vector.shape[0] * (1 - HOLDOUT_FRACTION))\n",
    "training_data = data_vector[0:training_size,:]\n",
    "validation_data = data_vector[training_size:-1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RF2'\n",
    "\n",
    "# Normalize data\n",
    "training_data[:,0:14] = (training_data[:,0:14] - data_mean) / data_std\n",
    "validation_data[:,0:14] = (validation_data[:,0:14] - data_mean) / data_std\n",
    "\n",
    "# Split into target and features\n",
    "X_train = training_data[:,0:14]\n",
    "y_train = training_data[:,14]\n",
    "X_test = validation_data[:,0:14]\n",
    "y_test = validation_data[:,14]\n",
    "\n",
    "# Hyperparameters optimized for the 30k sample (using a random search)\n",
    "best_n_estimators = 800\n",
    "best_min_samples_split = 10\n",
    "best_min_samples_leaf = 2\n",
    "best_max_features = 'sqrt'\n",
    "best_max_depth = 20\n",
    "best_bootstrap = False\n",
    "\n",
    "# Instantiate model with best parameters from random search\n",
    "clf = RandomForestClassifier(n_estimators = best_n_estimators, \n",
    "                             max_depth = best_max_depth,\n",
    "                             max_features = best_max_features,\n",
    "                             min_samples_split = best_min_samples_split,\n",
    "                             min_samples_leaf = best_min_samples_leaf,\n",
    "                             bootstrap = best_bootstrap,\n",
    "                             random_state=0)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the RF model to data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('RF training time: ' + timer(start_time, time.time()))\n",
    "\n",
    "# Save model\n",
    "pickle.dump(clf, open(model_path+model_name+'.sav', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
