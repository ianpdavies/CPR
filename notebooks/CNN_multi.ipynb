{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the performance of CNNs on different flood images, cloud cover %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "from IPython import display\n",
    "# import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# from osgeo import gdal\n",
    "# import tempfile\n",
    "import tensorflow as tf\n",
    "# import urllib\n",
    "import rasterio\n",
    "from zipfile import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_clear = 'C:/Users/ipdavies/CPR/data/images/clear_4337_LC08_026038_20160325'\n",
    "# path_clouds = 'C:/Users/ipdavies/CPR/data/images/clouds_4337_LC08_026038_20160325'\n",
    "# model_name = 'cnn2'\n",
    "# model_path = 'C:/Users/ipdavies/CPR/data/models/'+model_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/ipdavies/CPR/data/images/4337_LC08_026038_20160325_1/4337_LC08_026038_20160325_1.zip'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN on an image with 10-90% cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4101_LC08_027038_20131103', '4101_LC08_027038_20131103_2', '4101_LC08_027039_20131103', '4115_LC08_021033_20131227_1', '4115_LC08_021033_20131227_2', '4337_LC08_026038_20160325_1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "\n",
    "# Get list of all images\n",
    "img_list = []\n",
    "for file in os.listdir(path):\n",
    "        img_list.append(file)\n",
    "\n",
    "print(img_list)\n",
    "\n",
    "img = '4337_LC08_026038_20160325_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorders the tifs (i.e. individual bands) downloaded from GEE according to feature order in feat_list_new,\n",
    "# then stacks them all into one multiband image called 'stack.tif' located in input path\n",
    "# Reqs: rasterio, os, from zipfile import *\n",
    "# Ideally want to have this function in another notebook and call it, but running into problems - ZipFile not found\n",
    "# from ipynb.fs.full.useful_funcs import tifStacker\n",
    "\n",
    "def tifStacker(path, img, feat_list_new): \n",
    "\n",
    "    file_list = []\n",
    "    path = path+'images/'+img\n",
    "    \n",
    "    # This gets the name of all files in the zip folder, and formats them into a full path readable by rasterio.open()\n",
    "    with ZipFile(path + '/' + img + '.zip', 'r') as f:\n",
    "        names = f.namelist()\n",
    "        names = ['zip://'+ path + '/ + img + '.zip!' +name for name in names]\n",
    "        for file in names:\n",
    "            if file.endswith('.tif'):\n",
    "                file_list.append(file)\n",
    "    \n",
    "    feat_list_files = list(map(lambda x: x.split('.')[-2], file_list)) # Grabs a list of features in file order        \n",
    "    \n",
    "    # Create 1 row df of file names where each col is a feature name, in the order files are stored locally\n",
    "    file_arr = pd.DataFrame(data=[file_list], columns=feat_list_files)\n",
    "\n",
    "    # Then index the file list by the ordered list of feature names used in training\n",
    "    file_arr = file_arr.loc[:, feat_list_new]\n",
    "\n",
    "    # The take this re-ordered row as a list - the new file_list\n",
    "    file_list = list(file_arr.iloc[0,:])\n",
    "    \n",
    "    # Read metadata of first file. This needs to be a band in float32 dtype, because it sets the metadata for the entire stack\n",
    "    # and we are converting the other bands to float64\n",
    "    with rasterio.open(file_list[1]) as src0:\n",
    "        meta = src0.meta\n",
    "        meta['dtype'] = 'float32'\n",
    "    #         print(meta)\n",
    "\n",
    "    # Update meta to reflect the number of layers\n",
    "    meta.update(count = len(file_list))\n",
    "\n",
    "    # Read each layer, convert to float, and write it to stack\n",
    "    # There's also a gdal way to do this, but unsure how to convert to float: https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\n",
    "\n",
    "    # Make new directory for stacked tif if it doesn't already exist\n",
    "    try:\n",
    "        os.mkdir(path +'/stack')\n",
    "    except FileExistsError:\n",
    "        print('Stack directory already exists')\n",
    "\n",
    "    # Remove stack file if already exists\n",
    "    try:\n",
    "        os.remove(path + '/stack/stack.tif')\n",
    "        print('Removing existing \"stack.tif\" and creating new one')\n",
    "    except FileNotFoundError:\n",
    "    #     pass\n",
    "        print('Creating \"stack.tif\"')\n",
    "\n",
    "    with rasterio.open(path + '/stack/stack.tif', 'w', **meta) as dst:\n",
    "        for id, layer in enumerate(file_list, start=0):\n",
    "            with rasterio.open(layer) as src1:\n",
    "                dst.write_band(id+1, src1.read(1).astype('float32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the stacked image and masks it 9 times for cloud cover 10-90%, resulting in 9 arrays and 9 tuples of row, col indices of the array cells with non-nan values. It might take too much memory to have all 9 arrays loaded though ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path, img, pctl):\n",
    "\n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'cloudmasks/'+img\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds_'+str(pctl)+'.npy')\n",
    "    \n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "        \n",
    "    return data, data_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVal(data):\n",
    "    \n",
    "    HOLDOUT_FRACTION = 0.1\n",
    "\n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "    data_vector.shape\n",
    "\n",
    "    # Select only the valid data and shuffle it.\n",
    "    # valid_data = data_vector[numpy.equal(data_vector[:,8], 1)]\n",
    "    # np.random.shuffle(data_vector)\n",
    "\n",
    "    # Hold out a fraction of the labeled data for validation.\n",
    "    training_size = int(data_vector.shape[0] * (1 - HOLDOUT_FRACTION))\n",
    "    training_data = data_vector[0:training_size,:]\n",
    "    validation_data = data_vector[training_size:-1,:]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = training_data[:,0:14].mean(0)\n",
    "    data_std = training_data[:,0:14].std(0)\n",
    "    \n",
    "    return [data_vector, training_data, validation_data, data_mean, data_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train CNN on image, save model, and return performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN layer builder\n",
    "def make_nn_layer(input, output_size):\n",
    "    input_size = input.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal(\n",
    "        [input_size, output_size],\n",
    "        stddev=1.0 / math.sqrt(float(input_size))))\n",
    "    biases = tf.Variable(tf.zeros([output_size]))\n",
    "    return tf.matmul(input, weights) + biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNtrainer(data_vector, training_data, validation_data, data_mean, data_std, model_path, img, pctl):\n",
    "\n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    \n",
    "    \n",
    "    # These are all hyperparameters that might need to be tuned later\n",
    "    NUM_INPUT_BANDS = 14\n",
    "    NUM_HIDDEN_1 = 15\n",
    "    NUM_HIDDEN_2 = 15\n",
    "    NUM_CLASSES = 2\n",
    "\n",
    "    input = tf.placeholder(tf.float32, shape=[None, NUM_INPUT_BANDS])\n",
    "    labels = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "    normalized = (input - data_mean) / data_std\n",
    "    hidden1 = tf.nn.tanh(make_nn_layer(normalized, NUM_HIDDEN_1))\n",
    "    hidden2 = tf.nn.tanh(make_nn_layer(hidden1, NUM_HIDDEN_2))\n",
    "    logits = make_nn_layer(hidden2, NUM_CLASSES)\n",
    "    outputs = tf.argmax(logits, 1)\n",
    "\n",
    "    int_labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = int_labels, name='xentropy')\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy) # should we minimize something else?\n",
    "\n",
    "    correct_prediction = tf.equal(outputs, int_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # Want to add recall/precision to this but can do that later\n",
    "    # https://stackoverflow.com/questions/46409626/how-to-properly-use-tf-metrics-accuracy\n",
    "\n",
    "    import time\n",
    "    def timer(start,end):\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    # run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "    # import logging\n",
    "    # tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    flooded = feat_list_files.index('flooded')\n",
    "    BATCH_SIZE = 1000\n",
    "    NUM_BATCHES = 1000\n",
    "    mySaver = tf.train.Saver()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer(), options=run_options)\n",
    "\n",
    "        training_dict = {\n",
    "            input: training_data[:,0:14],\n",
    "            labels: training_data[:,14],\n",
    "        }\n",
    "\n",
    "        validation_dict = {\n",
    "            input: validation_data[:,0:14],\n",
    "            labels: validation_data[:,14],\n",
    "        }\n",
    "\n",
    "        for i in range(NUM_BATCHES):\n",
    "            batch = training_data[np.random.choice(training_size, BATCH_SIZE, False),:]\n",
    "            train_step.run({input: batch[:,0:14], labels: batch[:,14]})\n",
    "\n",
    "            if i % 100 == 0 or i == NUM_BATCHES - 1:\n",
    "    #             print('Train acc. %.2f%%, val acc. %.2f%%, train recall %.2f%, val recall %.2f%, train precision %.2f%, val precision %.2f%, at step %d' \n",
    "                print('Train acc. %.2f%%, val acc. %.2f%%, at step %d' \n",
    "                      % (accuracy.eval(training_dict) * 100,\n",
    "                         accuracy.eval(validation_dict) * 100, \n",
    "                         i))\n",
    "                \n",
    "        output_data = outputs.eval({input: data_vector[:,0:14]})\n",
    "\n",
    "        # Save the model\n",
    "        mySaver.save(sess, model_path+model_name+'.ckpt', global_step = NUM_BATCHES)\n",
    "\n",
    "    print('CNN training runtime for ' + str(pctl) + '% cloud cover: ' + timer(start_time, time.time()))\n",
    "    \n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    precision = sk.metrics.precision_score(y_true, y_pred)\n",
    "    recall = sk.metrics.recall_score(y_true, y_pred)\n",
    "    f1 = sk.metrics.f1_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to do all the functions together\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "feat_list_new = ['aspect','curve', 'developed', 'distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "#  Stack all the flood imagery\n",
    "tifStacker(path, img, feat_list_new)\n",
    "\n",
    "# Load stacked image, preprocess\n",
    "for i, pctl in enumerate(pctls):\n",
    "    \n",
    "    data, data_ind = preprocessing(path, img, pctl)\n",
    "    \n",
    "    data_vector, training_data, validation_data, data_mean, data_std = trainVal(data)\n",
    "    \n",
    "    y_pred = CNNtrainer(data_vector, training_data, validation_data, data_mean, data_std, model_path, img, pctl)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
