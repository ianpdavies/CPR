{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the performance of CNNs on different flood images, cloud cover %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "from IPython import display\n",
    "# import math\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# from osgeo import gdal\n",
    "# import tempfile\n",
    "import tensorflow as tf\n",
    "# import urllib\n",
    "import rasterio\n",
    "from zipfile import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_clear = 'C:/Users/ipdavies/CPR/data/images/clear_4337_LC08_026038_20160325'\n",
    "# path_clouds = 'C:/Users/ipdavies/CPR/data/images/clouds_4337_LC08_026038_20160325'\n",
    "# model_name = 'cnn2'\n",
    "# model_path = 'C:/Users/ipdavies/CPR/data/models/'+model_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'C:/Users/ipdavies/CPR/data/images/4337_LC08_026038_20160325_1/4337_LC08_026038_20160325_1.zip'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the CNN on an image with 10-90% cloud cover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4101_LC08_027038_20131103', '4101_LC08_027038_20131103_2', '4101_LC08_027039_20131103', '4115_LC08_021033_20131227_1', '4115_LC08_021033_20131227_2', '4337_LC08_026038_20160325_1']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "\n",
    "# Get list of all images\n",
    "img_list = []\n",
    "for file in os.listdir(path):\n",
    "        img_list.append(file)\n",
    "\n",
    "print(img_list)\n",
    "\n",
    "img = '4337_LC08_026038_20160325_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorders the tifs (i.e. individual bands) downloaded from GEE according to feature order in feat_list_new,\n",
    "# then stacks them all into one multiband image called 'stack.tif' located in input path\n",
    "# Reqs: rasterio, os, from zipfile import *\n",
    "# Ideally want to have this function in another notebook and call it, but running into problems - ZipFile not found\n",
    "# from ipynb.fs.full.useful_funcs import tifStacker\n",
    "\n",
    "def tifStacker(path, img, feat_list_new): \n",
    "\n",
    "    file_list = []\n",
    "    path = path+'images/'+img\n",
    "    \n",
    "    # This gets the name of all files in the zip folder, and formats them into a full path readable by rasterio.open()\n",
    "    with ZipFile(path + '/' + img + '.zip', 'r') as f:\n",
    "        names = f.namelist()\n",
    "        names = ['zip://'+ path + '/' + img + '.zip!' +name for name in names]\n",
    "        for file in names:\n",
    "            if file.endswith('.tif'):\n",
    "                file_list.append(file)\n",
    "    \n",
    "    feat_list_files = list(map(lambda x: x.split('.')[-2], file_list)) # Grabs a list of features in file order        \n",
    "    \n",
    "    # Create 1 row df of file names where each col is a feature name, in the order files are stored locally\n",
    "    file_arr = pd.DataFrame(data=[file_list], columns=feat_list_files)\n",
    "\n",
    "    # Then index the file list by the ordered list of feature names used in training\n",
    "    file_arr = file_arr.loc[:, feat_list_new]\n",
    "\n",
    "    # The take this re-ordered row as a list - the new file_list\n",
    "    file_list = list(file_arr.iloc[0,:])\n",
    "    \n",
    "    # Read metadata of first file. This needs to be a band in float32 dtype, because it sets the metadata for the entire stack\n",
    "    # and we are converting the other bands to float64\n",
    "    with rasterio.open(file_list[1]) as src0:\n",
    "        meta = src0.meta\n",
    "        meta['dtype'] = 'float32'\n",
    "    #         print(meta)\n",
    "\n",
    "    # Update meta to reflect the number of layers\n",
    "    meta.update(count = len(file_list))\n",
    "\n",
    "    # Read each layer, convert to float, and write it to stack\n",
    "    # There's also a gdal way to do this, but unsure how to convert to float: https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\n",
    "\n",
    "    # Make new directory for stacked tif if it doesn't already exist\n",
    "    try:\n",
    "        os.mkdir(path +'/stack')\n",
    "    except FileExistsError:\n",
    "        print('Stack directory already exists')\n",
    "\n",
    "    # Remove stack file if already exists\n",
    "    try:\n",
    "        os.remove(path + '/stack/stack.tif')\n",
    "        print('Removing existing \"stack.tif\" and creating new one')\n",
    "    except FileNotFoundError:\n",
    "    #     pass\n",
    "        print('Creating \"stack.tif\"')\n",
    "\n",
    "    with rasterio.open(path + '/stack/stack.tif', 'w', **meta) as dst:\n",
    "        for id, layer in enumerate(file_list, start=0):\n",
    "            with rasterio.open(layer) as src1:\n",
    "                dst.write_band(id+1, src1.read(1).astype('float32'))\n",
    "    \n",
    "    return feat_list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads the stacked image and masks it 9 times for cloud cover 10-90%, resulting in 9 arrays and 9 tuples of row, col indices of the array cells with non-nan values. It might take too much memory to have all 9 arrays loaded though ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(path, img, pctl):\n",
    "\n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'cloudmasks/'+img\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds_'+str(pctl)+'.npy')\n",
    "    \n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "        \n",
    "    return data, data_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVal(data):\n",
    "    \n",
    "    HOLDOUT_FRACTION = 0.1\n",
    "\n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "    data_vector.shape\n",
    "\n",
    "    # Select only the valid data and shuffle it.\n",
    "    # valid_data = data_vector[numpy.equal(data_vector[:,8], 1)]\n",
    "    # np.random.shuffle(data_vector)\n",
    "\n",
    "    # Hold out a fraction of the labeled data for validation.\n",
    "    training_size = int(data_vector.shape[0] * (1 - HOLDOUT_FRACTION))\n",
    "    training_data = data_vector[0:training_size,:]\n",
    "    validation_data = data_vector[training_size:-1,:]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = training_data[:,0:14].mean(0)\n",
    "    data_std = training_data[:,0:14].std(0)\n",
    "    \n",
    "    return [data_vector, training_data, validation_data, data_mean, data_std, training_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train CNN on image, save model, and return performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN layer builder\n",
    "def make_nn_layer(input, output_size):\n",
    "    input_size = input.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal(\n",
    "        [input_size, output_size],\n",
    "        stddev=1.0 / math.sqrt(float(input_size))))\n",
    "    biases = tf.Variable(tf.zeros([output_size]))\n",
    "    return tf.matmul(input, weights) + biases\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNNtrainer(data_vector, training_data, validation_data, data_mean, data_std, model_path, img, pctl):\n",
    "\n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    \n",
    "    \n",
    "    # These are all hyperparameters that might need to be tuned later\n",
    "    NUM_INPUT_BANDS = 14\n",
    "    NUM_HIDDEN_1 = 15\n",
    "    NUM_HIDDEN_2 = 15\n",
    "    NUM_CLASSES = 2\n",
    "\n",
    "    input = tf.placeholder(tf.float32, shape=[None, NUM_INPUT_BANDS])\n",
    "    labels = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "    normalized = (input - data_mean) / data_std\n",
    "    hidden1 = tf.nn.tanh(make_nn_layer(normalized, NUM_HIDDEN_1))\n",
    "    hidden2 = tf.nn.tanh(make_nn_layer(hidden1, NUM_HIDDEN_2))\n",
    "    logits = make_nn_layer(hidden2, NUM_CLASSES)\n",
    "    outputs = tf.argmax(logits, 1)\n",
    "\n",
    "    int_labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = int_labels, name='xentropy')\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy) # should we minimize something else?\n",
    "\n",
    "    correct_prediction = tf.equal(outputs, int_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    # Want to add recall/precision to this but can do that later\n",
    "    # https://stackoverflow.com/questions/46409626/how-to-properly-use-tf-metrics-accuracy\n",
    "\n",
    "    import time\n",
    "    def timer(start,end):\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    # run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "    # import logging\n",
    "    # tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "    flooded = feat_list_files.index('flooded')\n",
    "    BATCH_SIZE = 1000\n",
    "    NUM_BATCHES = 1000\n",
    "    mySaver = tf.train.Saver()\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer(), options=run_options)\n",
    "\n",
    "        training_dict = {\n",
    "            input: training_data[:,0:14],\n",
    "            labels: training_data[:,14],\n",
    "        }\n",
    "\n",
    "        validation_dict = {\n",
    "            input: validation_data[:,0:14],\n",
    "            labels: validation_data[:,14],\n",
    "        }\n",
    "\n",
    "        for i in range(NUM_BATCHES):\n",
    "            batch = training_data[np.random.choice(training_size, BATCH_SIZE, False),:]\n",
    "            train_step.run({input: batch[:,0:14], labels: batch[:,14]})\n",
    "\n",
    "            if i % 100 == 0 or i == NUM_BATCHES - 1:\n",
    "    #             print('Train acc. %.2f%%, val acc. %.2f%%, train recall %.2f%, val recall %.2f%, train precision %.2f%, val precision %.2f%, at step %d' \n",
    "                print('Train acc. %.2f%%, val acc. %.2f%%, at step %d' \n",
    "                      % (accuracy.eval(training_dict) * 100,\n",
    "                         accuracy.eval(validation_dict) * 100, \n",
    "                         i))\n",
    "                \n",
    "        output_data = outputs.eval({input: data_vector[:,0:14]})\n",
    "\n",
    "        # Save the model\n",
    "        mySaver.save(sess, model_path+model_name+'.ckpt', global_step = NUM_BATCHES)\n",
    "\n",
    "    print('CNN training runtime for ' + str(pctl) + '% cloud cover: ' + timer(start_time, time.time()))\n",
    "    \n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack directory already exists\n",
      "Removing existing \"stack.tif\" and creating new one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\rasterio\\__init__.py:160: FutureWarning: GDAL-style transforms are deprecated and will not be supported in Rasterio 1.0.\n",
      "  transform = guard_transform(transform)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc. 57.65%, val acc. 54.04%, at step 0\n",
      "Train acc. 96.61%, val acc. 98.74%, at step 100\n",
      "Train acc. 98.90%, val acc. 99.17%, at step 200\n",
      "Train acc. 99.04%, val acc. 99.21%, at step 300\n",
      "Train acc. 99.08%, val acc. 99.20%, at step 400\n",
      "Train acc. 99.09%, val acc. 99.21%, at step 500\n",
      "Train acc. 99.11%, val acc. 99.23%, at step 600\n",
      "Train acc. 99.10%, val acc. 99.23%, at step 700\n",
      "Train acc. 99.11%, val acc. 99.22%, at step 800\n",
      "Train acc. 99.12%, val acc. 99.23%, at step 900\n",
      "Train acc. 99.12%, val acc. 99.24%, at step 999\n",
      "CNN training runtime for 10% cloud cover: 00:01:13.44\n",
      "Train acc. 53.65%, val acc. 63.46%, at step 0\n",
      "Train acc. 95.04%, val acc. 96.87%, at step 100\n",
      "Train acc. 98.74%, val acc. 99.26%, at step 200\n",
      "Train acc. 98.99%, val acc. 99.26%, at step 300\n",
      "Train acc. 99.11%, val acc. 99.32%, at step 400\n",
      "Train acc. 99.18%, val acc. 99.33%, at step 500\n",
      "Train acc. 99.19%, val acc. 99.34%, at step 600\n",
      "Train acc. 99.19%, val acc. 99.34%, at step 700\n",
      "Train acc. 99.20%, val acc. 99.33%, at step 800\n",
      "Train acc. 99.20%, val acc. 99.33%, at step 900\n",
      "Train acc. 99.20%, val acc. 99.34%, at step 999\n",
      "CNN training runtime for 20% cloud cover: 00:02:36.15\n",
      "Train acc. 41.68%, val acc. 44.48%, at step 0\n",
      "Train acc. 94.70%, val acc. 96.78%, at step 100\n",
      "Train acc. 98.83%, val acc. 99.35%, at step 200\n",
      "Train acc. 98.91%, val acc. 99.37%, at step 300\n",
      "Train acc. 99.01%, val acc. 99.39%, at step 400\n",
      "Train acc. 99.06%, val acc. 99.39%, at step 500\n",
      "Train acc. 99.08%, val acc. 99.41%, at step 600\n",
      "Train acc. 99.11%, val acc. 99.40%, at step 700\n",
      "Train acc. 99.11%, val acc. 99.43%, at step 800\n",
      "Train acc. 99.12%, val acc. 99.43%, at step 900\n",
      "Train acc. 99.12%, val acc. 99.44%, at step 999\n",
      "CNN training runtime for 30% cloud cover: 00:04:38.78\n",
      "Train acc. 42.94%, val acc. 39.89%, at step 0\n",
      "Train acc. 97.38%, val acc. 98.82%, at step 100\n",
      "Train acc. 98.21%, val acc. 99.30%, at step 200\n",
      "Train acc. 98.86%, val acc. 99.36%, at step 300\n",
      "Train acc. 98.98%, val acc. 99.36%, at step 400\n",
      "Train acc. 99.03%, val acc. 99.39%, at step 500\n",
      "Train acc. 99.04%, val acc. 99.39%, at step 600\n",
      "Train acc. 99.04%, val acc. 99.39%, at step 700\n",
      "Train acc. 99.07%, val acc. 99.39%, at step 800\n",
      "Train acc. 99.07%, val acc. 99.41%, at step 900\n",
      "Train acc. 99.04%, val acc. 99.39%, at step 999\n",
      "CNN training runtime for 40% cloud cover: 00:06:43.14\n",
      "Train acc. 50.22%, val acc. 57.49%, at step 0\n",
      "Train acc. 95.41%, val acc. 97.05%, at step 100\n",
      "Train acc. 98.46%, val acc. 99.32%, at step 200\n",
      "Train acc. 99.07%, val acc. 99.38%, at step 300\n",
      "Train acc. 99.09%, val acc. 99.38%, at step 400\n",
      "Train acc. 99.08%, val acc. 99.39%, at step 500\n",
      "Train acc. 99.12%, val acc. 99.39%, at step 600\n",
      "Train acc. 99.12%, val acc. 99.40%, at step 700\n",
      "Train acc. 99.11%, val acc. 99.39%, at step 800\n",
      "Train acc. 99.13%, val acc. 99.41%, at step 900\n",
      "Train acc. 99.14%, val acc. 99.41%, at step 999\n",
      "CNN training runtime for 50% cloud cover: 00:08:49.91\n",
      "Train acc. 56.58%, val acc. 52.46%, at step 0\n",
      "Train acc. 98.02%, val acc. 99.01%, at step 100\n",
      "Train acc. 98.44%, val acc. 99.19%, at step 200\n",
      "Train acc. 98.94%, val acc. 99.38%, at step 300\n",
      "Train acc. 98.98%, val acc. 99.41%, at step 400\n",
      "Train acc. 99.11%, val acc. 99.40%, at step 500\n",
      "Train acc. 99.11%, val acc. 99.39%, at step 600\n",
      "Train acc. 99.11%, val acc. 99.39%, at step 700\n",
      "Train acc. 99.11%, val acc. 99.40%, at step 800\n",
      "Train acc. 99.12%, val acc. 99.40%, at step 900\n",
      "Train acc. 99.12%, val acc. 99.41%, at step 999\n",
      "CNN training runtime for 60% cloud cover: 00:12:00.13\n",
      "Train acc. 37.80%, val acc. 37.29%, at step 0\n",
      "Train acc. 98.05%, val acc. 98.99%, at step 100\n",
      "Train acc. 98.67%, val acc. 99.15%, at step 200\n",
      "Train acc. 98.96%, val acc. 99.35%, at step 300\n",
      "Train acc. 98.97%, val acc. 99.38%, at step 400\n",
      "Train acc. 99.01%, val acc. 99.42%, at step 500\n",
      "Train acc. 99.00%, val acc. 99.41%, at step 600\n",
      "Train acc. 99.02%, val acc. 99.42%, at step 700\n",
      "Train acc. 99.00%, val acc. 99.41%, at step 800\n",
      "Train acc. 99.03%, val acc. 99.42%, at step 900\n",
      "Train acc. 99.04%, val acc. 99.42%, at step 999\n",
      "CNN training runtime for 70% cloud cover: 00:18:26.25\n",
      "Train acc. 54.63%, val acc. 50.94%, at step 0\n",
      "Train acc. 98.08%, val acc. 98.94%, at step 100\n",
      "Train acc. 98.32%, val acc. 99.01%, at step 200\n",
      "Train acc. 98.87%, val acc. 99.35%, at step 300\n",
      "Train acc. 98.91%, val acc. 99.37%, at step 400\n",
      "Train acc. 98.91%, val acc. 99.37%, at step 500\n",
      "Train acc. 98.93%, val acc. 99.38%, at step 600\n",
      "Train acc. 98.91%, val acc. 99.36%, at step 700\n",
      "Train acc. 98.95%, val acc. 99.40%, at step 800\n",
      "Train acc. 98.93%, val acc. 99.39%, at step 900\n",
      "Train acc. 98.96%, val acc. 99.40%, at step 999\n",
      "CNN training runtime for 80% cloud cover: 00:18:57.08\n",
      "Train acc. 52.58%, val acc. 57.06%, at step 0\n",
      "Train acc. 97.92%, val acc. 98.76%, at step 100\n",
      "Train acc. 98.64%, val acc. 99.27%, at step 200\n",
      "Train acc. 98.81%, val acc. 99.37%, at step 300\n",
      "Train acc. 98.85%, val acc. 99.39%, at step 400\n",
      "Train acc. 98.90%, val acc. 99.39%, at step 500\n",
      "Train acc. 98.90%, val acc. 99.37%, at step 600\n",
      "Train acc. 98.93%, val acc. 99.40%, at step 700\n",
      "Train acc. 98.95%, val acc. 99.41%, at step 800\n",
      "Train acc. 98.94%, val acc. 99.40%, at step 900\n",
      "Train acc. 98.97%, val acc. 99.43%, at step 999\n",
      "CNN training runtime for 90% cloud cover: 00:18:04.24\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'function' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-deca97a4d231>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m metrics = pd.DataFrame(np.column_stack[pctls, accuracy, precision, recall, f1],\n\u001b[0m\u001b[0;32m     38\u001b[0m                       columns=['cloud_cover','accuracy','precision','recall','f1'])\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'function' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from math import sqrt\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, accuracy_score\n",
    "import time\n",
    "\n",
    "# Loop to do all the functions together\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "feat_list_new = ['aspect','curve', 'developed', 'distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "#  Stack all the flood imagery\n",
    "feat_list_files = tifStacker(path, img, feat_list_new)\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "accuracy = []\n",
    "time = []\n",
    "\n",
    "# Load stacked image, preprocess\n",
    "for i, pctl in enumerate(pctls):\n",
    "    \n",
    "    data, data_ind = preprocessing(path, img, pctl)\n",
    "    \n",
    "    data_vector, training_data, validation_data, data_mean, data_std, training_size = trainVal(data)\n",
    "    \n",
    "    start_time = time.time() # Start timer for CNN training\n",
    "    \n",
    "    y_pred = CNNtrainer(data_vector, training_data, validation_data, data_mean, data_std, model_path, img, pctl)\n",
    "    \n",
    "    time.append(time.time() - start_time) # Elapsed time in seconds\n",
    "    \n",
    "    y_true = data_vector[:,14]\n",
    "    \n",
    "    precision.append(sklearn.metrics.precision_score(y_true, y_pred))\n",
    "    recall.append(sklearn.metrics.recall_score(y_true, y_pred))\n",
    "    f1.append(sklearn.metrics.f1_score(y_true, y_pred))\n",
    "    accuracy.append(sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "    \n",
    "metrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, time]),\n",
    "                      columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n",
    "\n",
    "print(metrics)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   cloud_cover  precision    recall        f1     time\n",
      "0         90.0   0.940477  0.853726  0.895004   4424.0\n",
      "1         80.0   0.935017  0.846210  0.888400   9375.0\n",
      "2         70.0   0.940411  0.821862  0.877149  16758.0\n",
      "3         60.0   0.911477  0.835902  0.872055  24194.0\n",
      "4         50.0   0.941435  0.836684  0.885974  31831.0\n",
      "5         40.0   0.940850  0.838520  0.886742  43213.0\n",
      "6         30.0   0.933587  0.831837  0.879780  66385.0\n",
      "7         20.0   0.934336  0.818228  0.872436  68228.0\n",
      "8         10.0   0.935576  0.827322  0.878125  65064.0\n"
     ]
    }
   ],
   "source": [
    "time = [(18*3600)+(4*60)+24, (18*3600)+(57*60)+8, (18*3600)+(26*60)+25, (12*3600)+(13), (8*3600)+(49*60)+91, (6*3600)+(43*60)+14, (4*3600)+(38*60)+78, (2*3600)+(36*60)+15, (1*3600)+(13*60)+44]\n",
    "time.reverse()\n",
    "\n",
    "metrics = pd.DataFrame(np.column_stack([[90,80,70,60,50,40,30,20,10], precision, recall, f1, time]),\n",
    "                       \n",
    "                      columns=['cloud_cover','precision','recall','f1','time'])\n",
    "\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to add a printout or metric with how many flooded pixels are in train/test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.to_csv(path+'tables/CNN_cloud_metrics/'+'train_'+img+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x28fd8a44240>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize training metrics\n",
    "\n",
    "metrics.plot(x='cloud_cover', y=['recall', 'precision','f1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on cloud gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_gaps(path, img, pctl):\n",
    "\n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'cloudmasks/'+img\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds_'+str(pctl)+'.npy')\n",
    "    \n",
    "    # Invert cloudmask to get the gaps\n",
    "    cloudMask = np.invert(cloudMask)\n",
    "    \n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "    \n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = training_data[:,0:14].mean(0)\n",
    "    data_std = training_data[:,0:14].std(0)\n",
    "\n",
    "    return data_vector, data_mean, data_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: TF doesn't save every variable, like outputs or input, so we need to save those somehow\n",
    "https://stackoverflow.com/questions/43887425/how-to-import-a-model-in-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gapFill(data_vector, data_mean, data_std, img, pctl):\n",
    "    \n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    \n",
    "    NUM_INPUT_BANDS = 14\n",
    "    NUM_HIDDEN_1 = 15\n",
    "    NUM_HIDDEN_2 = 15\n",
    "    NUM_CLASSES = 2\n",
    "\n",
    "    # Prepare feed dictionary\n",
    "\n",
    "    input = tf.placeholder(tf.float32, shape=[None, NUM_INPUT_BANDS])\n",
    "    labels = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "    normalized = (input - data_mean) / data_std\n",
    "    \n",
    "    hidden1 = tf.nn.tanh(make_nn_layer(normalized, NUM_HIDDEN_1))\n",
    "    hidden2 = tf.nn.tanh(make_nn_layer(hidden1, NUM_HIDDEN_2))\n",
    "    logits = make_nn_layer(hidden2, NUM_CLASSES)\n",
    "    outputs = tf.argmax(logits, 1)\n",
    "\n",
    "    int_labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = int_labels, name='xentropy')\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy) # should we minimize something else?\n",
    "\n",
    "    correct_prediction = tf.equal(outputs, int_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "\n",
    "    config.gpu_options.allow_growth = True\n",
    "    sess = tf.Session(config=config)\n",
    "    # run_options = tf.RunOptions(report_tensor_allocations_upon_oom = True)\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "\n",
    "    with tf.Session(config=config) as sess:\n",
    "        sess.run(tf.global_variables_initializer(), options=run_options)\n",
    "        mySaver = tf.train.import_meta_graph(model_path+model_name+'.ckpt-1000.meta')\n",
    "        mySaver.restore(sess, tf.train.latest_checkpoint(model_path+'./'))\n",
    "\n",
    "        y_pred = outputs.eval({input: data_vector[:,0:14]})\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4337_LC08_026038_20160325_1_clouds_90.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gapFill(data_vector, data_mean, img, 80)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4337_LC08_026038_20160325_1_clouds_80.ckpt-1000.meta'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pctl=80\n",
    "model_name = img+'_clouds_'+str(pctl)\n",
    "model_path+model_name+'.ckpt-1000.meta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4337_LC08_026038_20160325_1_clouds_90.ckpt-1000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-199-44341abedd94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mdata_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_std\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing_gaps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpctl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgapFill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpctl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-198-e35d3f80a3d9>\u001b[0m in \u001b[0;36mgapFill\u001b[1;34m(data_vector, data_mean, img, pctl)\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mmySaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdata_vector\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'outputs' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "accuracy = []\n",
    "predictions = []\n",
    "\n",
    "for i, pctl in enumerate(pctls):\n",
    "    \n",
    "    data_vector, data_mean, data_std = preprocessing_gaps(path, img, pctl)\n",
    "    \n",
    "    y_pred = gapFill(data_vector, data_mean, data_std, img, pctl)\n",
    "    \n",
    "    y_true = data_vector[:,14]\n",
    "    \n",
    "    precision.append(sklearn.metrics.precision_score(y_true, y_pred))\n",
    "    recall.append(sklearn.metrics.recall_score(y_true, y_pred))\n",
    "    f1.append(sklearn.metrics.f1_score(y_true, y_pred))\n",
    "    predictions.append(y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
