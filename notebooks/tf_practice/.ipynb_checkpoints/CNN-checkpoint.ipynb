{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN piece by piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts features to 28x28x1 shape (in inferred batches, -1)\n",
    "input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "# Convolutional layer #1 with 32 filters\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs = input_layer,\n",
    "    filters = 32,\n",
    "    kernel_size = [5, 5],\n",
    "    padding = \"same\",\n",
    "    activation = tf.nn.relu)\n",
    "\n",
    "# Pooling layer #1\n",
    "pool1 = tf.layers.max_pooling2d(inputs = conv1, \n",
    "                                pool_size = [2,2], \n",
    "                                strides = 2)\n",
    "\n",
    "\n",
    "# Convolutional layer #2 with 64 filters\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs = pool1,\n",
    "    filters = 64,\n",
    "    kernel_size = [5, 5],\n",
    "    activation = tf.nn.relu)\n",
    "\n",
    "# Pooling layer #2\n",
    "pool2 = tf.layers.max_pooling2d(inputs = conv2, \n",
    "                                pool_size = [2,2], \n",
    "                                strides = 2)\n",
    "\n",
    "# Now add dense layer to perform classification on features extracted by the convolution/pooling layers\n",
    "\n",
    "# First, flatten tensor to two dimensions (width x height x channels)\n",
    "pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "# Connect dense layer\n",
    "dense = tf.layers.dense(inputs = pool2_flat, \n",
    "                        units = 1024, \n",
    "                        activation = tf.nn.relu)\n",
    "\n",
    "# Add dropout regularization to dense layer. \n",
    "# 40% of elements will be randomly dropped during training when training is TRUE\n",
    "dropout = tf.layers.dropout(inputs = dense, rate = 0.4, training = mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "# Resulting tensor, dropout is shape [batch_size, 1024]\n",
    "\n",
    "# Logits layer returns raw values for our predictions\n",
    "# We create a dense layer with 10 neurons (one for each target class, 0-9) with linear  activation\n",
    "logits = tf.layers.dense(inputs = dropout, units = 10)\n",
    "\n",
    "# Final output tensor, logits is shape [batch_size, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the logits layer into two formats:\n",
    "# (1) predicted class for each example (digit from 0-9)\n",
    "# (2) probabilities for each possible target class\n",
    "\n",
    "\"\"\"\n",
    "Predictions\n",
    "\n",
    "tf.argmax:\n",
    "- Axis specifies the axis of the input tensor along which to find the greatest value\n",
    "- Here, we want to find the largest value along the dimension with index 1\n",
    "  which corresponds to our predictions in logits tensor of shape [batch_size, 10]\n",
    "\n",
    "tf.nn.softmax:\n",
    "- We derive probs from logits layer by applying softmax activation\n",
    "\"\"\"\n",
    "\n",
    "# Compile predictions in a dict, return an EstimatorSpec object\n",
    "predictions = {\n",
    "    \"classes\": tf.argmax(input=logits, axis=1),\n",
    "    \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "}\n",
    "if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss\n",
    "Loss for our CNN is the softmax cross-entropy of the logits layer and our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels tensor contains a list of prediction indices for our examples (e.g. [1, 5, ...])\n",
    "# logits contains the linear outputs of our last layer\n",
    "# tf.losses.sparse_softmax_cross_entropy calculates the softmax crossentropy \n",
    "# (aka: categorical crossentropy, negative log-likelihood) from these two inputs in an efficient, numerically stable way.\n",
    "loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure training op\n",
    "Configure model to optimize this loss value during training. We use a learning rate of  0.001 and stochastic gradient descent as optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss = loss,\n",
    "        global_step = tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode = mode, loss = loss, train_op = train_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metric_ops = {\n",
    "    \"accuracy\": tf.metrics.accuracy(\n",
    "        labels = labels, predictions = predictions[\"class\"])\n",
    "}\n",
    "return tf.estimator.EstimatorSpec(\n",
    "    mode = mode, loss = loss, eval_metric_ops = eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "    # Pooling Layer #1\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Convolutional Layer #2 and Pooling Layer #2\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "    # Dense Layer\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    # Logits Layer\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data as np arrays\n",
    "# Raw pixel values for 55,000 images of hand-drawn digits\n",
    "# Training labels with values from 0-9\n",
    "\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255) # Divide by 255\n",
    "train_labels = train_labels.astype(np.int32) # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32) # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_covnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002049867F470>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create an estimator for our model\n",
    "# (estimators are a TensorFlow class for performing high-level model training, evaluation, and inference)\n",
    "\n",
    "# Create estimator. \n",
    "# model_dir is where checkpoints (model data) will be saved\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn = cnn_model_fn, model_dir = \"/tmp/mnist_covnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a logging hook to track progress while the CNN is training\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors = tensors_to_log, every_n_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_covnet_model\\model.ckpt-1001\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1001 into /tmp/mnist_covnet_model\\model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.07054292 0.11348545 0.09268121 0.06663964 0.13154176 0.09337026\n",
      "  0.07955404 0.07471107 0.15346894 0.12400474]\n",
      " [0.04343146 0.10258989 0.11969012 0.08906882 0.08916412 0.08433247\n",
      "  0.09387224 0.14944091 0.10355207 0.1248579 ]\n",
      " [0.06427707 0.0977134  0.17542368 0.15851511 0.07947324 0.03446219\n",
      "  0.237709   0.03469205 0.06289919 0.0548351 ]\n",
      " [0.04771806 0.04658738 0.06006234 0.11168235 0.10869076 0.03986224\n",
      "  0.0410329  0.33008516 0.06327008 0.15100871]\n",
      " [0.06166292 0.03492869 0.08907524 0.06793495 0.22011842 0.07113232\n",
      "  0.08781281 0.0975274  0.12543428 0.14437297]\n",
      " [0.07831957 0.15955654 0.13968563 0.10698231 0.06776198 0.09830673\n",
      "  0.0965921  0.0741463  0.10118664 0.07746205]\n",
      " [0.09459692 0.1392612  0.1102199  0.1547913  0.05595256 0.11493196\n",
      "  0.05098328 0.05607905 0.15574601 0.06743791]\n",
      " [0.35205653 0.02593481 0.07339607 0.1108132  0.09148577 0.07196201\n",
      "  0.11131824 0.04533595 0.07350107 0.04419638]\n",
      " [0.08523452 0.03340086 0.08542161 0.09872025 0.13922282 0.0664078\n",
      "  0.05294361 0.23803493 0.1243168  0.0762969 ]\n",
      " [0.07561528 0.08470318 0.20478128 0.14734009 0.03984483 0.05736982\n",
      "  0.15312387 0.06051374 0.11685509 0.05985275]\n",
      " [0.04334772 0.12582628 0.07412952 0.07253229 0.10177124 0.07252736\n",
      "  0.08473645 0.17030762 0.08957447 0.16524701]\n",
      " [0.0541367  0.05843642 0.11057676 0.14731362 0.04082285 0.08399366\n",
      "  0.04495157 0.21861017 0.1345403  0.10661799]\n",
      " [0.13590321 0.06690812 0.11772246 0.1310563  0.08100428 0.10415301\n",
      "  0.08808289 0.07861011 0.07894208 0.11761752]\n",
      " [0.0643914  0.0570354  0.10407571 0.08127028 0.08621696 0.07656027\n",
      "  0.26213032 0.04583244 0.07995456 0.14253269]\n",
      " [0.10202631 0.10719184 0.1785788  0.16897504 0.05291433 0.06659748\n",
      "  0.11232358 0.03850861 0.1114633  0.06142075]\n",
      " [0.1145679  0.03118327 0.05632128 0.0590389  0.15979761 0.08462155\n",
      "  0.09943102 0.17253253 0.09972217 0.12278385]\n",
      " [0.03274658 0.24990155 0.0782068  0.11882751 0.05237735 0.05984713\n",
      "  0.08122281 0.11103753 0.09933214 0.11650066]\n",
      " [0.06118758 0.1263844  0.12175518 0.07904468 0.05439449 0.05859246\n",
      "  0.1676592  0.07312167 0.15411326 0.1037471 ]\n",
      " [0.13332938 0.05376112 0.08474429 0.1431557  0.11177278 0.10129993\n",
      "  0.15900077 0.05604739 0.07568903 0.08119956]\n",
      " [0.14648424 0.07459535 0.09682978 0.30874932 0.06042377 0.13120845\n",
      "  0.05793741 0.03915922 0.04812673 0.03648572]\n",
      " [0.06606306 0.07606576 0.08236957 0.08197614 0.06950071 0.09621459\n",
      "  0.12503351 0.09385484 0.201402   0.10751987]\n",
      " [0.13793527 0.08785626 0.09152475 0.11689141 0.0926913  0.14266741\n",
      "  0.05795945 0.11080679 0.09668484 0.06498246]\n",
      " [0.07386991 0.09716898 0.09868179 0.10229112 0.09850149 0.057081\n",
      "  0.19368199 0.06097045 0.11911297 0.09864023]\n",
      " [0.06658608 0.13758217 0.09478634 0.10334273 0.04931128 0.07311121\n",
      "  0.20167571 0.05325316 0.13255902 0.08779218]\n",
      " [0.06124676 0.08431777 0.08451995 0.07502636 0.08359683 0.13478509\n",
      "  0.07585855 0.07403412 0.18703103 0.13958357]\n",
      " [0.12847146 0.09271374 0.15195912 0.13710408 0.04269841 0.04905419\n",
      "  0.20375939 0.03141011 0.09205352 0.07077592]\n",
      " [0.38607892 0.02994503 0.11524412 0.08468098 0.06340852 0.06575634\n",
      "  0.11869679 0.0175817  0.06955367 0.04905389]\n",
      " [0.06104507 0.07031593 0.05712431 0.06689652 0.08506514 0.06300273\n",
      "  0.10510577 0.22418521 0.11589631 0.15136302]\n",
      " [0.13755184 0.04112155 0.16886489 0.0754577  0.08570677 0.06721342\n",
      "  0.2469772  0.04715202 0.0518452  0.07810943]\n",
      " [0.03426188 0.25813758 0.08890966 0.07135975 0.06066589 0.06285329\n",
      "  0.0761502  0.12185904 0.12563089 0.10017174]\n",
      " [0.08876182 0.08271956 0.07082559 0.05653961 0.11922006 0.09928221\n",
      "  0.12348226 0.11286259 0.11524916 0.13105713]\n",
      " [0.04485109 0.12801555 0.1057887  0.10700385 0.09912295 0.10338954\n",
      "  0.07022949 0.11197387 0.13003221 0.09959278]\n",
      " [0.06229009 0.07369844 0.0800682  0.08437172 0.0954335  0.08386246\n",
      "  0.09197212 0.13324511 0.15853229 0.1365261 ]\n",
      " [0.07555765 0.06518969 0.12559386 0.08310578 0.08376448 0.07797098\n",
      "  0.23471308 0.04802772 0.12100023 0.0850766 ]\n",
      " [0.16426297 0.05048668 0.08352236 0.16384165 0.06587519 0.13519722\n",
      "  0.07503462 0.08138702 0.0883687  0.09202357]\n",
      " [0.04981838 0.07867249 0.07538529 0.09186527 0.12588277 0.06162811\n",
      "  0.0647015  0.16617091 0.12002239 0.16585293]\n",
      " [0.07880391 0.11328096 0.09896255 0.09408669 0.08540224 0.1133647\n",
      "  0.09857923 0.07174136 0.17835298 0.06742535]\n",
      " [0.36985824 0.02142747 0.06863868 0.13504736 0.04388749 0.08839923\n",
      "  0.13813308 0.03018033 0.05954057 0.04488762]\n",
      " [0.05934727 0.06305759 0.13616227 0.0764581  0.08997272 0.10117359\n",
      "  0.05850544 0.14131245 0.16931985 0.1046907 ]\n",
      " [0.2531122  0.05139202 0.13372815 0.07763149 0.08319473 0.0615031\n",
      "  0.15111862 0.06543401 0.04229906 0.08058669]\n",
      " [0.04686258 0.03911125 0.05117714 0.14642443 0.2050775  0.06845771\n",
      "  0.05920234 0.12340967 0.11562783 0.1446495 ]\n",
      " [0.05585643 0.12098894 0.09030494 0.13741519 0.10256037 0.06898391\n",
      "  0.09563603 0.11896934 0.09242826 0.11685669]\n",
      " [0.12072306 0.04411645 0.10402281 0.14776716 0.08330878 0.12549181\n",
      "  0.07762941 0.06544652 0.14722168 0.0842723 ]\n",
      " [0.04531074 0.1861113  0.16958714 0.15038198 0.05548663 0.05305875\n",
      "  0.06465841 0.03803645 0.14233314 0.09503549]\n",
      " [0.04028714 0.09357499 0.09077776 0.13969532 0.05640915 0.11745903\n",
      "  0.11445898 0.09446794 0.14578761 0.10708202]\n",
      " [0.09897429 0.02858779 0.06128704 0.07791729 0.12792525 0.10886236\n",
      "  0.05798628 0.17751344 0.07050542 0.19044086]\n",
      " [0.08420572 0.04112642 0.05655245 0.06241957 0.05067784 0.15437582\n",
      "  0.08562475 0.09687348 0.23033862 0.13780531]\n",
      " [0.0385866  0.05951932 0.09046775 0.09824297 0.08629407 0.08797452\n",
      "  0.06511167 0.11978664 0.23967682 0.11433972]\n",
      " [0.05592997 0.03760717 0.11360484 0.06593257 0.22353281 0.07287477\n",
      "  0.06345627 0.13317835 0.08165136 0.15223186]\n",
      " [0.02772618 0.1047908  0.08512603 0.05291036 0.13506775 0.07370335\n",
      "  0.07225271 0.13416119 0.11820704 0.19605461]\n",
      " [0.051202   0.17968577 0.12562555 0.11062288 0.07048167 0.0727282\n",
      "  0.08224355 0.13001129 0.08251428 0.09488475]\n",
      " [0.15343916 0.02211439 0.10026968 0.14043537 0.09409191 0.1597384\n",
      "  0.07460573 0.0753122  0.10793717 0.07205594]\n",
      " [0.04974686 0.09102235 0.06499714 0.11169715 0.0778819  0.10256214\n",
      "  0.06773824 0.12480279 0.20948361 0.10006773]\n",
      " [0.08002909 0.13494714 0.08347783 0.10068341 0.07095207 0.08194233\n",
      "  0.06871354 0.16482128 0.11127314 0.10316027]\n",
      " [0.08594655 0.08792587 0.0912837  0.12692477 0.07288026 0.12905061\n",
      "  0.08717851 0.06376929 0.15719055 0.09784994]\n",
      " [0.06247039 0.15082087 0.09603361 0.0628687  0.06565478 0.07252213\n",
      "  0.05221477 0.166261   0.13118553 0.13996813]\n",
      " [0.16211487 0.03256596 0.04719487 0.05022396 0.18637905 0.04629816\n",
      "  0.0882151  0.1335468  0.09272833 0.16073285]\n",
      " [0.38371935 0.02619663 0.09310186 0.09094466 0.05029057 0.08565959\n",
      "  0.11776051 0.02798367 0.07224806 0.05209495]\n",
      " [0.04455849 0.2540765  0.07038404 0.12252371 0.06298259 0.06621588\n",
      "  0.09437749 0.10094463 0.10572221 0.07821445]\n",
      " [0.11928988 0.03469761 0.07578    0.07878794 0.19001794 0.05436344\n",
      "  0.11022899 0.12670135 0.10809129 0.10204162]\n",
      " [0.0327081  0.06309409 0.07942829 0.07239892 0.12200141 0.07038205\n",
      "  0.05790836 0.1909581  0.14683764 0.16428305]\n",
      " [0.04393884 0.09041368 0.07396241 0.06837317 0.1403936  0.05025393\n",
      "  0.10462231 0.14080504 0.13273649 0.15450051]\n",
      " [0.04686743 0.09487151 0.05473477 0.06874669 0.05788042 0.07860908\n",
      "  0.03232946 0.37332916 0.11340418 0.07922728]\n",
      " [0.05481666 0.2251113  0.09609526 0.08773167 0.05543924 0.08954726\n",
      "  0.09676351 0.0857521  0.12700167 0.08174121]\n",
      " [0.15391248 0.05696359 0.09683898 0.12035739 0.06086783 0.09616458\n",
      "  0.19900559 0.04666656 0.09339422 0.07582887]\n",
      " [0.06674263 0.14346139 0.13100529 0.19558074 0.08926372 0.05261182\n",
      "  0.06351725 0.03960337 0.13552213 0.08269157]\n",
      " [0.05906859 0.04912418 0.14814033 0.07635851 0.09675156 0.0586771\n",
      "  0.08545539 0.09550405 0.18891837 0.14200182]\n",
      " [0.04199465 0.05979267 0.08270962 0.12081884 0.18101521 0.04182687\n",
      "  0.07199997 0.10625316 0.06609344 0.22749557]\n",
      " [0.05589554 0.08345503 0.06079942 0.08325654 0.1149635  0.06426049\n",
      "  0.05690588 0.19748747 0.10891178 0.17406438]\n",
      " [0.07551134 0.05776827 0.12779327 0.04574525 0.17592147 0.05213926\n",
      "  0.12032703 0.07097468 0.16221756 0.11160191]\n",
      " [0.04412255 0.08330268 0.04221464 0.09823003 0.08913842 0.09179795\n",
      "  0.05309637 0.2945694  0.09336356 0.11016447]\n",
      " [0.05132933 0.08162389 0.19700325 0.12456676 0.07549707 0.05462299\n",
      "  0.13813852 0.06981146 0.14816405 0.05924255]\n",
      " [0.06093679 0.03956524 0.08900048 0.14958887 0.12305506 0.0976918\n",
      "  0.07340862 0.13028014 0.06816388 0.16830915]\n",
      " [0.05776833 0.13442262 0.10067543 0.11650445 0.06017743 0.09387068\n",
      "  0.08564358 0.04980503 0.20659992 0.0945325 ]\n",
      " [0.09643998 0.0599333  0.08674916 0.06940883 0.17495476 0.09858114\n",
      "  0.13331224 0.10586145 0.09088048 0.08387868]\n",
      " [0.04404777 0.05138793 0.06205666 0.08584312 0.14135894 0.06611513\n",
      "  0.09734628 0.11611753 0.13996848 0.19575821]\n",
      " [0.06820688 0.13340455 0.08455993 0.19100414 0.06572946 0.08985329\n",
      "  0.10018366 0.07663263 0.12177034 0.06865515]\n",
      " [0.10058467 0.03827111 0.06097273 0.12067921 0.06341164 0.19319288\n",
      "  0.04880965 0.07469692 0.21077879 0.08860244]\n",
      " [0.08730491 0.05582608 0.30268162 0.07154424 0.08954269 0.04504094\n",
      "  0.11021794 0.09012914 0.05646417 0.09124839]\n",
      " [0.0716807  0.08694793 0.08194737 0.10908676 0.05803322 0.06901075\n",
      "  0.08543894 0.13294992 0.1857681  0.1191363 ]\n",
      " [0.07512927 0.07852086 0.17966756 0.09518743 0.07178743 0.073663\n",
      "  0.09345908 0.0535403  0.2104158  0.06862919]\n",
      " [0.07809589 0.06362775 0.07402185 0.0603033  0.16959631 0.08694945\n",
      "  0.10471005 0.10960333 0.11981819 0.13327387]\n",
      " [0.08524049 0.05196411 0.10331176 0.0569028  0.08195322 0.1063737\n",
      "  0.0794961  0.09272223 0.26946634 0.07256928]\n",
      " [0.07831264 0.06469258 0.08458739 0.13002378 0.08588617 0.08915742\n",
      "  0.07537117 0.09506698 0.19029279 0.10660902]\n",
      " [0.05107177 0.06928843 0.0724679  0.07526576 0.12125544 0.07277942\n",
      "  0.07176029 0.15999788 0.11265574 0.19345732]\n",
      " [0.10183899 0.04852493 0.09866735 0.07871139 0.06699417 0.05959488\n",
      "  0.32694167 0.05419618 0.09720784 0.06732256]\n",
      " [0.03754219 0.22497778 0.11871769 0.06920174 0.05363104 0.07571306\n",
      "  0.09660938 0.08221818 0.15847683 0.08291225]\n",
      " [0.09920458 0.0605167  0.10776491 0.07910226 0.06295083 0.09409545\n",
      "  0.07574819 0.09119346 0.2321412  0.09728243]\n",
      " [0.03298777 0.3010437  0.09053843 0.12731177 0.05424063 0.08092336\n",
      "  0.05088199 0.098437   0.10277562 0.0608598 ]\n",
      " [0.0774256  0.11167841 0.15951087 0.15133394 0.07630733 0.07385806\n",
      "  0.06382027 0.10298443 0.10333977 0.0797414 ]\n",
      " [0.19961195 0.02454222 0.03634463 0.09116554 0.1057158  0.06976505\n",
      "  0.05164042 0.23820332 0.0710918  0.11191925]\n",
      " [0.20618746 0.04891764 0.23403081 0.17886429 0.05931331 0.05426884\n",
      "  0.07543401 0.02606773 0.04909211 0.06782374]\n",
      " [0.09977551 0.02331923 0.09512737 0.05358773 0.23612158 0.08565594\n",
      "  0.12383961 0.07195194 0.08146557 0.12915562]\n",
      " [0.34748024 0.03228113 0.1275605  0.07892797 0.07051651 0.12420791\n",
      "  0.07079142 0.03096434 0.08567733 0.03159261]\n",
      " [0.2881485  0.02642476 0.11447432 0.13456316 0.06036689 0.09801982\n",
      "  0.0680911  0.05996236 0.08012532 0.06982371]\n",
      " [0.17508236 0.03335907 0.10269491 0.05003516 0.15723293 0.04860694\n",
      "  0.21968901 0.06418172 0.04932009 0.0997978 ]\n",
      " [0.06756265 0.14256059 0.09423799 0.06681258 0.06795503 0.09464154\n",
      "  0.13746308 0.05951925 0.16501877 0.10422857]\n",
      " [0.4257935  0.0250778  0.04152438 0.07407141 0.04596659 0.08661323\n",
      "  0.15155356 0.04325731 0.05595317 0.050189  ]\n",
      " [0.07127996 0.09858987 0.08203579 0.11425995 0.06484756 0.10597846\n",
      "  0.08259647 0.17600189 0.08979453 0.11461551]\n",
      " [0.07575323 0.0563721  0.11328908 0.08492146 0.11811282 0.04954879\n",
      "  0.16194114 0.06575289 0.13403185 0.1402767 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 1.745976, step = 1001\n",
      "INFO:tensorflow:Saving checkpoints for 1002 into /tmp/mnist_covnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 1.745976.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x2049c995eb8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {\"x\": train_data},\n",
    "    y = train_labels,\n",
    "    batch_size = 100,\n",
    "    num_epochs = None,\n",
    "    shuffle = True)\n",
    "\n",
    "# Train one step and display the probabilities\n",
    "mnist_classifier.train(\n",
    "    input_fn = train_input_fn,\n",
    "    steps = 1,\n",
    "    hooks = [logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_covnet_model\\model.ckpt-1002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1002 into /tmp/mnist_covnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1.7618825, step = 1002\n",
      "INFO:tensorflow:global_step/sec: 48.3765\n",
      "INFO:tensorflow:loss = 1.5846971, step = 1102 (2.069 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.2172\n",
      "INFO:tensorflow:loss = 1.3891101, step = 1202 (1.952 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4261\n",
      "INFO:tensorflow:loss = 1.2131184, step = 1302 (1.946 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3381\n",
      "INFO:tensorflow:loss = 1.0572499, step = 1402 (1.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3549\n",
      "INFO:tensorflow:loss = 1.0136278, step = 1502 (1.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3734\n",
      "INFO:tensorflow:loss = 0.90052795, step = 1602 (1.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.4452\n",
      "INFO:tensorflow:loss = 0.68529606, step = 1702 (1.944 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.3855\n",
      "INFO:tensorflow:loss = 0.8932968, step = 1802 (1.947 sec)\n",
      "INFO:tensorflow:global_step/sec: 51.2293\n",
      "INFO:tensorflow:loss = 0.70059454, step = 1902 (1.950 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2002 into /tmp/mnist_covnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.51310873.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x2049c995eb8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now without logging each step, train the model longer but still in a reasonable time.\n",
    "# Increasing number of steps to like 20,000 would increase accuracy\n",
    "\n",
    "mnist_classifier.train(input_fn = train_input_fn, steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-02-01-00:46:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_covnet_model\\model.ckpt-2002\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-02-01-00:46:32\n",
      "INFO:tensorflow:Saving dict for global step 2002: accuracy = 0.8495, global_step = 2002, loss = 0.5839219\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2002: /tmp/mnist_covnet_model\\model.ckpt-2002\n",
      "{'accuracy': 0.8495, 'loss': 0.5839219, 'global_step': 2002}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
