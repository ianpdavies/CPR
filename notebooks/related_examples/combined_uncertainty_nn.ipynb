{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: https://github.com/hutec/UncertaintyNN/blob/master/notebooks/MNIST%20Training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\") # go to parent dir to allow imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5a7eb2d6bcd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "from models import mnist_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Extracting ../data/MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# from models import mnist_model\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from scipy.stats import bernoulli\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../data/MNIST-data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(x) for x in range(10)]\n",
    "\n",
    "def show(img):\n",
    "    \"\"\"Displays single mnist digit\"\"\"\n",
    "    plt.imshow(img.reshape([28, 28]), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "def show_with_var(img, prob, var):\n",
    "    \"\"\"Display single mnist digit next to the variance per class\"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10,5))\n",
    "    axs[0].imshow(img.reshape([28, 28]))\n",
    "    axs[1].bar(labels, prob)\n",
    "    axs[2].bar(labels, var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Dropout model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mnist_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-836caec28c9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdropout_rate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_cnn_mnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0monehot_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_passes=50\n",
    "dropout_rate=0.3\n",
    "learning_rate=1e-4\n",
    "epochs=20000\n",
    "display_step=2000\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../data/MNIST-data\", one_hot=True)\n",
    "\n",
    "x_data = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_data = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "dropout_rate_data = tf.placeholder(tf.float32)\n",
    "\n",
    "logits, class_prob = mnist_model.dropout_cnn_mnist_model(x_data, dropout_rate_data)\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=y_data, logits=logits)\n",
    "correct_prediction = tf.equal(tf.argmax(class_prob, 1), tf.argmax(y_data, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "\n",
    "    sess.run(train_step, feed_dict={x_data: batch[0], y_data: batch[1], dropout_rate_data: 0.5})\n",
    "\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        # cur_loss = sess.run(loss, feed_dict={x_data: batch[0],\n",
    "        #                                      y_data: batch[1]})\n",
    "        train_accuracy = sess.run(accuracy, feed_dict={\n",
    "            x_data: batch[0], y_data: batch[1], dropout_rate_data:0}) # no dropout on single accuracy\n",
    "        print(\"Accuracy: {}\".format(train_accuracy))\n",
    "        \n",
    "        # tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "variable_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"mnist\")[:8]\n",
    "saver = tf.train.Saver(var_list=variable_list)\n",
    "save_path = saver.save(sess, \"mnist_dropout.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Bootstrap model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../data/MNIST-data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mnist_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-564488ee1de1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdropout_rate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mheads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout_cnn_mnist_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout_rate_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_model' is not defined"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_heads = 5\n",
    "dropout_rate=0.3\n",
    "learning_rate=1e-4\n",
    "epochs=20000\n",
    "display_step=50\n",
    "\n",
    "mnist = input_data.read_data_sets(\"../data/MNIST-data\", one_hot=True)\n",
    "\n",
    "x_data = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_data = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "dropout_rate_data = tf.placeholder(tf.float32)\n",
    "\n",
    "heads = mnist_model.dropout_cnn_mnist_model(x_data, dropout_rate_data)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_per_head = []\n",
    "train_per_head = []\n",
    "accuracy_per_head = []\n",
    "for head in heads:\n",
    "    logits, class_prob = head  # unpack\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=y_data, logits=logits)\n",
    "    loss_per_head.append(loss)\n",
    "    train_per_head.append(optimizer.minimize(loss))\n",
    "    \n",
    "    correct_prediction = tf.equal(tf.argmax(class_prob, 1), tf.argmax(y_data, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    accuracy_per_head.append(accuracy)\n",
    "    \n",
    "#loss = tf.losses.softmax_cross_entropy(onehot_labels=y_data, logits=logits)\n",
    "#correct_prediction = tf.equal(tf.argmax(class_prob, 1), tf.argmax(y_data, 1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "rv = bernoulli(0.5)\n",
    "mask = rv.rvs(size=(n_heads, 50)) # x is the length\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(init)\n",
    "\n",
    "# masked is defined only for the most recent batch\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    batch = mnist.train.next_batch(50)\n",
    "    x = batch[0]\n",
    "    y = batch[1]\n",
    "    \n",
    "    for i, train_step in enumerate(train_per_head):\n",
    "        masked_x = x[mask[i] == 1, :]\n",
    "        masked_y = y[mask[i] == 1, :]\n",
    "        sess.run(train_step, feed_dict={x_data: masked_x, y_data: masked_y, dropout_rate_data: 0.5})\n",
    "    \n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        for i, a in enumerate(accuracy_per_head):\n",
    "            cur_acc = sess.run(a, feed_dict={x_data: x, y_data: y, dropout_rate_data: 0.5})\n",
    "            print(\"Head {}: Accuracy: {}\".format(i, cur_acc))\n",
    "\n",
    "        #train_accuracy = sess.run(accuracy, feed_dict={\n",
    "        #    x_data: batch[0], y_data: batch[1], dropout_rate_data:0}) # no dropout on single accuracy\n",
    "        #print(\"Accuracy: {}\".format(train_accuracy))\n",
    "        \n",
    "        # tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES)\n",
    "    variable_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"mnist\")[:8]\n",
    "    saver = tf.train.Saver(var_list=variable_list)\n",
    "    save_path = saver.save(sess, \"mnist_bootstrap.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_model(x, dropout_rate):\n",
    "    \"\"\"\n",
    "    Model that combines aleatoric and epistemic uncertainty.\n",
    "    Based on the \"What uncertainties do we need\" paper by Kendall.\n",
    "    Works for simple 2D data.\n",
    "    :param x: Input feature x\n",
    "    :param dropout_rate:\n",
    "    :return: prediction, log(sigma^2)\n",
    "    \"\"\"\n",
    "\n",
    "    # with tf.device(\"/gpu:0\"):\n",
    "    keep_prob = 1 - dropout_rate\n",
    "\n",
    "    fc1 = tf.layers.dense(inputs=x, units=50, activation=tf.nn.relu)\n",
    "    fc1 = tf.nn.dropout(fc1, keep_prob)\n",
    "\n",
    "    fc2 = tf.layers.dense(inputs=fc1, units=50, activation=tf.nn.relu)\n",
    "    fc2 = tf.nn.dropout(fc2, keep_prob)\n",
    "\n",
    "    # Output layers has predictive mean and variance sigma^2\n",
    "    output_layer = tf.layers.dense(fc2, units=2)\n",
    "\n",
    "    predictions = tf.expand_dims(output_layer[:, 0], -1)\n",
    "    log_variance = tf.expand_dims(output_layer[:, 1], -1)\n",
    "\n",
    "    return predictions, log_variance\n",
    "\n",
    "def dropout_cnn_mnist_model(x, dropout_rate, reuse=False):\n",
    "    \"\"\"\n",
    "    Builds a simple CNN MNIST classifier with dropout after every layer\n",
    "    that contains learned weights.\n",
    "    :param x:\n",
    "    :param reuse: True if reusing layer scopes\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    with tf.variable_scope(\"mnist_model\"):\n",
    "        # Convolutional Layer #1\n",
    "        with tf.variable_scope(\"conv1\", reuse=reuse):\n",
    "            conv1 = tf.layers.conv2d(\n",
    "                inputs=input_layer,\n",
    "                filters=32,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout1 = tf.layers.dropout(conv1, dropout_rate, training=True)\n",
    "\n",
    "        # Pooling Layer #1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=dropout1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Convolutional Layer #2 and Pooling Layer #2\n",
    "        with tf.variable_scope(\"conv2\", reuse=reuse):\n",
    "            conv2 = tf.layers.conv2d(\n",
    "                inputs=pool1,\n",
    "                filters=64,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout2 = tf.layers.dropout(conv2, dropout_rate, training=True)\n",
    "\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=dropout2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Dense Layer\n",
    "        with tf.variable_scope(\"fc1\", reuse=reuse):\n",
    "            pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "            dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "            dropout3 = tf.layers.dropout(dense, dropout_rate, training=True)\n",
    "\n",
    "        # Logits Layer\n",
    "        with tf.variable_scope(\"fc2\", reuse=reuse):\n",
    "            logits = tf.layers.dense(inputs=dropout3, units=10)\n",
    "            class_prob = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "\n",
    "    return logits, class_prob\n",
    "\n",
    "\n",
    "def combined_cnn_mnist_model(x, dropout_rate, reuse=False):\n",
    "    \"\"\"\n",
    "    Model learns to predict aleatoric uncertainty as output\n",
    "    \"\"\"\n",
    "\n",
    "    input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    with tf.variable_scope(\"mnist_model\"):\n",
    "        # Convolutional Layer #1\n",
    "        with tf.variable_scope(\"conv1\", reuse=reuse):\n",
    "            conv1 = tf.layers.conv2d(\n",
    "                inputs=input_layer,\n",
    "                filters=32,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout1 = tf.layers.dropout(conv1, dropout_rate, training=True)\n",
    "\n",
    "        # Pooling Layer #1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=dropout1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Convolutional Layer #2 and Pooling Layer #2\n",
    "        with tf.variable_scope(\"conv2\", reuse=reuse):\n",
    "            conv2 = tf.layers.conv2d(\n",
    "                inputs=pool1,\n",
    "                filters=64,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout2 = tf.layers.dropout(conv2, dropout_rate, training=True)\n",
    "\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=dropout2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Dense Layer\n",
    "        with tf.variable_scope(\"fc1\", reuse=reuse):\n",
    "            pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "            dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "            dropout3 = tf.layers.dropout(dense, dropout_rate, training=True)\n",
    "\n",
    "        # Logits Layer\n",
    "        with tf.variable_scope(\"fc2\", reuse=reuse):\n",
    "            logits = tf.layers.dense(inputs=dropout3, units=10)\n",
    "            class_prob = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "\n",
    "        # uncertainty layer\n",
    "        with tf.variable_scope(\"fc2_2\", reuse=reuse):\n",
    "            uncertainty = tf.layers.dense(inputs=dropout3, units=10)\n",
    "\n",
    "    return logits, class_prob, uncertainty\n",
    "\n",
    "def bootstrap_cnn_mnist_model(x, dropout_rate, n_heads=5, reuse=False):\n",
    "    \"\"\"\n",
    "    Last FC-Layer has n heads.\n",
    "    \"\"\"\n",
    "    input_layer = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "    heads = []\n",
    "    with tf.variable_scope(\"mnist_model\"):\n",
    "        # Convolutional Layer #1\n",
    "        with tf.variable_scope(\"conv1\", reuse=reuse):\n",
    "            conv1 = tf.layers.conv2d(\n",
    "                inputs=input_layer,\n",
    "                filters=32,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout1 = tf.layers.dropout(conv1, dropout_rate, training=True)\n",
    "\n",
    "        # Pooling Layer #1\n",
    "        pool1 = tf.layers.max_pooling2d(inputs=dropout1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Convolutional Layer #2 and Pooling Layer #2\n",
    "        with tf.variable_scope(\"conv2\", reuse=reuse):\n",
    "            conv2 = tf.layers.conv2d(\n",
    "                inputs=pool1,\n",
    "                filters=64,\n",
    "                kernel_size=[5, 5],\n",
    "                padding=\"same\",\n",
    "                activation=tf.nn.relu)\n",
    "            dropout2 = tf.layers.dropout(conv2, dropout_rate, training=True)\n",
    "\n",
    "        pool2 = tf.layers.max_pooling2d(inputs=dropout2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "        # Dense Layer\n",
    "        with tf.variable_scope(\"fc1\", reuse=reuse):\n",
    "            pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "            dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "            dropout3 = tf.layers.dropout(dense, dropout_rate, training=True)\n",
    "\n",
    "        # Logits Layer + HEAD layer\n",
    "        with tf.variable_scope(\"fc2\", reuse=reuse):\n",
    "            for i in range(n_heads):\n",
    "                logits = tf.layers.dense(inputs=dropout3, units=10)\n",
    "                class_prob = tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "\n",
    "                heads.append([logits, class_prob])\n",
    "                # heads.append({\n",
    "                #     \"logits\": logits,\n",
    "                #     \"class_prob:\" class_prob\n",
    "                # })\n",
    "\n",
    "\n",
    "    return heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_training(x_truth, y_truth, dropout, learning_rate, epochs, display_step=2000):\n",
    "    \"\"\"\n",
    "    Generic training of a Combined (uncertainty) network for 2D data.\n",
    "    :param x_truth: training samples x\n",
    "    :param y_truth: training samples y / label\n",
    "    :param dropout:\n",
    "    :param learning_rate:\n",
    "    :param epochs:\n",
    "    :param display_step:\n",
    "    :return: session, x_placeholder, dropout_placeholder\n",
    "    \"\"\"\n",
    "    tf.reset_default_graph()\n",
    "    x_placeholder = tf.placeholder(tf.float32, [None, 1])\n",
    "    y_placeholder = tf.placeholder(tf.float32, [None, 1])\n",
    "    dropout_placeholder = tf.placeholder(tf.float32)\n",
    "\n",
    "    prediction, log_variance = combined_model(x_placeholder, dropout_placeholder)\n",
    "\n",
    "    tf.add_to_collection(\"prediction\", prediction)\n",
    "    tf.add_to_collection(\"log_variance\", log_variance)\n",
    "\n",
    "    loss = tf.reduce_sum(0.5 * tf.exp(-1 * log_variance) * tf.square(tf.abs(y_placeholder - prediction))\n",
    "                         + 0.5 * log_variance)\n",
    "\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    train = optimizer.minimize(loss)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        feed_dict = {x_placeholder: x_truth.reshape([-1, 1]),\n",
    "                     y_placeholder: y_truth.reshape([-1, 1]),\n",
    "                     dropout_placeholder: dropout}\n",
    "\n",
    "        sess.run(train, feed_dict=feed_dict)\n",
    "\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch {}\".format(epoch))\n",
    "            current_loss = sess.run(loss, feed_dict=feed_dict)\n",
    "            print(\"Loss {}\".format(current_loss))\n",
    "            print(\"================\")\n",
    "\n",
    "    print(\"Training done\")\n",
    "\n",
    "    return sess, x_placeholder, dropout_placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Combined CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grafik.png](attachment:grafik.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Accuracy: 113.98668670654297\n",
      "Epoch 2000\n",
      "Accuracy: 11.5392427444458\n",
      "Epoch 4000\n",
      "Accuracy: 3.322525978088379\n",
      "Epoch 6000\n",
      "Accuracy: 4.7057671546936035\n",
      "Epoch 8000\n",
      "Accuracy: 4.25748348236084\n",
      "Epoch 10000\n",
      "Accuracy: 3.4332520961761475\n",
      "Epoch 12000\n",
      "Accuracy: 3.266512632369995\n",
      "Epoch 14000\n",
      "Accuracy: 1.0480328798294067\n",
      "Epoch 16000\n",
      "Accuracy: 0.7044422626495361\n",
      "Epoch 18000\n",
      "Accuracy: 3.8238542079925537\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "dropout_rate=0.3\n",
    "learning_rate=1e-4\n",
    "epochs=20000\n",
    "display_step=2000\n",
    "T = 20 # Number of Monte Carlo Integration steps for adding noise to the uncertainty\n",
    "\n",
    "x_data = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y_data = tf.placeholder(tf.float32, shape=[None, 10])   # only contains correct label, shape[None] \n",
    "dropout_rate_data = tf.placeholder(tf.float32)\n",
    "\n",
    "# uncertainty (sigma) is per logit\n",
    "logits, props, uncertainty = combined_cnn_mnist_model(x_data, dropout_rate_data)\n",
    "\n",
    "batch_size = tf.shape(logits)[0]\n",
    "\n",
    "eps = tf.random_normal([batch_size, T, 10])\n",
    "logits_T = tf.tile(tf.reshape(logits, [-1, 1, 10]), [1, T, 1])\n",
    "uncertainty_T = tf.tile(tf.reshape(uncertainty, [-1, 1, 10]), [1, T, 1])\n",
    "\n",
    "\n",
    "# Combined loss from What Uncertainties do we need\n",
    "xi = logits_T + uncertainty_T * eps\n",
    "y = tf.tile(tf.reshape(y_data, [-1, 1, 10]), [1, T, 1])\n",
    "onehot_logit = tf.reduce_sum(xi * y, axis=2)\n",
    "loss = tf.reduce_sum(-tf.log(tf.reduce_mean(tf.exp(onehot_logit - tf.reduce_logsumexp(xi, axis=2)), axis=1)))\n",
    "\n",
    "# Aleatoric Uncertainty loss\n",
    "#loss = tf.losses.softmax_cross_entropy(onehot_labels=y, logits=xi)\n",
    "\n",
    "#l = onehot_logit - tf.reduce_logsumexp(xi, axis=2)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    sess.run(train_step, feed_dict={x_data: batch[0], y_data: batch[1], dropout_rate_data: 0.5})\n",
    "\n",
    "    if epoch % display_step == 0:\n",
    "        print(\"Epoch {}\".format(epoch))\n",
    "        # cur_loss = sess.run(loss, feed_dict={x_data: batch[0],\n",
    "        #                                      y_data: batch[1]})\n",
    "        train_accuracy = sess.run(loss, feed_dict={\n",
    "            x_data: batch[0], y_data: batch[1], dropout_rate_data:0}) # no dropout on single accuracy\n",
    "        print(\"Accuracy: {}\".format(train_accuracy))\n",
    "        \n",
    "variable_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"mnist\")[:10]\n",
    "saver = tf.train.Saver(var_list=variable_list)\n",
    "save_path = saver.save(sess, \"mnist_combined.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\ipdavies\\CPR\\notebooks\\adv_img.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8d2a9d44ed93>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0madv_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"adv_img.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"img.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mticks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    269\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\ipdavies\\CPR\\notebooks\\adv_img.png'"
     ]
    }
   ],
   "source": [
    "adv_img = imageio.imread(\"adv_img.png\").reshape(784)\n",
    "img = imageio.imread(\"img.png\").reshape(784)\n",
    "ticks = [str(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from mnist_combined.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'entropies' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-421ace54371d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.03\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m \u001b[0mcombined_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[0mcombined_inference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madv_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-421ace54371d>\u001b[0m in \u001b[0;36mcombined_inference\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     24\u001b[0m                                                                          dropout_rate_data: 0.5})[0])\n\u001b[0;32m     25\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Adversarial Attack in Combined Network - {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mticks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0maxs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Var\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'entropies' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "dropout_rate=0.3\n",
    "\n",
    "x_data = tf.placeholder(tf.float32, 784)\n",
    "dropout_rate_data = tf.placeholder(tf.float32)\n",
    "\n",
    "# uncertainty (sigma) is per logit\n",
    "logits,props, uncertainty = combined_cnn_mnist_model(x_data, dropout_rate_data)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "sess.run(init)\n",
    "\n",
    "variable_list = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=\"mnist\")[:10]\n",
    "saver = tf.train.Saver(var_list=variable_list)\n",
    "saver.restore(sess, \"mnist_combined.ckpt\")\n",
    "\n",
    "def combined_inference(img):\n",
    "    uncertainties = []\n",
    "    ys = []\n",
    "    for i in range(50):\n",
    "        ys.append(sess.run(props, feed_dict={x_data: img, dropout_rate_data: 0.5})[0])\n",
    "        uncertainties.append(sess.run(tf.square(uncertainty), feed_dict={x_data: img,\n",
    "                                                                         dropout_rate_data: 0.5})[0])\n",
    "    fig, axs = plt.subplots(2, 3, figsize=[15, 5])\n",
    "    fig.suptitle(\"Adversarial Attack in Combined Network - {}\".format(np.mean(entropies)), fontsize=16)\n",
    "    axs[0, 0].bar(ticks, np.array(ys).var(axis=0))\n",
    "    axs[0, 0].set_title(\"Var\")\n",
    "    axs[0, 1].bar(ticks, np.array(ys).mean(axis=0))\n",
    "    axs[0, 1].set_title(\"Mean\")\n",
    "    axs[0, 2].imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "    \n",
    "#    fig, axs = plt.subplots(1, 3, figsize=[15, 5])\n",
    "    axs[1, 0].bar(ticks, np.array(uncertainties).var(axis=0))\n",
    "    axs[1, 0].set_title(\"Uncertainty Variance\")\n",
    "    axs[1, 1].bar(ticks, np.array(uncertainties).mean(axis=0))\n",
    "    axs[1, 1].set_title(\"Uncertainty Mean\")\n",
    "    axs[1, 2].imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    \n",
    "combined_inference(np.random.uniform(size=(784)))\n",
    "combined_inference(adv_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation and display wrongly classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6d94edf0ffc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     pred_y_multipass = sess.run(class_prob, feed_dict={\n\u001b[0m\u001b[0;32m     13\u001b[0m         x_data: x_batch_multipass, dropout_rate_data: 0.5})\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'class_prob' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "\n",
    "results = []\n",
    "for i in range(10):\n",
    "    x_batch, y_batch = mnist.test.next_batch(100)\n",
    "    # Use tile instead of repeat, because np.repeat flattens results\n",
    "    x_batch_multipass = np.tile(x_batch, n_passes).reshape(-1, 784)\n",
    "\n",
    "\n",
    "    pred_y_multipass = sess.run(class_prob, feed_dict={\n",
    "        x_data: x_batch_multipass, dropout_rate_data: 0.5})\n",
    "\n",
    "    pred_y_multipass = pred_y_multipass.reshape(-1, n_passes, 10)\n",
    "    pred_y_mean = pred_y_multipass.mean(axis=1)\n",
    "    pred_y_var = pred_y_multipass.var(axis=1)\n",
    "\n",
    "    acc = sess.run(accuracy, feed_dict={\n",
    "        x_data: x_batch, y_data:y_batch, dropout_rate_data: 0.5})\n",
    "    \n",
    "    wrong_idx = np.where(np.equal(np.argmax(y_batch, axis=1), np.argmax(pred_y_mean, axis=1)) == False)[0]\n",
    "    if len(wrong_idx) > 0:\n",
    "        for idx in np.nditer(wrong_idx):\n",
    "            print(\"Correct: \" + str(np.argmax(y_batch[idx])))\n",
    "            print(\"Predicted: \" + str(np.argmax(pred_y_mean[idx])))\n",
    "            show_with_var(x_batch[idx], pred_y_mean[idx], pred_y_var[idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
