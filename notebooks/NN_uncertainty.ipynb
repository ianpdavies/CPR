{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "import time\n",
    "from zipfile import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from CPR.configs import data_path\n",
    "from CPR.utils import tif_stacker, cloud_generator, preprocessing, train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'CPR.utils' from '..\\\\CPR\\\\utils.py'>"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(CPR.utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stack.tif\" already exists for 4115_LC08_021033_20131227_test\n",
      "Cloud image already exists for 4115_LC08_021033_20131227_test\n"
     ]
    }
   ],
   "source": [
    "# Order in which features should be stacked to create stacked tif\n",
    "feat_list_new = ['aspect','curve', 'developed', 'GSW_distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "img_list = ['4115_LC08_021033_20131227_test']\n",
    "\n",
    "for j, img in enumerate(img_list):\n",
    "    #  Stack all the flood imagery\n",
    "    tif_stacker(data_path, img, feat_list_new, overwrite=False)\n",
    "    cloud_generator(img, data_path, overwrite=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctl = [20]\n",
    "data_train, data_vector_train, data_ind_train = preprocessing(data_path, img, pctl, gaps=False)\n",
    "training_data, validation_data = train_val(data_vector_train, holdout=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NN with MC Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = training_data[:,0:14], training_data[:,14]\n",
    "X_val, y_val = validation_data[:,0:14], validation_data[:,14]\n",
    "\n",
    "pctl = 20\n",
    "INPUT_DIMS = X_train.shape[1:]\n",
    "INPUT_SIZE = X_train.shape[0]\n",
    "BATCH_SIZE = 2000\n",
    "EPOCHS = 100\n",
    "DROPOUT_RATE = 0.3\n",
    "HOLDOUT = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_28 (Lambda)           (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 29)                435       \n",
      "_________________________________________________________________\n",
      "lambda_29 (Lambda)           (None, 29)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 917\n",
      "Trainable params: 917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 221269 samples, validate on 94829 samples\n",
      "Epoch 1/100\n",
      "221269/221269 [==============================] - 1s 7us/sample - loss: 0.3132 - sparse_categorical_accuracy: 0.9179 - recall_m: 1.0000 - val_loss: 0.0656 - val_sparse_categorical_accuracy: 0.9952 - val_recall_m: 0.9792\n",
      "Epoch 2/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1619 - sparse_categorical_accuracy: 0.9448 - recall_m: 1.0000 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9946 - val_recall_m: 1.0000\n",
      "Epoch 3/100\n",
      "221269/221269 [==============================] - 1s 4us/sample - loss: 0.1474 - sparse_categorical_accuracy: 0.9475 - recall_m: 1.0000 - val_loss: 0.0311 - val_sparse_categorical_accuracy: 0.9955 - val_recall_m: 1.0000\n",
      "Epoch 4/100\n",
      "221269/221269 [==============================] - 1s 4us/sample - loss: 0.1418 - sparse_categorical_accuracy: 0.9485 - recall_m: 1.0000 - val_loss: 0.0290 - val_sparse_categorical_accuracy: 0.9957 - val_recall_m: 1.0000\n",
      "Epoch 5/100\n",
      "221269/221269 [==============================] - 1s 4us/sample - loss: 0.1364 - sparse_categorical_accuracy: 0.9500 - recall_m: 1.0000 - val_loss: 0.0266 - val_sparse_categorical_accuracy: 0.9964 - val_recall_m: 0.9792\n",
      "Epoch 6/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1349 - sparse_categorical_accuracy: 0.9496 - recall_m: 1.0000 - val_loss: 0.0269 - val_sparse_categorical_accuracy: 0.9963 - val_recall_m: 1.0000\n",
      "Epoch 7/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1312 - sparse_categorical_accuracy: 0.9505 - recall_m: 1.0000 - val_loss: 0.0243 - val_sparse_categorical_accuracy: 0.9967 - val_recall_m: 1.0000\n",
      "Epoch 8/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1294 - sparse_categorical_accuracy: 0.9509 - recall_m: 1.0000 - val_loss: 0.0240 - val_sparse_categorical_accuracy: 0.9964 - val_recall_m: 0.9792\n",
      "Epoch 9/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1272 - sparse_categorical_accuracy: 0.9512 - recall_m: 1.0000 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9965 - val_recall_m: 1.0000\n",
      "Epoch 10/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1255 - sparse_categorical_accuracy: 0.9513 - recall_m: 1.0000 - val_loss: 0.0226 - val_sparse_categorical_accuracy: 0.9967 - val_recall_m: 0.9583\n",
      "Epoch 11/100\n",
      "221269/221269 [==============================] - 1s 5us/sample - loss: 0.1243 - sparse_categorical_accuracy: 0.9513 - recall_m: 1.0000 - val_loss: 0.0246 - val_sparse_categorical_accuracy: 0.9962 - val_recall_m: 1.0000\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8357ec710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Functional API\n",
    "## def get_NN_MCD():\n",
    "#     inputs = tf.keras.layers.Input(shape=(input_dims,))\n",
    "#     x = tf.keras.layers.Dropout(rate=dropout_rate)(inputs, training=True)\n",
    "#     x = tf.keras.layers.Dense(units=29, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(rate=dropout_rate)(x, training=True)  \n",
    "#     x = tf.keras.layers.Dense(units=15, activation='relu')(x)\n",
    "#     outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='sparse_categorical_crossentropy',      \n",
    "# #                   metrics=[tf.keras.metrics.Recall()])\n",
    "# #                   metrics=[tf.keras.metrics.F1()])\n",
    "#                   metrics=['sparse_categorical_accuracy'])\n",
    "#     return model\n",
    "\n",
    "# Using Sequential API\n",
    "def get_NN_MCD():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=INPUT_DIMS)),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=DROPOUT_RATE))),\n",
    "    model.add(tf.keras.layers.Dense(units=29,\n",
    "                                    activation='relu')),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=DROPOUT_RATE))),\n",
    "    model.add(tf.keras.layers.Dense(units=15,\n",
    "                                    activation='relu')),\n",
    "#     model.add(tf.keras.layers.Dropout(rate=dropout_rate)(training=True)),\n",
    "#     model.add(tf.keras.layers.Flatten()),\n",
    "    model.add(tf.keras.layers.Dense(2,\n",
    "                                    activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',      \n",
    "#                   metrics=[tf.keras.metrics.Recall()])\n",
    "#                   metrics=[tf.keras.metrics.F1()])\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model\n",
    "\n",
    "# Can maybe use callbacks to get output? https://keras.io/callbacks/\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.5, patience=10, verbose=1)\n",
    "\n",
    "NN_MCD = get_NN_MCD()\n",
    "NN_MCD.summary()\n",
    "NN_MCD.fit(X_train, y_train,\n",
    "           batch_size = BATCH_SIZE,\n",
    "           epochs= EPOCHS,\n",
    "           verbose = 1,\n",
    "           validation_data = (X_val, y_val),\n",
    "           callbacks = [es],\n",
    "           use_multiprocessing = True)\n",
    "# model_path = data_path / 'models' / 'cnn_vary_clouds' / img / '{0}'.format(img+'_clouds_'+str(pctl)+'.h5')\n",
    "# NN_MCD.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28051 samples, validate on 12022 samples\n",
      "Epoch 1/4\n",
      "28051/28051 [==============================] - 2s 57us/sample - loss: 0.3271 - acc: 0.9390 - val_loss: 0.1727 - val_acc: 0.9939\n",
      "Epoch 2/4\n",
      "28051/28051 [==============================] - 0s 11us/sample - loss: 0.1397 - acc: 0.9880 - val_loss: 0.0869 - val_acc: 0.9949\n",
      "Epoch 3/4\n",
      "28051/28051 [==============================] - 0s 12us/sample - loss: 0.0906 - acc: 0.9887 - val_loss: 0.0559 - val_acc: 0.9953\n",
      "Epoch 4/4\n",
      "28051/28051 [==============================] - 0s 10us/sample - loss: 0.0702 - acc: 0.9898 - val_loss: 0.0449 - val_acc: 0.9956\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9921927917008306"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is from my S.O. question - the solution doesn't seem to produce the same output as \n",
    "# is produced during training though\n",
    "\n",
    "# def get_model(training=None):\n",
    "#     inputs = tf.keras.layers.Input(shape=(input_dims,))\n",
    "#     x = tf.keras.layers.Dropout(rate=dropout_rate)(inputs, training=training)\n",
    "#     x = tf.keras.layers.Dense(units=29, activation='relu')(x)\n",
    "#     x = tf.keras.layers.Dropout(rate=dropout_rate)(x, training=training)  \n",
    "#     x = tf.keras.layers.Dense(units=15, activation='relu')(x)\n",
    "#     outputs = tf.keras.layers.Dense(2, activation='softmax')(x)\n",
    "#     model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "#     model.compile(optimizer='adam',\n",
    "#                   loss='sparse_categorical_crossentropy',      \n",
    "# #                   metrics=['sparse_categorical_accuracy'])\n",
    "#                   metrics=['accuracy'])                  \n",
    "#     return model\n",
    "\n",
    "# # build a model with dropout layers active in both training and test phases\n",
    "# myModel = get_model(training=True)\n",
    "# # train the model\n",
    "# myModel.fit(X_train, y_train,\n",
    "#             batch_size = BATCH_SIZE,\n",
    "#             epochs= EPOCHS,\n",
    "#             verbose = 1,\n",
    "#             validation_data = (X_val, y_val),\n",
    "#             use_multiprocessing = False)\n",
    "\n",
    "# # build a clone of the model with dropouts deactivated in test phase\n",
    "# myTestModel = get_model(training=False)  # note: the `training` is `None` by default\n",
    "# # transfer the weights from the trained model to this model\n",
    "# myTestModel.set_weights(myModel.get_weights())\n",
    "# # use the new model in test phase; the dropouts would not be active\n",
    "# preds = myTestModel.predict(X_train)\n",
    "# sklearn.metrics.accuracy_score(y_train, np.argmax(preds, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing NN on cloud gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctl = [20]\n",
    "data_gaps, data_vector_gaps, data_ind_gaps = preprocessing(data_path, img, pctl, gaps=True)\n",
    "\n",
    "X_test, y_test = data_vector_gaps[:,0:14], data_vector_gaps[:,14]\n",
    "\n",
    "def predict_with_uncertainty(model, X):\n",
    "    preds = []\n",
    "    for i in range(mc_passes):\n",
    "        preds.append(model.predict(X))\n",
    "    preds = np.array(preds)\n",
    "    means = np.mean(preds, axis=0)\n",
    "    variances = np.var(preds, axis=0)\n",
    "    stds = np.std(preds, axis=0)\n",
    "    pred = np.argmax(means, axis=1)\n",
    "    \n",
    "#     return pred, preds, means, variances, stds\n",
    "    return pred, variances\n",
    "\n",
    "mc_passes = 100\n",
    "# pred, preds, means, variances, stds = predict_with_uncertainty(NN_MCD, X_test)\n",
    "pred, variances = predict_with_uncertainty(NN_MCD, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how many MC samples predicted flooding?\n",
    "# (# times the prob of flooding > 0.5) / # samples\n",
    "# The color bar should be more saturated in the middle to highlight greater\n",
    "# uncertainty, and lighter towards 0% and 100%.\n",
    "\n",
    "# flood = 0\n",
    "# flood += "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d4658f7d30>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reshape gaps back into image\n",
    "stack_path = data_path / 'images' / img / 'stack' / 'stack.tif'\n",
    "with rasterio.open(str(stack_path), 'r') as ds:\n",
    "        shape = ds.read(1).shape # Shape of full original image\n",
    "        arr_empty = np.zeros(shape) # Create empty array with this shape\n",
    "        arr_empty[:] = np.nan # Convert all zeroes to NaN\n",
    "        var_img = arr_empty\n",
    "        rows, cols = zip(data_ind_gaps)\n",
    "        var_img[rows, cols] = variances[:,0]\n",
    "plt.imshow(var_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NN on multiple images and cloud covers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_MCD():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=INPUT_DIMS)),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=DROPOUT_RATE))),\n",
    "    model.add(tf.keras.layers.Dense(units=29,\n",
    "                                    activation='relu')),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=DROPOUT_RATE))),\n",
    "    model.add(tf.keras.layers.Dense(units=15,\n",
    "                                    activation='relu')),\n",
    "#     model.add(tf.keras.layers.Dropout(rate=dropout_rate)(training=True)),\n",
    "#     model.add(tf.keras.layers.Flatten()),\n",
    "    model.add(tf.keras.layers.Dense(2,\n",
    "                                    activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',      \n",
    "#                   metrics=[tf.keras.metrics.Recall()])\n",
    "#                   metrics=[tf.keras.metrics.F1()])\n",
    "                  metrics=['sparse_categorical_accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stack.tif\" already exists for 4101_LC08_027038_20131103_1\n",
      "Cloud image already exists for 4101_LC08_027038_20131103_1\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 8006443 samples, validate on 3431333 samples\n",
      "Epoch 1/100\n",
      "8006443/8006443 - 26s - loss: 0.0821 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.0305 - val_sparse_categorical_accuracy: 0.9964\n",
      "Epoch 2/100\n",
      "8006443/8006443 - 24s - loss: 0.0433 - sparse_categorical_accuracy: 0.9874 - val_loss: 0.0470 - val_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 3/100\n",
      "8006443/8006443 - 24s - loss: 0.0391 - sparse_categorical_accuracy: 0.9883 - val_loss: 0.0864 - val_sparse_categorical_accuracy: 0.9708\n",
      "Epoch 4/100\n",
      "8006443/8006443 - 24s - loss: 0.0373 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.1515 - val_sparse_categorical_accuracy: 0.9267\n",
      "Epoch 5/100\n",
      "8006443/8006443 - 23s - loss: 0.0364 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.2036 - val_sparse_categorical_accuracy: 0.8977\n",
      "Epoch 6/100\n",
      "8006443/8006443 - 25s - loss: 0.0354 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.2312 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 7/100\n",
      "8006443/8006443 - 24s - loss: 0.0340 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.3119 - val_sparse_categorical_accuracy: 0.8338\n",
      "Epoch 8/100\n",
      "8006443/8006443 - 23s - loss: 0.0329 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.3035 - val_sparse_categorical_accuracy: 0.8305\n",
      "Epoch 9/100\n",
      "8006443/8006443 - 23s - loss: 0.0323 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.3035 - val_sparse_categorical_accuracy: 0.8221\n",
      "Epoch 10/100\n",
      "8006443/8006443 - 23s - loss: 0.0318 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.2999 - val_sparse_categorical_accuracy: 0.8200\n",
      "Epoch 11/100\n",
      "8006443/8006443 - 23s - loss: 0.0314 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.2785 - val_sparse_categorical_accuracy: 0.8264\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 7099955 samples, validate on 3042837 samples\n",
      "Epoch 1/100\n",
      "7099955/7099955 - 23s - loss: 0.0908 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.0367 - val_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 2/100\n",
      "7099955/7099955 - 21s - loss: 0.0438 - sparse_categorical_accuracy: 0.9870 - val_loss: 0.0490 - val_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 3/100\n",
      "7099955/7099955 - 22s - loss: 0.0396 - sparse_categorical_accuracy: 0.9879 - val_loss: 0.0555 - val_sparse_categorical_accuracy: 0.9910\n",
      "Epoch 4/100\n",
      "7099955/7099955 - 23s - loss: 0.0379 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0544 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 5/100\n",
      "7099955/7099955 - 22s - loss: 0.0367 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 6/100\n",
      "7099955/7099955 - 22s - loss: 0.0357 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0723 - val_sparse_categorical_accuracy: 0.9836\n",
      "Epoch 7/100\n",
      "7099955/7099955 - 23s - loss: 0.0349 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.1166 - val_sparse_categorical_accuracy: 0.9408\n",
      "Epoch 8/100\n",
      "7099955/7099955 - 22s - loss: 0.0340 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.2174 - val_sparse_categorical_accuracy: 0.8847\n",
      "Epoch 9/100\n",
      "7099955/7099955 - 22s - loss: 0.0335 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.3870 - val_sparse_categorical_accuracy: 0.8727\n",
      "Epoch 10/100\n",
      "7099955/7099955 - 22s - loss: 0.0331 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.5823 - val_sparse_categorical_accuracy: 0.8723\n",
      "Epoch 11/100\n",
      "7099955/7099955 - 22s - loss: 0.0330 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.7407 - val_sparse_categorical_accuracy: 0.8745\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 6197194 samples, validate on 2655940 samples\n",
      "Epoch 1/100\n",
      "6197194/6197194 - 19s - loss: 0.1111 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.0358 - val_sparse_categorical_accuracy: 0.9928\n",
      "Epoch 2/100\n",
      "6197194/6197194 - 18s - loss: 0.0418 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0368 - val_sparse_categorical_accuracy: 0.9927\n",
      "Epoch 3/100\n",
      "6197194/6197194 - 19s - loss: 0.0378 - sparse_categorical_accuracy: 0.9884 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9922\n",
      "Epoch 4/100\n",
      "6197194/6197194 - 18s - loss: 0.0355 - sparse_categorical_accuracy: 0.9889 - val_loss: 0.0406 - val_sparse_categorical_accuracy: 0.9907\n",
      "Epoch 5/100\n",
      "6197194/6197194 - 19s - loss: 0.0345 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.0422 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 6/100\n",
      "6197194/6197194 - 18s - loss: 0.0337 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.0443 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 7/100\n",
      "6197194/6197194 - 18s - loss: 0.0331 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0446 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 8/100\n",
      "6197194/6197194 - 18s - loss: 0.0326 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.0416 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 9/100\n",
      "6197194/6197194 - 18s - loss: 0.0321 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0415 - val_sparse_categorical_accuracy: 0.9867\n",
      "Epoch 10/100\n",
      "6197194/6197194 - 18s - loss: 0.0317 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0427 - val_sparse_categorical_accuracy: 0.9860\n",
      "Epoch 11/100\n",
      "6197194/6197194 - 18s - loss: 0.0313 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0433 - val_sparse_categorical_accuracy: 0.9857\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 5294438 samples, validate on 2269044 samples\n",
      "Epoch 1/100\n",
      "5294438/5294438 - 17s - loss: 0.1516 - sparse_categorical_accuracy: 0.9381 - val_loss: 0.0376 - val_sparse_categorical_accuracy: 0.9910\n",
      "Epoch 2/100\n",
      "5294438/5294438 - 17s - loss: 0.0404 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0390 - val_sparse_categorical_accuracy: 0.9912\n",
      "Epoch 3/100\n",
      "5294438/5294438 - 21s - loss: 0.0370 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.0388 - val_sparse_categorical_accuracy: 0.9912\n",
      "Epoch 4/100\n",
      "5294438/5294438 - 19s - loss: 0.0347 - sparse_categorical_accuracy: 0.9895 - val_loss: 0.0444 - val_sparse_categorical_accuracy: 0.9906\n",
      "Epoch 5/100\n",
      "5294438/5294438 - 18s - loss: 0.0331 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.0537 - val_sparse_categorical_accuracy: 0.9874\n",
      "Epoch 6/100\n",
      "5294438/5294438 - 18s - loss: 0.0323 - sparse_categorical_accuracy: 0.9900 - val_loss: 0.0588 - val_sparse_categorical_accuracy: 0.9841\n",
      "Epoch 7/100\n",
      "5294438/5294438 - 20s - loss: 0.0317 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9801\n",
      "Epoch 8/100\n",
      "5294438/5294438 - 19s - loss: 0.0314 - sparse_categorical_accuracy: 0.9902 - val_loss: 0.0644 - val_sparse_categorical_accuracy: 0.9787\n",
      "Epoch 9/100\n",
      "5294438/5294438 - 21s - loss: 0.0311 - sparse_categorical_accuracy: 0.9903 - val_loss: 0.0748 - val_sparse_categorical_accuracy: 0.9703\n",
      "Epoch 10/100\n",
      "5294438/5294438 - 19s - loss: 0.0309 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0794 - val_sparse_categorical_accuracy: 0.9681\n",
      "Epoch 11/100\n",
      "5294438/5294438 - 16s - loss: 0.0305 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0737 - val_sparse_categorical_accuracy: 0.9746\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 4406035 samples, validate on 1888301 samples\n",
      "Epoch 1/100\n",
      "4406035/4406035 - 14s - loss: 0.0976 - sparse_categorical_accuracy: 0.9687 - val_loss: 0.0425 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 2/100\n",
      "4406035/4406035 - 14s - loss: 0.0392 - sparse_categorical_accuracy: 0.9886 - val_loss: 0.0400 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 3/100\n",
      "4406035/4406035 - 14s - loss: 0.0356 - sparse_categorical_accuracy: 0.9894 - val_loss: 0.0396 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 4/100\n",
      "4406035/4406035 - 13s - loss: 0.0334 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0414 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 5/100\n",
      "4406035/4406035 - 13s - loss: 0.0321 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0427 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 6/100\n",
      "4406035/4406035 - 13s - loss: 0.0312 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0442 - val_sparse_categorical_accuracy: 0.9884\n",
      "Epoch 7/100\n",
      "4406035/4406035 - 14s - loss: 0.0307 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0446 - val_sparse_categorical_accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100\n",
      "4406035/4406035 - 14s - loss: 0.0303 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0464 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 9/100\n",
      "4406035/4406035 - 15s - loss: 0.0301 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0474 - val_sparse_categorical_accuracy: 0.9871\n",
      "Epoch 10/100\n",
      "4406035/4406035 - 14s - loss: 0.0296 - sparse_categorical_accuracy: 0.9908 - val_loss: 0.0469 - val_sparse_categorical_accuracy: 0.9875\n",
      "Epoch 11/100\n",
      "4406035/4406035 - 15s - loss: 0.0296 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0489 - val_sparse_categorical_accuracy: 0.9867\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 3521240 samples, validate on 1509102 samples\n",
      "Epoch 1/100\n",
      "3521240/3521240 - 12s - loss: 0.0765 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0434 - val_sparse_categorical_accuracy: 0.9879\n",
      "Epoch 2/100\n",
      "3521240/3521240 - 11s - loss: 0.0376 - sparse_categorical_accuracy: 0.9893 - val_loss: 0.0395 - val_sparse_categorical_accuracy: 0.9889\n",
      "Epoch 3/100\n",
      "3521240/3521240 - 12s - loss: 0.0344 - sparse_categorical_accuracy: 0.9898 - val_loss: 0.0387 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 4/100\n",
      "3521240/3521240 - 11s - loss: 0.0323 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0406 - val_sparse_categorical_accuracy: 0.9890\n",
      "Epoch 5/100\n",
      "3521240/3521240 - 11s - loss: 0.0308 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.0400 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 6/100\n",
      "3521240/3521240 - 11s - loss: 0.0302 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9892\n",
      "Epoch 7/100\n",
      "3521240/3521240 - 11s - loss: 0.0298 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0381 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 8/100\n",
      "3521240/3521240 - 11s - loss: 0.0295 - sparse_categorical_accuracy: 0.9907 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 9/100\n",
      "3521240/3521240 - 11s - loss: 0.0290 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0397 - val_sparse_categorical_accuracy: 0.9895\n",
      "Epoch 10/100\n",
      "3521240/3521240 - 11s - loss: 0.0289 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0444 - val_sparse_categorical_accuracy: 0.9893\n",
      "Epoch 11/100\n",
      "3521240/3521240 - 11s - loss: 0.0286 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0435 - val_sparse_categorical_accuracy: 0.9891\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 2651187 samples, validate on 1136223 samples\n",
      "Epoch 1/100\n",
      "2651187/2651187 - 9s - loss: 0.1072 - sparse_categorical_accuracy: 0.9721 - val_loss: 0.0422 - val_sparse_categorical_accuracy: 0.9887\n",
      "Epoch 2/100\n",
      "2651187/2651187 - 8s - loss: 0.0375 - sparse_categorical_accuracy: 0.9901 - val_loss: 0.0375 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 3/100\n",
      "2651187/2651187 - 9s - loss: 0.0342 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.0359 - val_sparse_categorical_accuracy: 0.9897\n",
      "Epoch 4/100\n",
      "2651187/2651187 - 9s - loss: 0.0322 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0350 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 5/100\n",
      "2651187/2651187 - 9s - loss: 0.0311 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0342 - val_sparse_categorical_accuracy: 0.9901\n",
      "Epoch 6/100\n",
      "2651187/2651187 - 9s - loss: 0.0299 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.0333 - val_sparse_categorical_accuracy: 0.9902\n",
      "Epoch 7/100\n",
      "2651187/2651187 - 8s - loss: 0.0288 - sparse_categorical_accuracy: 0.9913 - val_loss: 0.0326 - val_sparse_categorical_accuracy: 0.9904\n",
      "Epoch 8/100\n",
      "2651187/2651187 - 8s - loss: 0.0280 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0322 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 9/100\n",
      "2651187/2651187 - 8s - loss: 0.0275 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0325 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 10/100\n",
      "2651187/2651187 - 9s - loss: 0.0271 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0323 - val_sparse_categorical_accuracy: 0.9903\n",
      "Epoch 11/100\n",
      "2651187/2651187 - 8s - loss: 0.0270 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0324 - val_sparse_categorical_accuracy: 0.9905\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 1772953 samples, validate on 759837 samples\n",
      "Epoch 1/100\n",
      "1772953/1772953 - 7s - loss: 0.2479 - sparse_categorical_accuracy: 0.8976 - val_loss: 0.0382 - val_sparse_categorical_accuracy: 0.9926\n",
      "Epoch 2/100\n",
      "1772953/1772953 - 6s - loss: 0.0389 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.0285 - val_sparse_categorical_accuracy: 0.9929\n",
      "Epoch 3/100\n",
      "1772953/1772953 - 6s - loss: 0.0337 - sparse_categorical_accuracy: 0.9909 - val_loss: 0.0265 - val_sparse_categorical_accuracy: 0.9931\n",
      "Epoch 4/100\n",
      "1772953/1772953 - 6s - loss: 0.0319 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0261 - val_sparse_categorical_accuracy: 0.9930\n",
      "Epoch 5/100\n",
      "1772953/1772953 - 6s - loss: 0.0304 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.0248 - val_sparse_categorical_accuracy: 0.9931\n",
      "Epoch 6/100\n",
      "1772953/1772953 - 5s - loss: 0.0298 - sparse_categorical_accuracy: 0.9914 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9932\n",
      "Epoch 7/100\n",
      "1772953/1772953 - 5s - loss: 0.0286 - sparse_categorical_accuracy: 0.9916 - val_loss: 0.0241 - val_sparse_categorical_accuracy: 0.9932\n",
      "Epoch 8/100\n",
      "1772953/1772953 - 5s - loss: 0.0278 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0238 - val_sparse_categorical_accuracy: 0.9934\n",
      "Epoch 9/100\n",
      "1772953/1772953 - 5s - loss: 0.0270 - sparse_categorical_accuracy: 0.9918 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 10/100\n",
      "1772953/1772953 - 5s - loss: 0.0261 - sparse_categorical_accuracy: 0.9920 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9935\n",
      "Epoch 11/100\n",
      "1772953/1772953 - 5s - loss: 0.0259 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0234 - val_sparse_categorical_accuracy: 0.9934\n",
      "Epoch 00011: early stopping\n",
      "4101_LC08_027038_20131103_1\n",
      "Train on 888854 samples, validate on 380937 samples\n",
      "Epoch 1/100\n",
      "888854/888854 - 4s - loss: 0.1790 - sparse_categorical_accuracy: 0.9610 - val_loss: 0.0426 - val_sparse_categorical_accuracy: 0.9940\n",
      "Epoch 2/100\n",
      "888854/888854 - 3s - loss: 0.0418 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.0303 - val_sparse_categorical_accuracy: 0.9944\n",
      "Epoch 3/100\n",
      "888854/888854 - 3s - loss: 0.0340 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0275 - val_sparse_categorical_accuracy: 0.9945\n",
      "Epoch 4/100\n",
      "888854/888854 - 3s - loss: 0.0305 - sparse_categorical_accuracy: 0.9926 - val_loss: 0.0256 - val_sparse_categorical_accuracy: 0.9947\n",
      "Epoch 5/100\n",
      "888854/888854 - 3s - loss: 0.0292 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0247 - val_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 6/100\n",
      "888854/888854 - 3s - loss: 0.0277 - sparse_categorical_accuracy: 0.9930 - val_loss: 0.0244 - val_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 7/100\n",
      "888854/888854 - 3s - loss: 0.0267 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0236 - val_sparse_categorical_accuracy: 0.9948\n",
      "Epoch 8/100\n",
      "888854/888854 - 3s - loss: 0.0259 - sparse_categorical_accuracy: 0.9933 - val_loss: 0.0232 - val_sparse_categorical_accuracy: 0.9950\n",
      "Epoch 9/100\n",
      "888854/888854 - 3s - loss: 0.0249 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0233 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 10/100\n",
      "888854/888854 - 3s - loss: 0.0246 - sparse_categorical_accuracy: 0.9935 - val_loss: 0.0220 - val_sparse_categorical_accuracy: 0.9951\n",
      "Epoch 11/100\n",
      "888854/888854 - 3s - loss: 0.0241 - sparse_categorical_accuracy: 0.9936 - val_loss: 0.0222 - val_sparse_categorical_accuracy: 0.9949\n",
      "Epoch 00011: early stopping\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from CPR.configs import data_path\n",
    "from CPR.utils import tif_stacker, cloud_generator, preprocessing, train_val, timer\n",
    "\n",
    "# Order in which features should be stacked to create stacked tif\n",
    "feat_list_new = ['aspect','curve', 'developed', 'GSW_distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "# Image to predict on\n",
    "# img_list = ['4115_LC08_021033_20131227_test']\n",
    "img_list = ['4101_LC08_027038_20131103_1']\n",
    "#             '4101_LC08_027038_20131103_2' \n",
    "#             '4101_LC08_027039_20131103_1',\n",
    "#             '4115_LC08_021033_20131227_1',\n",
    "#             '4337_LC08_026038_20160325_1']\n",
    "\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "# pctls = [40, 50]\n",
    "batch_size = 7000\n",
    "epochs = 100\n",
    "dropout_rate = 0.3\n",
    "holdout = 0.3 # Validation data size\n",
    "cb_list = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                 min_delta=0.5, \n",
    "                                                 patience=10, \n",
    "                                                 verbose=1)]\n",
    "valMetricsList = []\n",
    "\n",
    "# Stack layers into a single tif, and generate cloud cover image\n",
    "for j, img in enumerate(img_list):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    times = []\n",
    "    history = []\n",
    "    \n",
    "    tif_stacker(data_path, img, feat_list_new, overwrite=False)\n",
    "    cloud_generator(img, data_path, overwrite=False)\n",
    "    \n",
    "    for i, pctl in enumerate(pctls):\n",
    "        data_train, data_vector_train, data_ind_train = preprocessing(data_path, img, pctl, gaps=False)\n",
    "        training_data, validation_data = train_val(data_vector_train, holdout=holdout)\n",
    "        X_train, y_train = training_data[:,0:14], training_data[:,14]\n",
    "        X_val, y_val = validation_data[:,0:14], validation_data[:,14]\n",
    "        INPUT_DIMS = X_train.shape[1]\n",
    "                           \n",
    "        print('~~~~~', img, pctl+'% cloud cover')\n",
    "        \n",
    "        NN_MCD = get_NN_MCD()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        NN_MCD.fit(X_train, y_train,\n",
    "                   batch_size = batch_size,\n",
    "                   epochs= epochs,\n",
    "                   verbose = 2,\n",
    "                   validation_data = (X_val, y_val),\n",
    "                   callbacks=cb_list,\n",
    "                   use_multiprocessing = True)\n",
    "        \n",
    "        end_time = time.time()\n",
    "        times.append(timer(start_time, end_time, False))\n",
    "\n",
    "        model_path = data_path / 'models' / 'cnn_vary_clouds' / img / '{0}'.format(img+'_clouds_'+str(pctl)+'.h5')\n",
    "        NN_MCD.save(model_path)\n",
    "    \n",
    "    metrics_path = data_path / 'metrics' / 'testing' / img \n",
    "    \n",
    "    try:\n",
    "        metrics_path.mkdir(parents=True)\n",
    "    except FileExistsError:\n",
    "        print('Metrics directory already exists')\n",
    "    \n",
    "    times = [float(i) for i in times]\n",
    "    times_df = pd.DataFrame(times, columns = ['times'])\n",
    "    times_df.to_csv(metrics_path / 'training_times.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4101_LC08_027038_20131103_1 10\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 20\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 30\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 40\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 50\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 60\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n",
      "Running MC 60/100\n",
      "Running MC 70/100\n",
      "Running MC 80/100\n",
      "Running MC 90/100\n",
      "Running MC 99/100\n",
      "4101_LC08_027038_20131103_1 70\n",
      "Running MC 0/100\n",
      "Running MC 10/100\n",
      "Running MC 20/100\n",
      "Running MC 30/100\n",
      "Running MC 40/100\n",
      "Running MC 50/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-7aa796422b57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'models'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'cnn_vary_clouds'\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;34m'{0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_clouds_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpctl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mNN_MCD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_with_uncertainty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNN_MCD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Elapsed time for MC simulations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-36-7aa796422b57>\u001b[0m in \u001b[0;36mpredict_with_uncertainty\u001b[1;34m(model, X)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m10\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mMC_PASSES\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running MC '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMC_PASSES\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1076\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m           \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1078\u001b[1;33m           callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# There is a problem loading keras models: https://github.com/keras-team/keras/issues/10417\n",
    "# But loading the weights into an identical compiled model works\n",
    "\n",
    "import pickle\n",
    "\n",
    "def predict_with_uncertainty(model, X):\n",
    "    preds = []\n",
    "    for i in range(MC_PASSES):\n",
    "        if i % 10 == 0 or i == MC_PASSES - 1:\n",
    "            print('Running MC '+str(i)+'/'+str(MC_PASSES))\n",
    "        preds.append(model.predict(X, batch_size=7000, use_multiprocessing=True))\n",
    "    preds = np.array(preds)\n",
    "    means = np.mean(preds, axis=0)\n",
    "    variances = np.var(preds, axis=0)\n",
    "    stds = np.std(preds, axis=0)\n",
    "    pred = np.argmax(means, axis=1)\n",
    "    pred = list(pred)\n",
    "#     return pred, preds, means, variances, stds\n",
    "    return pred, variances\n",
    "\n",
    "MC_PASSES = 100\n",
    "\n",
    "for j, img in enumerate(img_list):\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    times = []\n",
    "    predictions = []\n",
    "    gapMetricsList = []\n",
    "    variances = []\n",
    "    \n",
    "    for i, pctl in enumerate(pctls):\n",
    "        data_test, data_vector_test, data_ind_test = preprocessing(data_path, img, pctl, gaps=True)\n",
    "        X_test, y_test = data_vector_test[:,0:14], data_vector_test[:,14]\n",
    "        \n",
    "        print(img, pctl)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        NN_MCD = get_NN_MCD() # Get untrained model to add trained weights into\n",
    "        model_path = data_path / 'models' / 'cnn_vary_clouds' / img / '{0}'.format(img+'_clouds_'+str(pctl)+'.h5')\n",
    "        NN_MCD.load_weights(str(model_path))\n",
    "        preds, variances = predict_with_uncertainty(NN_MCD, X_test)\n",
    "        \n",
    "        times.append(timer(start_time, time.time(), False)) # Elapsed time for MC simulations\n",
    "        predictions.append(list(preds))\n",
    "        accuracy.append(sklearn.metrics.accuracy_score(y_test, preds))\n",
    "        precision.append(sklearn.metrics.precision_score(y_test, preds))\n",
    "        recall.append(sklearn.metrics.recall_score(y_test, preds))\n",
    "        f1.append(sklearn.metrics.f1_score(y_test, preds))\n",
    "    \n",
    "    metrics_path = data_path / 'metrics' / 'testing' / img \n",
    "    \n",
    "    try:\n",
    "        metrics_path.mkdir(parents=True)\n",
    "    except FileExistsError:\n",
    "        print('Metrics directory already exists')\n",
    "        \n",
    "    with open(str(metrics_path / 'predictions.pkl'), 'wb') as outfile:\n",
    "        pickle.dump(predictions, outfile, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    times = [float(i) for i in times] # Need to convert time objects to float, otherwise valMetrics will be non-numeric\n",
    "        \n",
    "    gapMetrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, times]),\n",
    "                          columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n",
    "    \n",
    "    gapMetrics.to_csv(metrics_path / 'gapMetrics.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into using GPU to improve speed\n",
    "# Also callbacks like EarlyStopping to halt training once performance stops improving"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
