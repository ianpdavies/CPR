{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\thesis\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "from zipfile import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from CPR.configs import data_path\n",
    "from CPR.utils import tif_stacker, preprocessing, train_val, cloud_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'WindowsPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-56dd8e2652c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#  Stack all the flood imagery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtifStacker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_list_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mcloudGenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\CPR\\CPR\\utils.py\u001b[0m in \u001b[0;36mtifStacker\u001b[1;34m(path, img, feat_list_new, overwrite)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mfile_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mimgPath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'images/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;31m# This gets the name of all files in the zip folder, and formats them into a full path readable by rasterio.open()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'WindowsPath' and 'str'"
     ]
    }
   ],
   "source": [
    "# Order in which features should be stacked to create stacked tif\n",
    "feat_list_new = ['aspect','curve', 'developed', 'GSW_distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "img_list = ['4115_LC08_021033_20131227_test']\n",
    "\n",
    "for j, img in enumerate(img_list):\n",
    "    #  Stack all the flood imagery\n",
    "    tif_stacker(path_data, img, feat_list_new, overwrite=False)\n",
    "    cloud_generator(img, data_path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctl = [20]\n",
    "data, data_ind = preprocessing(path, img, pctl)\n",
    "data_vector, training_data, validation_data, training_size = train_val(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using UncertaintyNN\n",
    "from [here](https://github.com/hutec/UncertaintyNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try creating NN with MCD in tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = data_vector[:,0:14], data_vector[:,14]\n",
    "X_val, y_val = validation_data[:,0:14], validation_data[:,14]\n",
    "\n",
    "# # Convert labels to one-hot encoding\n",
    "# y_train = tf.keras.utils.to_categorical(y_train)\n",
    "# y_val = tf.keras.utils.to_categorical(y_val)\n",
    "\n",
    "# data_vector_expand = np.expand_dims(data_vector, axis=-1)\n",
    "# validation_data_expand = np.expand_dims(validation_data, axis=-1)\n",
    "\n",
    "# X_train, y_train = data_vector_expand[:,0:14], data_vector_expand[:,14]\n",
    "# X_val, y_val = validation_data_expand[:,0:14], validation_data_expand[:,14]\n",
    "\n",
    "pctl = 20\n",
    "batch_size = 100\n",
    "epochs = 5\n",
    "input_dims = X_train.shape[1]\n",
    "dropout_rate = 0.3\n",
    "mc_passes = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_10 (Lambda)           (None, 14)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 28)                420       \n",
      "_________________________________________________________________\n",
      "lambda_11 (Lambda)           (None, 28)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 12)                348       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 794\n",
      "Trainable params: 794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 316099 samples, validate on 31609 samples\n",
      "Epoch 1/5\n",
      "316099/316099 [==============================] - 15s 47us/sample - loss: 0.1202 - acc: 0.9579 - val_loss: 0.0219 - val_acc: 0.9970\n",
      "Epoch 2/5\n",
      "316099/316099 [==============================] - 13s 42us/sample - loss: 0.0936 - acc: 0.9652 - val_loss: 0.0194 - val_acc: 0.9970\n",
      "Epoch 3/5\n",
      "316099/316099 [==============================] - 13s 42us/sample - loss: 0.0900 - acc: 0.9662 - val_loss: 0.0196 - val_acc: 0.9966\n",
      "Epoch 4/5\n",
      "316099/316099 [==============================] - 13s 42us/sample - loss: 0.0876 - acc: 0.9669 - val_loss: 0.0169 - val_acc: 0.9965\n",
      "Epoch 5/5\n",
      "316099/316099 [==============================] - 13s 42us/sample - loss: 0.0866 - acc: 0.9673 - val_loss: 0.0179 - val_acc: 0.9966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ecd5f41c88>"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_NN_MCD():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(input_dims,))),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=0.3))),\n",
    "    model.add(tf.keras.layers.Dense(input_shape=(input_dims,),\n",
    "                                    units=28,\n",
    "                                    activation='relu')),\n",
    "    model.add(tf.keras.layers.Lambda(lambda x: K.dropout(x, level=0.3))),\n",
    "    model.add(tf.keras.layers.Dense(units=12,\n",
    "                                    activation='relu')),\n",
    "#     model.add(tf.keras.layers.Dropout(rate=dropout_rate)(training=True)),\n",
    "#     model.add(tf.keras.layers.Flatten()),\n",
    "    model.add(tf.keras.layers.Dense(2,\n",
    "                                    activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',      \n",
    "#                   metrics=[tf.keras.metrics.Recall()])\n",
    "#                   metrics=[tf.keras.metrics.F1()])\n",
    "                  metrics=['accuracy'])                  \n",
    "    return model\n",
    "\n",
    "NN_MCD = get_NN_MCD()\n",
    "NN_MCD.summary()\n",
    "\n",
    "NN_MCD.fit(X_train, y_train,\n",
    "          batch_size = batch_size,\n",
    "          epochs= epochs,\n",
    "          verbose = 1,\n",
    "          validation_data = (X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctl = [20]\n",
    "data_vector_gaps, data_ind_gaps = preprocessing_gaps(path, img, pctl)\n",
    "X_test, y_test = data_vector_gaps[:,0:14], data_vector_gaps[:,14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_passes = 20\n",
    "def predict_with_uncertainty(model, X):\n",
    "    preds = []\n",
    "    for i in range(mc_passes):\n",
    "        preds.append(model.predict(X))\n",
    "    preds = np.array(preds)\n",
    "    means = np.mean(preds, axis=0)\n",
    "    variances = np.var(preds, axis=0)\n",
    "    stds = np.std(preds, axis=0)\n",
    "    pred = np.argmax(means, axis=1)\n",
    "    \n",
    "    return pred, preds, means, variances, stds\n",
    "\n",
    "pred, preds, means, variances, stds = predict_with_uncertainty(NN_MCD, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting how many MC samples predicted flooding?\n",
    "# (# times the prob of flooding > 0.5) / # samples\n",
    "# The color bar should be more saturated in the middle to highlight greater\n",
    "# uncertainty, and lighter towards 0% and 100%.\n",
    "\n",
    "# flood = 0\n",
    "# flood += "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
