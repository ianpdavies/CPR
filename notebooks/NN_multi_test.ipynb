{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing CNNs on multiple cloud gaps at varying cloud cover %s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_gaps(path, img, pctl):\n",
    "\n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'clouds'\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds.npy')\n",
    "    # Note how the sign is >=, not <, we want inverse of training data\n",
    "    cloudMask = cloudMask >= np.percentile(cloudMask, pctl)\n",
    "\n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "    \n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = data_vector[:,0:14].mean(0)\n",
    "    data_std = data_vector[:,0:14].std(0)\n",
    "\n",
    "    # Normalize features\n",
    "    data_vector[:,0:14] = (data_vector[:,0:14] - data_mean) / data_std\n",
    "    \n",
    "    return data_vector, data_mean, data_std, data_ind\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "def gapFill(data_vector, data_mean, data_std, img, pctl):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    model_path = path+'models/cnn_vary_clouds/'+img+'/'+img+'_clouds_'+str(pctl)\n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    checkpoint_filename = model_name+'_checkpoint'\n",
    "    \n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        graph = tf.get_default_graph()\n",
    "        mySaver = tf.train.import_meta_graph(model_path+'/'+model_name+'.ckpt-1000.meta') # Get metadata of saved graph\n",
    "        mySaver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir=model_path+'./')) # Restore checkpoint\n",
    "#         input = graph.get_tensor_by_name(\"input:0\") # Get inputs placeholder\n",
    "        outputs = graph.get_tensor_by_name('outputs:0') # Get outputs\n",
    "        hidden1 = graph.get_tensor_by_name('hidden1:0')\n",
    "        hidden2 = graph.get_tensor_by_name('hidden2:0')\n",
    "        \n",
    "        tf.local_variables_initializer()\n",
    "\n",
    "#         y_pred = outputs.eval({input: data_vector[:,0:14]})\n",
    "        y_pred = sess.run(outputs, feed_dict = {input: data_vector[:,0:14]})\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem: TF doesn't save every variable, like outputs or input, so we need to save those somehow\n",
    "https://stackoverflow.com/questions/43887425/how-to-import-a-model-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting flooding in cloud gaps using pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_10./4101_LC08_027038_20131103_1_clouds_10.ckpt-1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_20./4101_LC08_027038_20131103_1_clouds_20.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_30./4101_LC08_027038_20131103_1_clouds_30.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_40./4101_LC08_027038_20131103_1_clouds_40.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_50./4101_LC08_027038_20131103_1_clouds_50.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_60./4101_LC08_027038_20131103_1_clouds_60.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_70./4101_LC08_027038_20131103_1_clouds_70.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_80./4101_LC08_027038_20131103_1_clouds_80.ckpt-1000\n",
      "4101_LC08_027038_20131103_1\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4101_LC08_027038_20131103_1/4101_LC08_027038_20131103_1_clouds_90./4101_LC08_027038_20131103_1_clouds_90.ckpt-1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-64efa7e40af9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[0mtimes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtimes\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Need to convert time objects to float, otherwise valMetrics will be non-numeric\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     gapMetrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, times]),\n\u001b[0m\u001b[0;32m     55\u001b[0m                           columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[1;34m(tup)\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0marrays\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly"
     ]
    }
   ],
   "source": [
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "import math\n",
    "\n",
    "img_list = ['4101_LC08_027038_20131103_1',\n",
    "            '4101_LC08_027038_20131103_2',\n",
    "            '4101_LC08_027039_20131103_1',\n",
    "            '4115_LC08_021033_20131227_1',\n",
    "            '4337_LC08_026038_20160325_1']\n",
    "\n",
    "import time\n",
    "def timer(start,end, formatted = True):\n",
    "    if formatted == True: # Returns full formated time in hours, minutes, seconds\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    else: # Returns minutes + fraction of minute\n",
    "        minutes, seconds = divmod(time.time() - start_time, 60)\n",
    "        seconds = seconds/60\n",
    "        minutes = minutes + seconds\n",
    "        return str(minutes)\n",
    "    \n",
    "for j, img in enumerate(img_list):\n",
    "    \n",
    "    print(img)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    times = []\n",
    "#     predictions []\n",
    "    gapMetricsList = []\n",
    "    \n",
    "    for i, pctl in enumerate(pctls):\n",
    "\n",
    "        data_vector, data_mean, data_std, data_ind = preprocessing_gaps(path, img, pctl)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        y_pred = gapFill(data_vector, data_mean, data_std, img, pctl)\n",
    "        \n",
    "        times.append(timer(start_time, time.time(), False)) # Elapsed time in minutes\n",
    "        \n",
    "        y_true = data_vector[:,14]\n",
    "\n",
    "        accuracy.append(sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        precision.append(sklearn.metrics.precision_score(y_true, y_pred))\n",
    "        recall.append(sklearn.metrics.recall_score(y_true, y_pred))\n",
    "        f1.append(sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "#         predictions.append(y_pred)\n",
    "        \n",
    "    times = [float(i) for i in times] # Need to convert time objects to float, otherwise valMetrics will be non-numeric\n",
    "        \n",
    "    gapMetrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, times]),\n",
    "                          columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n",
    "    \n",
    "    gapMetrics.to_csv(path+'/models/cnn_vary_clouds/'+img+'/gapMetrics.csv', index=False)\n",
    "    \n",
    "    gapMetricsList.append(gapMetrics)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot gap metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = 2\n",
    "    \n",
    "# Create list of axes\n",
    "fig, axes = plt.subplots(nrows = int(len(gapMetricsList) / columns + 1), ncols = columns, \n",
    "                         sharex = True, figsize = (10,5), squeeze = False)\n",
    "\n",
    "axes_list = [item for sublist in axes for item in sublist] \n",
    "\n",
    "for i in range(len(gapMetricsList)):\n",
    "    ax = axes_list.pop(0) # Pop each axis out then put data into it\n",
    "    valMetricsList[i].plot(ax = ax, x='cloud_cover', y=['recall', 'precision','f1','accuracy']) \n",
    "    ax.tick_params(\n",
    "        which='both',\n",
    "        bottom='off',\n",
    "        left='off',\n",
    "        right='off',\n",
    "        top='off'\n",
    "    )\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do the metrics not decline linearly?\n",
    " - Not enough flooded pixels in training set\n",
    "\n",
    "Test metrics vs ...\n",
    "- Number of flooded pixels in training / number of flooded pixels in image\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot filled gaps\n",
    "\n",
    "First create binary correct/incorrect prediction image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "flooded_imgs = []\n",
    "prediction_imgs = []\n",
    "\n",
    "# Reshape predicted values back into image band\n",
    "with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        shape = ds.read(1).shape # Shape of full original image\n",
    "        arr_empty = np.zeros(shape) # Create empty array with this shape\n",
    "        arr_empty[:] = np.nan # Convert all zeroes to NaN\n",
    "            \n",
    "for i, pctl in enumerate(pctls):\n",
    "    data_vector, data_mean, data_std, data_ind = preprocessing_gaps(path, img, pctl)\n",
    "\n",
    "    # Add predicted values to cloud-covered pixel positions\n",
    "    prediction_img = arr_empty\n",
    "    rows, cols = zip(data_ind)\n",
    "    prediction_img[rows, cols] = predictions[i]\n",
    "    prediction_imgs.append(prediction_img)\n",
    "    \n",
    "    # Add actual flood values to cloud-covered pixel positions\n",
    "    flooded_img = arr_empty\n",
    "    flooded_img[rows, cols] = data_vector[:,14]\n",
    "    flooded_imgs.append(flooded_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flooded_imgs == prediction_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,100))\n",
    "columns = 2\n",
    "\n",
    "images = []\n",
    "\n",
    "for i in range(len(flooded_imgs)+len(prediction_imgs)):\n",
    "    images.append(flooded_imgs[i])\n",
    "    images.append(prediction_imgs[i])\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
    "#     plt.suptitle('Actual flooding, predicted flooding', fontsize=20)\n",
    "    plt.imshow(image)\n",
    "    plt.colorbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing correct/incorrect predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "\n",
    "comparison_imgs = []\n",
    "prediction_imgs = []\n",
    "\n",
    "# Reshape predicted values back into image band\n",
    "with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        actual_flooded = ds.read(15)\n",
    "        shape = ds.read(1).shape # Shape of full original image\n",
    "        arr_empty = np.zeros(shape) # Create empty array with this shape\n",
    "        arr_empty[:] = np.nan # Convert all zeroes to NaN\n",
    "        ones = np.ones(shape=shape)\n",
    "            \n",
    "for i, pctl in enumerate(pctls):\n",
    "    data_vector, data_mean, data_std, data_ind = preprocessing_gaps(path, img, pctl)\n",
    "    \n",
    "    # Add predicted values to cloud-covered pixel positions\n",
    "    prediction_img = arr_empty\n",
    "    rows, cols = zip(data_ind)\n",
    "    prediction_img[rows, cols] = predictions[i]\n",
    "    prediction_imgs.append(prediction_img)\n",
    "    \n",
    "    red = np.where(ones, prediction_img, 0.5)\n",
    "    blue = np.where(ones, actual_flooded, 0.5)\n",
    "    green = np.minimum(red, blue)\n",
    "    \n",
    "    comparison_img = np.dstack((red, green, blue))\n",
    "    comparison_imgs.append(comparison_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(prediction_imgs[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at correlation between predicted values and features?\n",
    "data_vector, data_mean, data_std, data_ind = preprocessing_gaps(path, img, 90)\n",
    "df = pd.DataFrame(data=data_vector, columns=['aspect','curve', 'developed', 'distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded'])\n",
    "df['preds'] = predictions[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot cloud masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pctls = [10,20,30,40,50,60,70,80,90]\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "model_path = path+'models/cnn_vary_clouds/'\n",
    "img = '4337_LC08_026038_20160325_1'\n",
    "\n",
    "images = [] \n",
    "\n",
    "for i, pctl in enumerate(pctls):\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'clouds'\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds.npy')\n",
    "    cloudMask = cloudMask < np.percentile(cloudMask, pctl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# settings\n",
    "h, w = 10, 10        # for raster image\n",
    "nrows, ncols = 3, 3  # array of sub-plots\n",
    "figsize = [12, 12]     # figure size, inches\n",
    "\n",
    "# # prep (x,y) for extra plotting on selected sub-plots\n",
    "# xs = np.linspace(0, 2*np.pi, 60)  # from 0 to 2pi\n",
    "# ys = np.abs(np.sin(xs))           # absolute of sine\n",
    "\n",
    "titles = ['10%', '20%', '30%','40%','50%',\n",
    "         '60%','70%','80%','90%']\n",
    "\n",
    "# create figure (fig), and array of axes (ax)\n",
    "fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "# plot simple raster image on each sub-plot\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    # i runs from 0 to (nrows*ncols-1)\n",
    "    # axi is equivalent with ax[rowid][colid]\n",
    "    img = images[i]\n",
    "    axi.imshow(img)\n",
    "    axi.axis('off')\n",
    "\n",
    "    # write row/col indices as axes' title for identification\n",
    "    axi.set_title(titles[i], fontdict = {'fontsize' : 18})\n",
    "\n",
    "# one can access the axes by ax[row_id][col_id]\n",
    "# do additional plotting on ax[row_id][col_id] of your choice\n",
    "# ax[0][2].plot(xs, 3*ys, color='red', linewidth=3)\n",
    "# ax[4][3].plot(ys**2, xs, color='green', linewidth=3)\n",
    "\n",
    "# plt.tight_layout(True)\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
