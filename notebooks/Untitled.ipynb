{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.7.3 (default, Apr 24 2019, 15:29:51) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rasterio\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from training import training3\n",
    "from prediction import prediction\n",
    "from evaluation import evaluation\n",
    "from CPR.utils import preprocessing, timer\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "project_path = Path('C:/Users/ipdavies/CPR')\n",
    "\n",
    "data_path = project_path / 'data'\n",
    "\n",
    "# Version numbers\n",
    "print('Python Version:', sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================================================================================================\n",
    "# Performance metrics vs. image metadata\n",
    "img_list = ['4444_LC08_044033_20170222_3']\n",
    "pctls = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "feat_list_new = ['GSW_maxExtent', 'GSW_distExtent', 'GSW_perm', 'aspect', 'curve', 'developed', 'elevation',\n",
    "                 'forest', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "batch = 'v2'\n",
    "uncertainty = False\n",
    "BATCH_SIZE = 8192\n",
    "EPOCHS = 100\n",
    "DROPOUT_RATE = 0.3  # Dropout rate for MCD\n",
    "HOLDOUT = 0.3  # Validation data size\n",
    "remove_perm = True\n",
    "\n",
    "model_params = {'batch_size': BATCH_SIZE,\n",
    "                'epochs': EPOCHS,\n",
    "                'verbose': 2,\n",
    "                'use_multiprocessing': True}\n",
    "\n",
    "viz_params = {'img_list': img_list,\n",
    "              'pctls': pctls,\n",
    "              'data_path': data_path,\n",
    "              'uncertainty': uncertainty,\n",
    "              'batch': batch,\n",
    "              'feat_list_new': feat_list_new}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 4444_LC08_044033_20170222_3 60 % cloud cover\n",
      "Predicting for 4444_LC08_044033_20170222_3 at 60% cloud cover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\CPR\\utils.py:200: RuntimeWarning: invalid value encountered in true_divide\n",
      "  data_vector[:, 0:shape[1]-1] = (data_vector[:, 0:shape[1]-1] - data_mean) / data_std\n"
     ]
    }
   ],
   "source": [
    "img = img_list[0]\n",
    "pctl = 60\n",
    "print('Preprocessing', img, pctl, '% cloud cover')\n",
    "data_test, data_vector_test, data_ind_test, feat_keep = preprocessing(data_path, img, pctl, gaps=True)\n",
    "feat_list_keep = [feat_list_new[i] for i in feat_keep]  # Removed if feat was deleted in preprocessing\n",
    "if remove_perm:\n",
    "    perm_index = feat_list_keep.index('GSW_perm')\n",
    "    flood_index = feat_list_keep.index('flooded')\n",
    "    data_vector_test[data_vector_test[:, perm_index] == 1, flood_index] = 0  # Remove flood water that is perm water\n",
    "data_vector_test = np.delete(data_vector_test, perm_index, axis=1)  # Remove GSW_perm column\n",
    "data_shape = data_vector_test.shape\n",
    "X_test, y_test = data_vector_test[:, 0:data_shape[1]-1], data_vector_test[:, data_shape[1]-1]\n",
    "\n",
    "print('Predicting for {} at {}% cloud cover'.format(img, pctl))\n",
    "\n",
    "#         # There is a problem loading keras models: https://github.com/keras-team/keras/issues/10417\n",
    "#         # Workaround is to use load_model: https://github.com/keras-team/keras-tuner/issues/75\n",
    "#         start_time = time.time()\n",
    "#         model_path = data_path / batch / 'models' / img / '{}'.format(img + '_clouds_' + str(pctl) + '.h5')\n",
    "#         trained_model = tf.keras.models.load_model(model_path)\n",
    "#         preds = trained_model.predict(X_test, batch_size=model_params['batch_size'], use_multiprocessing=True)\n",
    "#         preds = np.argmax(preds, axis=1)  # Display most probable value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True\n",
    "from CPR.utils import tif_stacker, cloud_generator\n",
    "\n",
    "img_path = data_path / 'images' / img\n",
    "stack_path = img_path / 'stack' / 'stack.tif'\n",
    "\n",
    "# load cloudmasks\n",
    "cloudmask_dir = data_path / 'clouds'\n",
    "\n",
    "cloudmask = np.load(cloudmask_dir / '{0}'.format(img+'_clouds.npy'))\n",
    "\n",
    "# Check for any features that have all zeros/same value and remove. This only matters with the training data\n",
    "cloudmask = cloudmask < np.percentile(cloudmask, pctl)\n",
    "# Get local image\n",
    "with rasterio.open(str(stack_path), 'r') as ds:\n",
    "    data = ds.read()\n",
    "    data = data.transpose((1, -1, 0))  # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    data[cloudmask] = -999999\n",
    "    data[data == -999999] = np.nan\n",
    "    data[np.isneginf(data)] = np.nan\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "    data_std = data_vector[:, 0:data_vector.shape[1] - 1].std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just adding this next line in to correctly remove the deleted feat from feat_list_new during training\n",
    "# Should remove once I've decided whether to train with or without perm water\n",
    "feat_keep = [a for a in range(data.shape[2])]\n",
    "with rasterio.open(str(stack_path), 'r') as ds:\n",
    "    data = ds.read()\n",
    "    data = data.transpose((1, -1, 0))  # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "\n",
    "if 0 in data_std.tolist():\n",
    "    zero_feat = data_std.tolist().index(0)\n",
    "    data = np.delete(data, zero_feat, axis=2)\n",
    "    feat_keep.pop(zero_feat)\n",
    "\n",
    "# Convert -999999 and -Inf to Nans\n",
    "data[cloudmask] = -999999\n",
    "data[data == -999999] = np.nan\n",
    "data[np.isneginf(data)] = np.nan\n",
    "\n",
    "# Get indices of non-nan values. These are the indices of the original image array\n",
    "data_ind = np.where(~np.isnan(data[:, :, 1]))\n",
    "\n",
    "# Reshape into a 2D array, where rows = pixels and cols = features\n",
    "data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "shape = data_vector.shape\n",
    "\n",
    "# Remove NaNs\n",
    "data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "\n",
    "data_mean = data_vector[:, 0:shape[1] - 1].mean(0)\n",
    "data_std = data_vector[:, 0:shape[1] - 1].std(0)\n",
    "\n",
    "# Normalize data - only the non-binary variables\n",
    "if normalize:\n",
    "    data_vector[:, 0:shape[1]-1] = (data_vector[:, 0:shape[1]-1] - data_mean) / data_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test, data_vector_test, data_ind_test, feat_keep = preprocessing(data_path, img, pctl, gaps=True)\n",
    "data_vector_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = True\n",
    "from CPR.utils import tif_stacker, cloud_generator\n",
    "\n",
    "img_path = data_path / 'images' / img\n",
    "stack_path = img_path / 'stack' / 'stack.tif'\n",
    "\n",
    "# load cloudmasks\n",
    "cloudmask_dir = data_path / 'clouds'\n",
    "\n",
    "cloudmask = np.load(cloudmask_dir / '{0}'.format(img+'_clouds.npy'))\n",
    "\n",
    "# Check for any features that have all zeros/same value and remove. This only matters with the training data\n",
    "cloudmask = cloudmask < np.percentile(cloudmask, pctl)\n",
    "# Get local image\n",
    "with rasterio.open(str(stack_path), 'r') as ds:\n",
    "    data = ds.read()\n",
    "    data = data.transpose((1, -1, 0))  # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    data[cloudmask] = -999999\n",
    "    data[data == -999999] = np.nan\n",
    "    data[np.isneginf(data)] = np.nan\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "    data_std = data_vector[:, 0:data_vector.shape[1] - 1].std(0)\n",
    "\n",
    "# Just adding this next line in to correctly remove the deleted feat from feat_list_new during training\n",
    "# Should remove once I've decided whether to train with or without perm water\n",
    "feat_keep = [a for a in range(data.shape[2])]\n",
    "with rasterio.open(str(stack_path), 'r') as ds:\n",
    "    data = ds.read()\n",
    "    data = data.transpose((1, -1, 0))  # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "\n",
    "if 0 in data_std.tolist():\n",
    "    zero_feat = data_std.tolist().index(0)\n",
    "    data = np.delete(data, zero_feat, axis=2)\n",
    "    feat_keep.pop(zero_feat)\n",
    "\n",
    "if gaps:\n",
    "    cloudmask = cloudmask < np.percentile(cloudmask, pctl)\n",
    "if not gaps:\n",
    "    cloudmask = cloudmask > np.percentile(cloudmask, pctl)\n",
    "\n",
    "# Convert -999999 and -Inf to Nans\n",
    "data[cloudmask] = -999999\n",
    "data[data == -999999] = np.nan\n",
    "data[np.isneginf(data)] = np.nan\n",
    "\n",
    "# Get indices of non-nan values. These are the indices of the original image array\n",
    "data_ind = np.where(~np.isnan(data[:, :, 1]))\n",
    "\n",
    "# Reshape into a 2D array, where rows = pixels and cols = features\n",
    "data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "shape = data_vector.shape\n",
    "\n",
    "# Remove NaNs\n",
    "data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "\n",
    "data_mean = data_vector[:, 0:shape[1] - 1].mean(0)\n",
    "data_std = data_vector[:, 0:shape[1] - 1].std(0)\n",
    "\n",
    "# Normalize data - only the non-binary variables\n",
    "if normalize:\n",
    "    data_vector[:, 0:shape[1]-1] = (data_vector[:, 0:shape[1]-1] - data_mean) / data_std"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
