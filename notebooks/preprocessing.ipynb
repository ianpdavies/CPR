{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - GSw: use max_extent or another metric?\n",
    " - Remove points overlying permanent water from classifier? Or remove later?\n",
    " - Height Above Nearest Drainage ([HAND](https://www.mdpi.com/2072-4292/8/5/386)) data useful for separating areas where water is more or less likely to occur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import ipywidgets\n",
    "import IPython.display\n",
    "import numpy as np\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ee; ee.Initialize()\n",
    "\n",
    "# Configure the pretty printing output\n",
    "pp = pprint.PrettyPrinter(depth=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search through DFO fusion table for flood events (for now, just in the US) and then find overlap with Landsat 8. Might later want to add Landsat 7, maybe 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The import feature collection with flood events\n",
    "feats = ee.FeatureCollection('ft:1uQgyUakR1ZiXeKZNc2uay69A_5vJe0iC882-Id8E');\n",
    "\n",
    "# Set the end date 3 days after the begin date and convert the date entries ee.Dates.\n",
    "# These will be the date bounds in which we search for imagery\n",
    "def eventDate(event):\n",
    "    newBegan = ee.Date(event.get('Began'))\n",
    "    newEnded = ee.Date(event.get('Ended')).advance(3, 'day')\n",
    "    return (event.set({'Began': newBegan, 'Ended': newEnded}))\n",
    "\n",
    "dfo = eventDate(feats)\n",
    "dfo = dfo.filterMetadata('Country', 'equals', 'USA') # Filter by US\n",
    "dfo = dfo.filterMetadata('Began', 'greater_than', ee.Date('2000-01-01')) # Filter a small number of events for testing\n",
    "\n",
    "# Function to filter the ImageCollection by date and bounds of flood event\n",
    "def filterIC(ic, ft):\n",
    "    range = ee.DateRange(ft.get('Began'), ft.get('Ended'))\n",
    "    bounds = ft.geometry()\n",
    "    dfoID = ft.get('ID')\n",
    "    return ic.filterBounds(bounds).filterDate(range).map(lambda x: x.set('dfoID', dfoID))\n",
    "\n",
    "# Get Landsat images that intersect flood boundaries during flood event window\n",
    "def getLandsatImages(event):\n",
    "    dfoID = event.get('ID')\n",
    "    l8 = filterIC(ee.ImageCollection('LANDSAT/LC08/C01/T1_TOA'), event).toList(1000)\n",
    "    l7 = filterIC(ee.ImageCollection('LANDSAT/LE07/C01/T1_TOA'), event).toList(1000)\n",
    "    l5 = filterIC(ee.ImageCollection('LANDSAT/LT05/C01/T1_TOA'), event).toList(1000)\n",
    "    imageList = l8.add(l7).add(l5);\n",
    "    return ee.ImageCollection.fromImages(ee.List(imageList).flatten())\\\n",
    "    .set({'dfoID': dfoID, 'Began': ee.Date(event.get('Began')),\n",
    "          'Ended': ee.Date(event.get('Ended')).advance(3, 'day')});\n",
    "\n",
    "imgs = ee.ImageCollection(dfo.map(getLandsatImages)).flatten();\n",
    "imgs = ee.ImageCollection(dfo.map(getLandsatImages))\n",
    "# print(\"list of flood event IDs\", ee.List(feats.aggregate_array('ID')))\n",
    "# print(\"Images from a certain flood event\", imgs.filter(ee.Filter.eq('dfoID', 4625)));\n",
    "# print(\"Images from a certain flood event\", imgs.filter(ee.Filter.eq('dfoID', 4560)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Landsat 8 scene from Iowa City, IA (2016)\n",
    "# scene = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_025031_20160926')\n",
    "scene = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_044033_20170105')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pansharpen and visualize the scene in true color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize part of image in RGB\n",
    "poly = ee.Geometry.Polygon(\n",
    "    [[[-91.78812019737575, 41.95033307316587],\n",
    "           [-91.79361336143825, 41.90333364712244],\n",
    "           [-91.71739571007106, 41.9012894084067],\n",
    "           [-91.72151558311793, 41.95288639774597]]])\n",
    "\n",
    "# Pansharpen the image to get a better resolution\n",
    "def panSharpenL8(scene):\n",
    "    hsv = scene.select('B4', 'B3', 'B2').rgbToHsv()\n",
    "    sharpened = ee.Image.cat([hsv.select('hue'), \n",
    "                              hsv.select('saturation'), \n",
    "                              scene.select('B8')]).hsvToRgb()\n",
    "    return sharpened\n",
    "\n",
    "visparams = {'min':0,\n",
    "             'max': 0.25,\n",
    "             'gamma': [1.3, 1.3, 1.3]}\n",
    "\n",
    "sharpened = panSharpenL8(scene)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Inventory:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - SRTM 30m DEM\n",
    "      - aspect\n",
    "      - slope\n",
    "      - curvature\n",
    "      - SPI (stream power index)\n",
    "      - TWI (topographic wetness index)\n",
    "      - HAND (height above nearest drainage)\n",
    "      - Climatological data? (precip)\n",
    "  - Land cover \n",
    "  - Distance from permanent water extent\n",
    "  - Lithography"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect inundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [Feyisa et al. (2014)](https://www.sciencedirect.com/science/article/pii/S0034425713002873). Using a threshold of 0, and only incorporating AWEInsh, not the AWEIsh used for cloud shadows. Might be necessary later with certain images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWEI Function from Feyisa et al. (2014) to detect water\n",
    "def feyisa(image):\n",
    "    return image.expression(\"4 * (b('B3')-b('B6')) - (0.25 * b('B5') + 2.75 * b('B7'))\").gt(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------- Mask out clouds, cloud shadows, and snow/ice\n",
    "\n",
    "# Compute the bits we need to extract\n",
    "def getQABits(image, start, end, newName):\n",
    "    pattern = 0\n",
    "    i = start\n",
    "    for i in range(start, end+1):\n",
    "        pattern += 2**i\n",
    "    # Return a single band image of the extracted QA bits, giving the band a new name\n",
    "    return image.select([0], [newName])\\\n",
    "              .bitwiseAnd(pattern)\\\n",
    "              .rightShift(start);\n",
    "\n",
    "# Cloud shadows QA (Landsat 8, T1 TOA)\n",
    "def cloud_shadowsQA(image):\n",
    "    QA = image.select(['BQA'])\n",
    "    return getQABits(QA, 7, 8, 'cloud_shadows').eq(1)\n",
    "\n",
    "# Clouds QA (Landsat 8, T1 TOA)\n",
    "def cloudsQA(image):\n",
    "    QA = image.select(['BQA'])\n",
    "    return getQABits(QA, 4, 4, 'clouds').eq(0)\n",
    "\n",
    "def snowQA(image):\n",
    "    QA = image.select(['BQA'])\n",
    "    return getQABits(QA, 9, 10, 'snow_ice').eq(1)\n",
    "\n",
    "cs = cloud_shadowsQA(scene)\n",
    "c = cloudsQA(scene)\n",
    "s = snowQA(scene)\n",
    "\n",
    "sceneFlood = feyisa(scene).rename('floodBinary') # Detect water\n",
    "sceneFlood = sceneFlood.updateMask(cs).updateMask(c).updateMask(s) # Mask out clouds, cloud shadows, and snow/ice\n",
    "# sceneFlood = sceneFlood.updateMask(sceneFlood.eq(1)) # Mask out non-water for visualizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch auxiliary datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Permanent Water Extent, Joint Research Centre, Global Surface Water dataset (JRC GSW)\n",
    "GSW = ee.Image('JRC/GSW1_0/GlobalSurfaceWater') # Permanent Water Extent, Joint Research Centre, Global Surface Water dataset (JRC GSW)\n",
    "GSW_trans = GSW.select(5) # Band 5 (\"transition\") has a permanent water code, 1\n",
    "GSW_perm = GSW_trans.lt(2).gt(0) # Get only permanent water extent, code 1\n",
    "\n",
    "nlcd = ee.Image('USGS/NLCD/NLCD2011') # NLCD: National Land Cover Dataset\n",
    "\n",
    "# JRC permanent water extent\n",
    "waterJRC = ee.Image.constant(0).blend(ee.Image('JRC/GSW1_0/GlobalSurfaceWater').select('occurrence').gte(50)).select(['constant'],['water'])\n",
    "# .clip(region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HydroSHEDS lvl 6 for North America "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this necessary? Should compare values of TWI/SPI/other topo features calculated in watersheds vs. calculated in just image extent\n",
    "\n",
    "# Find drainage areas that intersect image extent\n",
    "watershed = ee.FeatureCollection(\"ft:166OsLQQh86M6GLvQeNgER7IxX8ZzgZngFMbFLRZJ\")\n",
    "\n",
    "def find_watersheds(ft, scene):\n",
    "    ft_bounds = ft.geometry()\n",
    "    scene_bounds = scene.geometry()\n",
    "    return ft.filterBounds(scene_bounds)\n",
    "\n",
    "watershed = find_watersheds(watershed, scene)\n",
    "region = watershed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate flood conditioning factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slope, curve, aspect, impervious surface, distance from water features, TWI, SPI, HAND (height above nearest drainage), water mask. Climatological factors also available but not sure how to integrate. \n",
    "\n",
    "* Might not even need to clip to watersheds - might just be able to clip to image and be good.\n",
    "\n",
    "* One problem might be that the CNN just learns the DEM, since most of the aux variables come from a DEM. Would spectral data be useful? Might be useful to put longitude and latitude in to account for spatial autocorrelation.\n",
    "\n",
    "* Are these features all the same resolution, and have the same grid overlap? Should be fine if we do points to train, but if there is some spatial mismatch then might need to do some averaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topographical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If images are in the US, use 'USGS/NED' 10m DEM, other use 'USGS/SRTMGL1_003'\n",
    "DEM = ee.Image(\"USGS/NED\") # 10-m DEM from USGS National Elevation Dataset\n",
    "\n",
    "slope = ee.Terrain.slope(DEM)\n",
    "curve = DEM.convolve(ee.Kernel.laplacian8()).resample().select(['DEM'],['curve'])\n",
    "aspect = ee.Terrain.aspect(DEM)\n",
    "\n",
    "flowAcc = ee.Image('WWF/HydroSHEDS/15ACC')\n",
    "\n",
    "nhd = flowAcc.clip(region).gte(2000) # why 2000?\n",
    "water = ee.Image('ESA/GLOBCOVER_L4_200901_200912_V2_3').select(0).eq(210).clip(region)\n",
    "kern = ee.Kernel.euclidean(2000, 'meters') # What does this do?\n",
    "distance = water.distance(kern)\n",
    "rdist = nhd.distance(kern).clip(region).select(['b1'],['distanceRiver'])\n",
    "\n",
    "# Calculating TWI and SPI\n",
    "# I don't think we need to map these functions over each watershed because flowAcc is already\n",
    "# calculated by HydroSHEDS. However, there are different ways to calculate flowAcc (http://gis4geomorphology.com/topographic-index-model/)\n",
    "# so it might be worthwhile to calculate the values in alternative ways if they are not predicting well\n",
    "\n",
    "# Topographic wetness index is LN([flowaccum+1*cellarea]/tanslope)\n",
    "    # It is defined as ln(a/tanβ) where a is the local upslope area draining \n",
    "    # through a certain point per unit contour length and tanβ is the local slope.\n",
    "\n",
    "# Stream power index is LN([flowaccum+1*cellarea]*tanslope)\n",
    "    # It is defined as ______\n",
    "    # Note that both TWI and SPI assume steady state\n",
    "    \n",
    "floodFlowAcc = flowAcc.clip(region)\n",
    "imageValue1 = ee.Image.constant(1)\n",
    "floodFlowAccPlusOne = floodFlowAcc.add(imageValue1) # so no 0s when taking the log\n",
    "pixelArea = ee.Image.pixelArea().mask(floodFlowAcc.mask())\n",
    "catchmentArea = floodFlowAccPlusOne.multiply(pixelArea) # CA= (flow accum + 1 * cell^2)\n",
    "nonZeroSlopes = slope.add(ee.Image.constant(0.0000001)) # so low slopes don't get left out\n",
    "slopeRadians = nonZeroSlopes.multiply(3.141592653/280)\n",
    "tanSlope = slopeRadians.tan()\n",
    "\n",
    "topoIndex = catchmentArea.divide(tanSlope)\n",
    "twi = topoIndex.log().select(['b1'], ['twi']) # what does this do exactly, why are we selecting b1?\n",
    "\n",
    "streamPower = catchmentArea.multiply(tanSlope)\n",
    "spi = streamPower.clip(region).select(['b1'], ['spi'])\n",
    "\n",
    "# Height above nearest drainage\n",
    "hand = ee.ImageCollection('users/gena/global-hand/hand-100').mosaic().select(['b1'],['hand']).clip(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other features\n",
    "\n",
    " * Wanted to include lat/lon to take autocorrelation into account (cloudy areas adjacent to flooded areas likely to also be flooded). But this doesn't seem necessary because all of the features are themselves autocorrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance from permanent water extent\n",
    "dist = GSW_perm.fastDistanceTransform() # distance from permanent water bodies\n",
    "\n",
    "# Hansen global forest coverage\n",
    "hansen = ee.Image(\"UMD/hansen/global_forest_change_2015\").select('datamask').clip(region)\n",
    "hansenWater =  hansen.select([0]).remap([0,1,2], [1,0,1])\n",
    "hansenLand = hansen.select([0]).remap([0,1,2], [0,1,0])\n",
    "\n",
    "# Land Cover\n",
    "# If only including US floods, use 2011 NLCD \n",
    "nlcd = ee.Image('USGS/NLCD/NLCD2011') # NLCD: National Land Cover Dataset\n",
    "# Otherwise use this 2009 ESA global dataset\n",
    "# imp = ee.Image('ESA/GLOBCOVER_L4_200901_200912_V2_3').select(0).eq(190).select(['landcover'],['impervious']).clip(region);\n",
    "\n",
    "# Make these binary features instead of categorical. Not sure if neural nets prefer one type of data over another\n",
    "# This SO answer says decision trees don't like binary data (https://datascience.stackexchange.com/questions/20132/is-it-better-to-have-binary-features-rather-than-class-ones/20137)\n",
    "imp = nlcd.select(2) # impervious surfaces\n",
    "# Add more ... probably need to aggregate a bunch of NLCD classes, but not sure how to do that\n",
    "\n",
    "# US Lithography\n",
    "lith = ee.Image(\"CSP/ERGo/1_0/US/lithology\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloudmask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than generating artificial clouds using, say, Perlin or simplex noise, we can just use the cloud masks that come with Landsat images (any Landsat image, but obviously not an image that is part of our dataset). Using cloud cover of 20-30% right now. Not sure if there is any downside to doing this versus Perlin/Simplex noise, but couldn't figure out a way to generate cloud cover server side in GEE.\n",
    "\n",
    "Another important point is that the cloud cover is really more for aesthetic purposes, at least until we use the classifer to predict all cloud-covered pixels. To speed things up, we could just take a random subset of the sampled points as our \"cloud pixels\" for testing. But then again, we ultimately want to have a figure of red/green, incorrect/correct predictions over cloud areas, which we would need artificial clouds for.\n",
    "\n",
    "All of these methods for generating artificial cloud cover assume that cloud presence is equally probable in all pixels of an image, which isn't necessarily true if we are dealing with mountains /cloud shadow areas, large water bodies, etc. Doesn't seem too important at this point though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting images with 20-30% cloudcover and taking their cloudmask to use as cloud cover for classifier\n",
    "extent = scene.geometry()\n",
    "ic = ee.ImageCollection('LANDSAT/LC08/C01/T1_SR').filterBounds(extent)\n",
    "\n",
    "# Do we need a geometry? Or can we just filter only by cloudscore? What exactly is this used for?\n",
    "def getCloudScore(scene):\n",
    "    cloud = ee.Algorithms.Landsat.simpleCloudScore(scene).select('cloud')\n",
    "    cloudiness = cloud.reduceRegion(ee.Reducer.mean(), extent, 30)\n",
    "    return scene.set(cloudiness)\n",
    "\n",
    "# Find images with 20-30% average cloud cover per pixel\n",
    "# from: https://gis.stackexchange.com/questions/252685/filter-landsat-images-base-on-cloud-cover-over-a-region-of-interest/252785\n",
    "withCloudiness = ic.map(getCloudScore)\n",
    "filteredCollection = withCloudiness.filter(ee.Filter.gt('cloud', 20))\n",
    "filteredCollection = filteredCollection.filter(ee.Filter.lt('cloud', 30))\n",
    "\n",
    "# Arbitrarily sort by date acquired and take the first image that matches cloudiness criteria\n",
    "sortedCollection = filteredCollection.sort('DATE_ACQUIRED')\n",
    "cloudMask = ee.Image(sortedCollection.first())\n",
    "\n",
    "# Select the QA band and pixels that are cloudy (bit value = 32)\n",
    "cloudMask = cloudMask.select('pixel_qa').bitwiseAnd(32).neq(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add all features to one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into one image\n",
    "features = DEM.addBands([twi, spi, flowAcc, nhd, water, rdist, slope, curve, aspect, hand, lith, imp, cloudMask, water]) \n",
    "\n",
    "# Rescale features. Skipping this for now - CNNs might be scale invariant, but need to read up more on that.\n",
    "# features = features.map(ee.Image.unitScale())\n",
    "\n",
    "# Clip features to image region\n",
    "features = features.clip(extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mytask = ee.batch.Export.scene.toDrive(features, folder='data_earth_engine', description='myExportTableTask')\n",
    "# ee.batch.data.startProcessing(mytask.id, mytask.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract values of randomly sampled points to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of points to sample\n",
    "sample_n = 10000\n",
    "\n",
    "# Should we stratify this? To get a certain % from clouds and certain % from non-clouds?\n",
    "scene = ee.Image('LANDSAT/LC08/C01/T1_TOA/LC08_025031_20160926')\n",
    "\n",
    "pts = ee.FeatureCollection.randomPoints(extent, sample_n) # randomly sampled points\n",
    " \n",
    "sample = features.reduceRegions(pts, ee.Reducer.first()) # extract values of image stack to points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'BPBY6IXAUCY67ZHAOSCCMKBJ',\n",
       " 'state': 'READY',\n",
       " 'creation_timestamp_ms': 1548459139683,\n",
       " 'update_timestamp_ms': 1548459139683,\n",
       " 'description': 'LC08_044033_20170105_sample_pts',\n",
       " 'task_type': 'EXPORT_FEATURES'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exportFolder = 'GEE_exports'\n",
    "tableName = 'LC08_044033_20170105_sample_pts'\n",
    "task=ee.batch.Export.table.toDrive(collection=sample,\n",
    "                                   folder = exportFolder,\n",
    "                                   description = tableName, \n",
    "                                   fileFormat='CSV')\n",
    "task.start()\n",
    "task.status()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
