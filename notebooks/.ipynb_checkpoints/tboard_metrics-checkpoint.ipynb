{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch: 1 cost =  0.670\n",
      "Epoch: 2 cost =  0.242\n",
      "Epoch: 3 cost =  0.179\n",
      "Epoch: 4 cost =  0.147\n",
      "Epoch: 5 cost =  0.123\n",
      "Epoch: 6 cost =  0.106\n",
      "Epoch: 7 cost =  0.090\n",
      "Epoch: 8 cost =  0.076\n",
      "Epoch: 9 cost =  0.067\n",
      "Epoch: 10 cost =  0.058\n",
      "0.9774\n"
     ]
    }
   ],
   "source": [
    "# Weights and biases for the connections between the input and hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')\n",
    "\n",
    "# Calculate the output of the hidden layer\n",
    "# Matrix multiplication of the weights by the input vector, add bias \n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "\n",
    "# Use ReLU to output\n",
    "hidden_out = tf.nn.relu(hidden_out)\n",
    "\n",
    "# Output layer\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "\n",
    "# Loss function - cross entropy\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999) # prevent log(0)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                         + (1 - y) * tf.log(1 - y_clipped), axis=1))\n",
    "\n",
    "\n",
    "\n",
    "# optimizer\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# initialize variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# define an acc metric\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Train the model\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    total_batch = int(len(mnist.train.labels) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size = batch_size)\n",
    "            _, c = sess.run([optimiser, cross_entropy],\n",
    "                            feed_dict = {x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch+1), \"cost = \", \"{:.3f}\".format(avg_cost))\n",
    "    print(sess.run(accuracy, feed_dict = {x: mnist.test.images, y:mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncertainty estimation using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:455: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Step:   0 Loss: 0.700 Accuracy: 0.375\n",
      "Step: 100 Loss: 0.549 Accuracy: 0.808\n",
      "Step: 200 Loss: 0.501 Accuracy: 0.833\n",
      "Step: 300 Loss: 0.409 Accuracy: 0.845\n",
      "Step: 400 Loss: 0.332 Accuracy: 0.852\n",
      "Step: 500 Loss: 0.344 Accuracy: 0.856\n",
      "Step: 600 Loss: 0.261 Accuracy: 0.859\n",
      "Step: 700 Loss: 0.384 Accuracy: 0.861\n",
      "Step: 800 Loss: 0.260 Accuracy: 0.863\n",
      "Step: 900 Loss: 0.367 Accuracy: 0.864\n",
      "Step: 1000 Loss: 0.435 Accuracy: 0.865\n",
      "Step: 1100 Loss: 0.381 Accuracy: 0.866\n",
      "Step: 1200 Loss: 0.298 Accuracy: 0.867\n",
      "Step: 1300 Loss: 0.320 Accuracy: 0.867\n",
      "Step: 1400 Loss: 0.248 Accuracy: 0.868\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-c4a3f5be80b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-c4a3f5be80b6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mcandidate_w_bs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_monte_carlo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw_draw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb_draw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m         \u001b[0mcandidate_w_bs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     visualize_decision(x, y, (w_true, b_true),\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1073\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1075\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1076\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "# Copyright 2018 The TensorFlow Probability Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"Trains a Bayesian logistic regression model on synthetic data.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "# Dependency imports\n",
    "from absl import flags\n",
    "from matplotlib import cm\n",
    "from matplotlib import figure\n",
    "from matplotlib.backends import backend_agg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\",\n",
    "                   default=0.01,\n",
    "                   help=\"Initial learning rate.\")\n",
    "flags.DEFINE_integer(\"max_steps\",\n",
    "                     default=1500,\n",
    "                     help=\"Number of training steps to run.\")\n",
    "flags.DEFINE_integer(\"batch_size\",\n",
    "                     default=32,\n",
    "                     help=\"Batch size.\")\n",
    "flags.DEFINE_string(\n",
    "    \"model_dir\",\n",
    "    default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"),\n",
    "                         \"logistic_regression/\"),\n",
    "    help=\"Directory to put the model's fit.\")\n",
    "flags.DEFINE_integer(\"num_examples\",\n",
    "                     default=256,\n",
    "                     help=\"Number of datapoints to generate.\")\n",
    "flags.DEFINE_integer(\"num_monte_carlo\",\n",
    "                     default=50,\n",
    "                     help=\"Monte Carlo samples to visualize weight posterior.\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def toy_logistic_data(num_examples, input_size=2, weights_prior_stddev=5.0):\n",
    "    \"\"\"Generates synthetic data for binary classification.\n",
    "\n",
    "    Args:\n",
    "    num_examples: The number of samples to generate (scalar Python `int`).\n",
    "    input_size: The input space dimension (scalar Python `int`).\n",
    "    weights_prior_stddev: The prior standard deviation of the weight\n",
    "      vector. (scalar Python `float`).\n",
    "\n",
    "    Returns:\n",
    "    random_weights: Sampled weights as a Numpy `array` of shape\n",
    "      `[input_size]`.\n",
    "    random_bias: Sampled bias as a scalar Python `float`.\n",
    "    design_matrix: Points sampled uniformly from the cube `[-1,\n",
    "       1]^{input_size}`, as a Numpy `array` of shape `(num_examples,\n",
    "       input_size)`.\n",
    "    labels: Labels sampled from the logistic model `p(label=1) =\n",
    "      logistic(dot(features, random_weights) + random_bias)`, as a Numpy\n",
    "      `int32` `array` of shape `(num_examples, 1)`.\n",
    "    \"\"\"\n",
    "    random_weights = weights_prior_stddev * np.random.randn(input_size)\n",
    "    random_bias = np.random.randn()\n",
    "    design_matrix = np.random.rand(num_examples, input_size) * 2 - 1\n",
    "    logits = np.reshape(\n",
    "      np.dot(design_matrix, random_weights) + random_bias,\n",
    "      (-1, 1))\n",
    "    p_labels = 1. / (1 + np.exp(-logits))\n",
    "    labels = np.int32(p_labels > np.random.rand(num_examples, 1))\n",
    "    return random_weights, random_bias, np.float32(design_matrix), labels\n",
    "\n",
    "\n",
    "def visualize_decision(features, labels, true_w_b, candidate_w_bs, fname):\n",
    "    \"\"\"Utility method to visualize decision boundaries in R^2.\n",
    "\n",
    "    Args:\n",
    "    features: Input points, as a Numpy `array` of shape `[num_examples, 2]`.\n",
    "    labels: Numpy `float`-like array of shape `[num_examples, 1]` giving a\n",
    "      label for each point.\n",
    "    true_w_b: A `tuple` `(w, b)` where `w` is a Numpy array of\n",
    "       shape `[2]` and `b` is a scalar `float`, interpreted as a\n",
    "       decision rule of the form `dot(features, w) + b > 0`.\n",
    "    candidate_w_bs: Python `iterable` containing tuples of the same form as\n",
    "       true_w_b.\n",
    "    fname: The filename to save the plot as a PNG image (Python `str`).\n",
    "    \"\"\"\n",
    "    fig = figure.Figure(figsize=(6, 6))\n",
    "    canvas = backend_agg.FigureCanvasAgg(fig)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.scatter(features[:, 0], features[:, 1],\n",
    "             c=np.float32(labels[:, 0]),\n",
    "             cmap=cm.get_cmap(\"binary\"),\n",
    "             edgecolors=\"k\")\n",
    "\n",
    "    def plot_weights(w, b, **kwargs):\n",
    "        w1, w2 = w\n",
    "        x1s = np.linspace(-1, 1, 100)\n",
    "        x2s = -(w1  * x1s + b) / w2\n",
    "        ax.plot(x1s, x2s, **kwargs)\n",
    "\n",
    "    for w, b in candidate_w_bs:\n",
    "        plot_weights(w, b,\n",
    "                     alpha=1./np.sqrt(len(candidate_w_bs)),\n",
    "                     lw=1, color=\"blue\")\n",
    "\n",
    "    if true_w_b is not None:\n",
    "        plot_weights(*true_w_b, lw=4,\n",
    "                 color=\"green\", label=\"true separator\")\n",
    "\n",
    "    ax.set_xlim([-1.5, 1.5])\n",
    "    ax.set_ylim([-1.5, 1.5])\n",
    "    ax.legend()\n",
    "\n",
    "    canvas.print_figure(fname, format=\"png\")\n",
    "    print(\"saved {}\".format(fname))\n",
    "\n",
    "\n",
    "def build_input_pipeline(x, y, batch_size):\n",
    "    \"\"\"Build a Dataset iterator for supervised classification.\n",
    "\n",
    "    Args:\n",
    "    x: Numpy `array` of features, indexed by the first dimension.\n",
    "    y: Numpy `array` of labels, with the same first dimension as `x`.\n",
    "    batch_size: Number of elements in each training batch.\n",
    "\n",
    "    Returns:\n",
    "    batch_features: `Tensor` feed  features, of shape\n",
    "      `[batch_size] + x.shape[1:]`.\n",
    "    batch_labels: `Tensor` feed of labels, of shape\n",
    "      `[batch_size] + y.shape[1:]`.\n",
    "    \"\"\"\n",
    "    training_dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    training_batches = training_dataset.repeat().batch(batch_size)\n",
    "    training_iterator = tf.compat.v1.data.make_one_shot_iterator(training_batches)\n",
    "    batch_features, batch_labels = training_iterator.get_next()\n",
    "    return batch_features, batch_labels\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv  # unused\n",
    "    if tf.io.gfile.exists(FLAGS.model_dir):\n",
    "        tf.compat.v1.logging.warning(\n",
    "            \"Warning: deleting old log directory at {}\".format(FLAGS.model_dir))\n",
    "        tf.io.gfile.rmtree(FLAGS.model_dir)\n",
    "    tf.io.gfile.makedirs(FLAGS.model_dir)\n",
    "\n",
    "    # Generate (and visualize) a toy classification dataset.\n",
    "    w_true, b_true, x, y = toy_logistic_data(FLAGS.num_examples, 2)\n",
    "    features, labels = build_input_pipeline(x, y, FLAGS.batch_size)\n",
    "\n",
    "    # Define a logistic regression model as a Bernoulli distribution\n",
    "    # parameterized by logits from a single linear layer. We use the Flipout\n",
    "    # Monte Carlo estimator for the layer: this enables lower variance\n",
    "    # stochastic gradients than naive reparameterization.\n",
    "    with tf.compat.v1.name_scope(\"logistic_regression\", values=[features]):\n",
    "        layer = tfp.layers.DenseFlipout(\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_posterior_fn=tfp.layers.default_mean_field_normal_fn(),\n",
    "            bias_posterior_fn=tfp.layers.default_mean_field_normal_fn())\n",
    "        logits = layer(features)\n",
    "        labels_distribution = tfd.Bernoulli(logits=logits)\n",
    "\n",
    "    # Compute the -ELBO as the loss, averaged over the batch size.\n",
    "    neg_log_likelihood = -tf.reduce_mean(\n",
    "        input_tensor=labels_distribution.log_prob(labels))\n",
    "    kl = sum(layer.losses) / FLAGS.num_examples\n",
    "    elbo_loss = neg_log_likelihood + kl\n",
    "\n",
    "    # Build metrics for evaluation. Predictions are formed from a single forward\n",
    "    # pass of the probabilistic layers. They are cheap but noisy predictions.\n",
    "    predictions = tf.cast(logits > 0, dtype=tf.int32)\n",
    "    accuracy, accuracy_update_op = tf.compat.v1.metrics.accuracy(\n",
    "        labels=labels, predictions=predictions)\n",
    "\n",
    "    with tf.compat.v1.name_scope(\"train\"):\n",
    "        optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "            learning_rate=FLAGS.learning_rate)\n",
    "        train_op = optimizer.minimize(elbo_loss)\n",
    "\n",
    "    init_op = tf.group(tf.compat.v1.global_variables_initializer(),\n",
    "                     tf.compat.v1.local_variables_initializer())\n",
    "\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        # Fit the model to data.\n",
    "        for step in range(FLAGS.max_steps):\n",
    "            _ = sess.run([train_op, accuracy_update_op])\n",
    "            if step % 100 == 0:\n",
    "                loss_value, accuracy_value = sess.run([elbo_loss, accuracy])\n",
    "                print(\"Step: {:>3d} Loss: {:.3f} Accuracy: {:.3f}\".format(\n",
    "                    step, loss_value, accuracy_value))\n",
    "\n",
    "    # Visualize some draws from the weights posterior.\n",
    "    w_draw = layer.kernel_posterior.sample()\n",
    "    b_draw = layer.bias_posterior.sample()\n",
    "    candidate_w_bs = []\n",
    "    for _ in range(FLAGS.num_monte_carlo):\n",
    "        w, b = sess.run((w_draw, b_draw))\n",
    "        candidate_w_bs.append((w, b))\n",
    "    visualize_decision(x, y, (w_true, b_true),\n",
    "                       candidate_w_bs,\n",
    "                       fname=os.path.join(FLAGS.model_dir,\n",
    "                                          \"weights_inferred.png\"))\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     tf.compat.v1.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1434, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\pylab\\backend_inline.py\", line 164, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\__init__.py\", line 1422, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\importlib\\__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\backends\\__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "DuplicateFlagError",
     "evalue": "The flag 'learning_rate' is defined twice. First from C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py, Second from C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py.  Description from first occurrence: Initial learning rate.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateFlagError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-18071f3508ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m flags.DEFINE_float(\"learning_rate\",\n\u001b[0;32m     61\u001b[0m                    \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                    help=\"Initial learning rate.\")\n\u001b[0m\u001b[0;32m     63\u001b[0m flags.DEFINE_integer(\"max_steps\",\n\u001b[0;32m     64\u001b[0m                      \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_float\u001b[1;34m(name, default, help, lower_bound, upper_bound, flag_values, **args)\u001b[0m\n\u001b[0;32m    289\u001b[0m   \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatParser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_bound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupper_bound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m   \u001b[0mserializer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_argument_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mArgumentSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m   \u001b[0mDEFINE\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    292\u001b[0m   \u001b[0m_register_bounds_validator_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflag_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE\u001b[1;34m(parser, name, default, help, flag_values, serializer, module_name, **args)\u001b[0m\n\u001b[0;32m     80\u001b[0m   \"\"\"\n\u001b[0;32m     81\u001b[0m   DEFINE_flag(_flag.Flag(parser, serializer, name, default, help, **args),\n\u001b[1;32m---> 82\u001b[1;33m               flag_values, module_name)\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_defines.py\u001b[0m in \u001b[0;36mDEFINE_flag\u001b[1;34m(flag, flag_values, module_name)\u001b[0m\n\u001b[0;32m    102\u001b[0m   \u001b[1;31m# Copying the reference to flag_values prevents pychecker warnings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m   \u001b[0mfv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m   \u001b[0mfv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m   \u001b[1;31m# Tell flag_values who's defining the flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\absl\\flags\\_flagvalues.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, name, flag)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;31m# module is simply being imported a subsequent time.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDuplicateFlagError\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_flag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m     \u001b[0mshort_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflag\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshort_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;31m# If a new flag overrides an old one, we need to cleanup the old flag's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateFlagError\u001b[0m: The flag 'learning_rate' is defined twice. First from C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py, Second from C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py.  Description from first occurrence: Initial learning rate."
     ]
    }
   ],
   "source": [
    "# %load https://raw.githubusercontent.com/tensorflow/probability/master/tensorflow_probability/examples/bayesian_neural_network.py\n",
    "# Copyright 2018 The TensorFlow Probability Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================\n",
    "\"\"\"Trains a Bayesian neural network to classify MNIST digits.\n",
    "\n",
    "The architecture is LeNet-5 [1].\n",
    "\n",
    "#### References\n",
    "\n",
    "[1]: Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner.\n",
    "     Gradient-based learning applied to document recognition.\n",
    "     _Proceedings of the IEEE_, 1998.\n",
    "     http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Dependency imports\n",
    "from absl import flags\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "from matplotlib import figure  # pylint: disable=g-import-not-at-top\n",
    "from matplotlib.backends import backend_agg\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "from tensorflow.contrib.learn.python.learn.datasets import mnist\n",
    "\n",
    "# TODO(b/78137893): Integration tests currently fail with seaborn imports.\n",
    "warnings.simplefilter(action=\"ignore\")\n",
    "\n",
    "try:\n",
    "  import seaborn as sns  # pylint: disable=g-import-not-at-top\n",
    "  HAS_SEABORN = True\n",
    "except ImportError:\n",
    "  HAS_SEABORN = False\n",
    "\n",
    "tfd = tfp.distributions\n",
    "\n",
    "IMAGE_SHAPE = [28, 28, 1]\n",
    "\n",
    "flags.DEFINE_float(\"learning_rate\",\n",
    "                   default=0.001,\n",
    "                   help=\"Initial learning rate.\")\n",
    "flags.DEFINE_integer(\"max_steps\",\n",
    "                     default=6000,\n",
    "                     help=\"Number of training steps to run.\")\n",
    "flags.DEFINE_integer(\"batch_size\",\n",
    "                     default=128,\n",
    "                     help=\"Batch size.\")\n",
    "flags.DEFINE_string(\"data_dir\",\n",
    "                    default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"),\n",
    "                                         \"bayesian_neural_network/data\"),\n",
    "                    help=\"Directory where data is stored (if using real data).\")\n",
    "flags.DEFINE_string(\n",
    "    \"model_dir\",\n",
    "    default=os.path.join(os.getenv(\"TEST_TMPDIR\", \"/tmp\"),\n",
    "                         \"bayesian_neural_network/\"),\n",
    "    help=\"Directory to put the model's fit.\")\n",
    "flags.DEFINE_integer(\"viz_steps\",\n",
    "                     default=400,\n",
    "                     help=\"Frequency at which save visualizations.\")\n",
    "flags.DEFINE_integer(\"num_monte_carlo\",\n",
    "                     default=50,\n",
    "                     help=\"Network draws to compute predictive probabilities.\")\n",
    "flags.DEFINE_bool(\"fake_data\",\n",
    "                  default=None,\n",
    "                  help=\"If true, uses fake data. Defaults to real data.\")\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "\n",
    "def plot_weight_posteriors(names, qm_vals, qs_vals, fname):\n",
    "  \"\"\"Save a PNG plot with histograms of weight means and stddevs.\n",
    "\n",
    "  Args:\n",
    "    names: A Python `iterable` of `str` variable names.\n",
    "    qm_vals: A Python `iterable`, the same length as `names`,\n",
    "      whose elements are Numpy `array`s, of any shape, containing\n",
    "      posterior means of weight varibles.\n",
    "    qs_vals: A Python `iterable`, the same length as `names`,\n",
    "      whose elements are Numpy `array`s, of any shape, containing\n",
    "      posterior standard deviations of weight varibles.\n",
    "    fname: Python `str` filename to save the plot to.\n",
    "  \"\"\"\n",
    "  fig = figure.Figure(figsize=(6, 3))\n",
    "  canvas = backend_agg.FigureCanvasAgg(fig)\n",
    "\n",
    "  ax = fig.add_subplot(1, 2, 1)\n",
    "  for n, qm in zip(names, qm_vals):\n",
    "    sns.distplot(qm.flatten(), ax=ax, label=n)\n",
    "  ax.set_title(\"weight means\")\n",
    "  ax.set_xlim([-1.5, 1.5])\n",
    "  ax.legend()\n",
    "\n",
    "  ax = fig.add_subplot(1, 2, 2)\n",
    "  for n, qs in zip(names, qs_vals):\n",
    "    sns.distplot(qs.flatten(), ax=ax)\n",
    "  ax.set_title(\"weight stddevs\")\n",
    "  ax.set_xlim([0, 1.])\n",
    "\n",
    "  fig.tight_layout()\n",
    "  canvas.print_figure(fname, format=\"png\")\n",
    "  print(\"saved {}\".format(fname))\n",
    "\n",
    "\n",
    "def plot_heldout_prediction(input_vals, probs,\n",
    "                            fname, n=10, title=\"\"):\n",
    "  \"\"\"Save a PNG plot visualizing posterior uncertainty on heldout data.\n",
    "\n",
    "  Args:\n",
    "    input_vals: A `float`-like Numpy `array` of shape\n",
    "      `[num_heldout] + IMAGE_SHAPE`, containing heldout input images.\n",
    "    probs: A `float`-like Numpy array of shape `[num_monte_carlo,\n",
    "      num_heldout, num_classes]` containing Monte Carlo samples of\n",
    "      class probabilities for each heldout sample.\n",
    "    fname: Python `str` filename to save the plot to.\n",
    "    n: Python `int` number of datapoints to vizualize.\n",
    "    title: Python `str` title for the plot.\n",
    "  \"\"\"\n",
    "  fig = figure.Figure(figsize=(9, 3*n))\n",
    "  canvas = backend_agg.FigureCanvasAgg(fig)\n",
    "  for i in range(n):\n",
    "    ax = fig.add_subplot(n, 3, 3*i + 1)\n",
    "    ax.imshow(input_vals[i, :].reshape(IMAGE_SHAPE[:-1]), interpolation=\"None\")\n",
    "\n",
    "    ax = fig.add_subplot(n, 3, 3*i + 2)\n",
    "    for prob_sample in probs:\n",
    "      sns.barplot(np.arange(10), prob_sample[i, :], alpha=0.1, ax=ax)\n",
    "      ax.set_ylim([0, 1])\n",
    "    ax.set_title(\"posterior samples\")\n",
    "\n",
    "    ax = fig.add_subplot(n, 3, 3*i + 3)\n",
    "    sns.barplot(np.arange(10), np.mean(probs[:, i, :], axis=0), ax=ax)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_title(\"predictive probs\")\n",
    "  fig.suptitle(title)\n",
    "  fig.tight_layout()\n",
    "\n",
    "  canvas.print_figure(fname, format=\"png\")\n",
    "  print(\"saved {}\".format(fname))\n",
    "\n",
    "\n",
    "def build_input_pipeline(mnist_data, batch_size, heldout_size):\n",
    "  \"\"\"Build an Iterator switching between train and heldout data.\"\"\"\n",
    "\n",
    "  # Build an iterator over training batches.\n",
    "  training_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "      (mnist_data.train.images, np.int32(mnist_data.train.labels)))\n",
    "  training_batches = training_dataset.shuffle(\n",
    "      50000, reshuffle_each_iteration=True).repeat().batch(batch_size)\n",
    "  training_iterator = tf.compat.v1.data.make_one_shot_iterator(training_batches)\n",
    "\n",
    "  # Build a iterator over the heldout set with batch_size=heldout_size,\n",
    "  # i.e., return the entire heldout set as a constant.\n",
    "  heldout_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "      (mnist_data.validation.images,\n",
    "       np.int32(mnist_data.validation.labels)))\n",
    "  heldout_frozen = (heldout_dataset.take(heldout_size).\n",
    "                    repeat().batch(heldout_size))\n",
    "  heldout_iterator = tf.compat.v1.data.make_one_shot_iterator(heldout_frozen)\n",
    "\n",
    "  # Combine these into a feedable iterator that can switch between training\n",
    "  # and validation inputs.\n",
    "  handle = tf.compat.v1.placeholder(tf.string, shape=[])\n",
    "  feedable_iterator = tf.compat.v1.data.Iterator.from_string_handle(\n",
    "      handle, training_batches.output_types, training_batches.output_shapes)\n",
    "  images, labels = feedable_iterator.get_next()\n",
    "\n",
    "  return images, labels, handle, training_iterator, heldout_iterator\n",
    "\n",
    "\n",
    "def build_fake_data(num_examples=10):\n",
    "  \"\"\"Build fake MNIST-style data for unit testing.\"\"\"\n",
    "\n",
    "  class Dummy(object):\n",
    "    pass\n",
    "\n",
    "  num_examples = 10\n",
    "  mnist_data = Dummy()\n",
    "  mnist_data.train = Dummy()\n",
    "  mnist_data.train.images = np.float32(np.random.randn(\n",
    "      num_examples, *IMAGE_SHAPE))\n",
    "  mnist_data.train.labels = np.int32(np.random.permutation(\n",
    "      np.arange(num_examples)))\n",
    "  mnist_data.train.num_examples = num_examples\n",
    "  mnist_data.validation = Dummy()\n",
    "  mnist_data.validation.images = np.float32(np.random.randn(\n",
    "      num_examples, *IMAGE_SHAPE))\n",
    "  mnist_data.validation.labels = np.int32(np.random.permutation(\n",
    "      np.arange(num_examples)))\n",
    "  mnist_data.validation.num_examples = num_examples\n",
    "  return mnist_data\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "  del argv  # unused\n",
    "  if tf.io.gfile.exists(FLAGS.model_dir):\n",
    "    tf.compat.v1.logging.warning(\n",
    "        \"Warning: deleting old log directory at {}\".format(FLAGS.model_dir))\n",
    "    tf.io.gfile.rmtree(FLAGS.model_dir)\n",
    "  tf.io.gfile.makedirs(FLAGS.model_dir)\n",
    "\n",
    "  if FLAGS.fake_data:\n",
    "    mnist_data = build_fake_data()\n",
    "  else:\n",
    "    mnist_data = mnist.read_data_sets(FLAGS.data_dir, reshape=False)\n",
    "\n",
    "  (images, labels, handle,\n",
    "   training_iterator, heldout_iterator) = build_input_pipeline(\n",
    "       mnist_data, FLAGS.batch_size, mnist_data.validation.num_examples)\n",
    "\n",
    "  # Build a Bayesian LeNet5 network. We use the Flipout Monte Carlo estimator\n",
    "  # for the convolution and fully-connected layers: this enables lower\n",
    "  # variance stochastic gradients than naive reparameterization.\n",
    "  with tf.compat.v1.name_scope(\"bayesian_neural_net\", values=[images]):\n",
    "    neural_net = tf.keras.Sequential([\n",
    "        tfp.layers.Convolution2DFlipout(6,\n",
    "                                        kernel_size=5,\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=[2, 2],\n",
    "                                     strides=[2, 2],\n",
    "                                     padding=\"SAME\"),\n",
    "        tfp.layers.Convolution2DFlipout(16,\n",
    "                                        kernel_size=5,\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=[2, 2],\n",
    "                                     strides=[2, 2],\n",
    "                                     padding=\"SAME\"),\n",
    "        tfp.layers.Convolution2DFlipout(120,\n",
    "                                        kernel_size=5,\n",
    "                                        padding=\"SAME\",\n",
    "                                        activation=tf.nn.relu),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tfp.layers.DenseFlipout(84, activation=tf.nn.relu),\n",
    "        tfp.layers.DenseFlipout(10)\n",
    "        ])\n",
    "\n",
    "    logits = neural_net(images)\n",
    "    labels_distribution = tfd.Categorical(logits=logits)\n",
    "\n",
    "  # Compute the -ELBO as the loss, averaged over the batch size.\n",
    "  neg_log_likelihood = -tf.reduce_mean(\n",
    "      input_tensor=labels_distribution.log_prob(labels))\n",
    "  kl = sum(neural_net.losses) / mnist_data.train.num_examples\n",
    "  elbo_loss = neg_log_likelihood + kl\n",
    "\n",
    "  # Build metrics for evaluation. Predictions are formed from a single forward\n",
    "  # pass of the probabilistic layers. They are cheap but noisy predictions.\n",
    "  predictions = tf.argmax(input=logits, axis=1)\n",
    "  accuracy, accuracy_update_op = tf.compat.v1.metrics.accuracy(\n",
    "      labels=labels, predictions=predictions)\n",
    "\n",
    "  # Extract weight posterior statistics for layers with weight distributions\n",
    "  # for later visualization.\n",
    "  names = []\n",
    "  qmeans = []\n",
    "  qstds = []\n",
    "  for i, layer in enumerate(neural_net.layers):\n",
    "    try:\n",
    "      q = layer.kernel_posterior\n",
    "    except AttributeError:\n",
    "      continue\n",
    "    names.append(\"Layer {}\".format(i))\n",
    "    qmeans.append(q.mean())\n",
    "    qstds.append(q.stddev())\n",
    "\n",
    "  with tf.compat.v1.name_scope(\"train\"):\n",
    "    optimizer = tf.compat.v1.train.AdamOptimizer(\n",
    "        learning_rate=FLAGS.learning_rate)\n",
    "    train_op = optimizer.minimize(elbo_loss)\n",
    "\n",
    "  init_op = tf.group(tf.compat.v1.global_variables_initializer(),\n",
    "                     tf.compat.v1.local_variables_initializer())\n",
    "\n",
    "  with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # Run the training loop.\n",
    "    train_handle = sess.run(training_iterator.string_handle())\n",
    "    heldout_handle = sess.run(heldout_iterator.string_handle())\n",
    "    for step in range(FLAGS.max_steps):\n",
    "      _ = sess.run([train_op, accuracy_update_op],\n",
    "                   feed_dict={handle: train_handle})\n",
    "\n",
    "      if step % 100 == 0:\n",
    "        loss_value, accuracy_value = sess.run(\n",
    "            [elbo_loss, accuracy], feed_dict={handle: train_handle})\n",
    "        print(\"Step: {:>3d} Loss: {:.3f} Accuracy: {:.3f}\".format(\n",
    "            step, loss_value, accuracy_value))\n",
    "\n",
    "      if (step+1) % FLAGS.viz_steps == 0:\n",
    "        # Compute log prob of heldout set by averaging draws from the model:\n",
    "        # p(heldout | train) = int_model p(heldout|model) p(model|train)\n",
    "        #                   ~= 1/n * sum_{i=1}^n p(heldout | model_i)\n",
    "        # where model_i is a draw from the posterior p(model|train).\n",
    "        probs = np.asarray([sess.run((labels_distribution.probs),\n",
    "                                     feed_dict={handle: heldout_handle})\n",
    "                            for _ in range(FLAGS.num_monte_carlo)])\n",
    "        mean_probs = np.mean(probs, axis=0)\n",
    "\n",
    "        image_vals, label_vals = sess.run((images, labels),\n",
    "                                          feed_dict={handle: heldout_handle})\n",
    "        heldout_lp = np.mean(np.log(mean_probs[np.arange(mean_probs.shape[0]),\n",
    "                                               label_vals.flatten()]))\n",
    "        print(\" ... Held-out nats: {:.3f}\".format(heldout_lp))\n",
    "\n",
    "        qm_vals, qs_vals = sess.run((qmeans, qstds))\n",
    "\n",
    "        if HAS_SEABORN:\n",
    "          plot_weight_posteriors(names, qm_vals, qs_vals,\n",
    "                                 fname=os.path.join(\n",
    "                                     FLAGS.model_dir,\n",
    "                                     \"step{:05d}_weights.png\".format(step)))\n",
    "\n",
    "          plot_heldout_prediction(image_vals, probs,\n",
    "                                  fname=os.path.join(\n",
    "                                      FLAGS.model_dir,\n",
    "                                      \"step{:05d}_pred.png\".format(step)),\n",
    "                                  title=\"mean heldout logprob {:.2f}\"\n",
    "                                  .format(heldout_lp))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.compat.v1.app.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC Dropout uncertainty with just TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0. Mean squared error: 0.2322.\n",
      "Iteration 100. Mean squared error: 0.2019.\n",
      "Iteration 200. Mean squared error: 0.1330.\n",
      "Iteration 300. Mean squared error: 0.0645.\n",
      "Iteration 400. Mean squared error: 0.0442.\n",
      "Iteration 500. Mean squared error: 0.0618.\n",
      "Iteration 600. Mean squared error: 0.0279.\n",
      "Iteration 700. Mean squared error: 0.0667.\n",
      "Iteration 800. Mean squared error: 0.0366.\n",
      "Iteration 900. Mean squared error: 0.0172.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.distributions import Bernoulli\n",
    "\n",
    "class VariationalDense:\n",
    "    \"\"\"Variational Dense Layer Class\"\"\"\n",
    "    def __init__(self, n_in, n_out, model_prob, model_lam):\n",
    "        self.model_prob = model_prob\n",
    "        self.model_lam = model_lam\n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "        self.model_M = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.01))\n",
    "        self.model_m = tf.Variable(tf.zeros([n_out]))\n",
    "        self.model_W = tf.matmul(\n",
    "            tf.diag(self.model_bern.sample((n_in, ))), self.model_M\n",
    "        )\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        output = activation(tf.matmul(X, self.model_W) + self.model_m)\n",
    "        if self.model_M.shape[1] == 1:\n",
    "            output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def regularization(self):\n",
    "        return self.model_lam * (\n",
    "            self.model_prob * tf.reduce_sum(tf.square(self.model_M)) +\n",
    "            tf.reduce_sum(tf.square(self.model_m))\n",
    "        )\n",
    "\n",
    "# Created sample data.\n",
    "n_samples = 20\n",
    "X = np.random.normal(size=(n_samples, 1))\n",
    "y = np.random.normal(np.cos(5.*X) / (np.abs(X) + 1.), 0.1).ravel()\n",
    "X_pred = np.atleast_2d(np.linspace(-3., 3., num=100)).T\n",
    "X = np.hstack((X, X**2, X**3))\n",
    "X_pred = np.hstack((X_pred, X_pred**2, X_pred**3))\n",
    "\n",
    "# Create the TensorFlow model.\n",
    "n_feats = X.shape[1]\n",
    "n_hidden = 100\n",
    "model_prob = 0.9\n",
    "model_lam = 1e-2\n",
    "model_X = tf.placeholder(tf.float32, [None, n_feats])\n",
    "model_y = tf.placeholder(tf.float32, [None])\n",
    "model_L_1 = VariationalDense(n_feats, n_hidden, model_prob, model_lam)\n",
    "model_L_2 = VariationalDense(n_hidden, n_hidden, model_prob, model_lam)\n",
    "model_L_3 = VariationalDense(n_hidden, 1, model_prob, model_lam)\n",
    "model_out_1 = model_L_1(model_X, tf.nn.relu)\n",
    "model_out_2 = model_L_2(model_out_1, tf.nn.relu)\n",
    "model_pred = model_L_3(model_out_2)\n",
    "model_sse = tf.reduce_sum(tf.square(model_y - model_pred))\n",
    "model_mse = model_sse / n_samples\n",
    "model_loss = (\n",
    "    # Negative log-likelihood.\n",
    "    model_sse +\n",
    "    # Regularization.\n",
    "    model_L_1.regularization +\n",
    "    model_L_2.regularization +\n",
    "    model_L_3.regularization\n",
    ") / n_samples\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(model_loss)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, {model_X: X, model_y: y})\n",
    "        if i % 100 == 0:\n",
    "            mse = sess.run(model_mse, {model_X: X, model_y: y})\n",
    "            print(\"Iteration {}. Mean squared error: {:.4f}.\".format(i, mse))\n",
    "\n",
    "    # Sample from the posterior.\n",
    "    n_post = 1000\n",
    "    Y_post = np.zeros((n_post, X_pred.shape[0]))\n",
    "    for i in range(n_post):\n",
    "        Y_post[i] = sess.run(model_pred, {model_X: X_pred})\n",
    "\n",
    "if True:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_post):\n",
    "        plt.plot(X_pred[:, 0], Y_post[i], \"b-\", alpha=1. / 200)\n",
    "    plt.plot(X[:, 0], y, \"r.\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "data = make_classification(n_samples=1200, n_features=5, n_informative=5, n_redundant=0, n_repeated=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=1.0, \n",
    "                            hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "# df3 = pd.DataFrame(data3[0],columns=['x'+str(i) for i in range(1,5)])\n",
    "# df3['y'] = data3[1]\n",
    "\n",
    "X_pred = data[0][0:200,:].astype('float32')\n",
    "y_pred = data[1][0:200].astype('float32')\n",
    "X, y = data[0][200:1200,:].astype('float32'), data[1][200:1200].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 1).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-114a15d27f81>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = model_pred, \n\u001b[0;32m     61\u001b[0m                                                                \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                                                                name='xentropy')\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[0mtrain_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e-3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36msparse_softmax_cross_entropy_with_logits\u001b[1;34m(_sentinel, labels, logits, name)\u001b[0m\n\u001b[0;32m   2645\u001b[0m       raise ValueError(\"Rank mismatch: Rank of labels (received %s) should \"\n\u001b[0;32m   2646\u001b[0m                        \u001b[1;34m\"equal rank of logits minus 1 (received %s).\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2647\u001b[1;33m                        (labels_static_shape.ndims, logits.get_shape().ndims))\n\u001b[0m\u001b[0;32m   2648\u001b[0m     if (static_shapes_fully_defined and\n\u001b[0;32m   2649\u001b[0m         labels_static_shape != logits.get_shape()[:-1]):\n",
      "\u001b[1;31mValueError\u001b[0m: Rank mismatch: Rank of labels (received 1) should equal rank of logits minus 1 (received 1)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.contrib.distributions import Bernoulli\n",
    "\n",
    "class VariationalDense:\n",
    "    \"\"\"Variational Dense Layer Class\"\"\"\n",
    "    def __init__(self, n_in, n_out, model_prob, model_lam):\n",
    "        self.model_prob = model_prob\n",
    "        self.model_lam = model_lam\n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "        self.model_M = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.01))\n",
    "        self.model_m = tf.Variable(tf.zeros([n_out]))\n",
    "        self.model_W = tf.matmul(\n",
    "            tf.diag(self.model_bern.sample((n_in, ))), self.model_M\n",
    "        )\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        output = activation(tf.matmul(X, self.model_W) + self.model_m)\n",
    "        if self.model_M.shape[1] == 1:\n",
    "            output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def regularization(self):\n",
    "        return self.model_lam * (\n",
    "            self.model_prob * tf.reduce_sum(tf.square(self.model_M)) +\n",
    "            tf.reduce_sum(tf.square(self.model_m))\n",
    "        )\n",
    "\n",
    "# Created sample data.\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "data = make_classification(n_samples=1200, n_features=5, n_informative=5, n_redundant=0, n_repeated=0, \n",
    "                            n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=1.0, \n",
    "                            hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "X_pred = data[0][0:200,:].astype('float32')\n",
    "y_pred = data[1][0:200].astype('float32')\n",
    "X, y = data[0][200:1200,:].astype('float32'), data[1][200:1200].astype('float32')\n",
    "\n",
    "# X_pred = np.atleast_2d(np.linspace(-3., 3., num=100)).T\n",
    "# X_pred = np.hstack((X_pred, X_pred**2, X_pred**3))\n",
    "\n",
    "# Create the TensorFlow model.\n",
    "n_feats = X.shape[1]\n",
    "n_hidden = 100\n",
    "model_prob = 0.9\n",
    "model_lam = 1e-2\n",
    "model_X = tf.placeholder(tf.float32, [None, n_feats])\n",
    "model_y = tf.placeholder(tf.float32, [None])\n",
    "int_labels = tf.to_int64(model_y)\n",
    "# Create variational layers\n",
    "model_L_1 = VariationalDense(n_feats, n_hidden, model_prob, model_lam)\n",
    "model_L_2 = VariationalDense(n_hidden, n_hidden, model_prob, model_lam)\n",
    "model_L_3 = VariationalDense(n_hidden, 1, model_prob, model_lam)\n",
    "# Pass data through variational layers\n",
    "model_out_1 = model_L_1(model_X, tf.nn.relu)\n",
    "model_out_2 = model_L_2(model_out_1, tf.nn.relu)\n",
    "model_pred = model_L_3(model_out_2)\n",
    "model_pred = tf.reshape(model_pred, y.shape)\n",
    "outputs = tf.argmax(model_pred, 1)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = model_pred, \n",
    "                                                               labels = int_labels, \n",
    "                                                               name='xentropy')\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        sess.run(train_step, {model_X: X, model_y: y})\n",
    "        if i % 100 == 0:\n",
    "            mse = sess.run(model_mse, {model_X: X, model_y: y})\n",
    "            print(\"Iteration {}. Cross-entropy: {:.4f}.\".format(i, cross_entropy))\n",
    "\n",
    "    # Sample from the posterior.\n",
    "    n_post = 1000\n",
    "    Y_post = np.zeros((n_post, X_pred.shape[0]))\n",
    "    for i in range(n_post):\n",
    "        Y_post[i] = sess.run(model_pred, {model_X: X_pred})\n",
    "\n",
    "# if True:\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     for i in range(n_post):\n",
    "#         plt.plot(X_pred[:, 0], Y_post[i], \"b-\", alpha=1. / 200)\n",
    "#     plt.plot(X[:, 0], y, \"r.\")\n",
    "#     plt.grid()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BNN for flood prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalDense:\n",
    "    \"\"\"Variational Dense Layer Class\"\"\"\n",
    "    def __init__(self, n_in, n_out, model_prob, model_lam):\n",
    "        self.model_prob = model_prob\n",
    "        self.model_lam = model_lam\n",
    "        self.model_bern = Bernoulli(probs=self.model_prob, dtype=tf.float32)\n",
    "        self.model_M = tf.Variable(tf.truncated_normal([n_in, n_out], stddev=0.01))\n",
    "        self.model_m = tf.Variable(tf.zeros([n_out]))\n",
    "        self.model_W = tf.matmul(\n",
    "            tf.diag(self.model_bern.sample((n_in, ))), self.model_M\n",
    "        )\n",
    "\n",
    "    def __call__(self, X, activation=tf.identity):\n",
    "        output = activation(tf.matmul(X, self.model_W) + self.model_m)\n",
    "        if self.model_M.shape[1] == 1:\n",
    "            output = tf.squeeze(output)\n",
    "        return output\n",
    "\n",
    "    @property\n",
    "    def regularization(self):\n",
    "        return self.model_lam * (\n",
    "            self.model_prob * tf.reduce_sum(tf.square(self.model_M)) +\n",
    "            tf.reduce_sum(tf.square(self.model_m))\n",
    "        )\n",
    "\n",
    "# Create the TensorFlow model.\n",
    "n_feats = X.shape[1]\n",
    "n_hidden = 100\n",
    "model_prob = 0.9\n",
    "model_lam = 1e-2\n",
    "model_X = tf.placeholder(tf.float32, [None, n_feats])\n",
    "model_y = tf.placeholder(tf.float32, [None])\n",
    "model_L_1 = VariationalDense(n_feats, n_hidden, model_prob, model_lam)\n",
    "model_L_2 = VariationalDense(n_hidden, n_hidden, model_prob, model_lam)\n",
    "model_L_3 = VariationalDense(n_hidden, 1, model_prob, model_lam)\n",
    "model_out_1 = model_L_1(model_X, tf.nn.relu)\n",
    "model_out_2 = model_L_2(model_out_1, tf.nn.relu)\n",
    "model_pred = model_L_3(model_out_2)\n",
    "# model_sse = tf.reduce_sum(tf.square(model_y - model_pred))\n",
    "# model_mse = model_sse / n_samples \n",
    "# model_loss = (\n",
    "#     # Negative log-likelihood.\n",
    "#     model_sse +\n",
    "#     # Regularization.\n",
    "#     model_L_1.regularization +\n",
    "#     model_L_2.regularization +\n",
    "#     model_L_3.regularization \n",
    "# ) / n_samples\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = int_labels, name='xentropy')\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10000):\n",
    "        sess.run(train_step, {model_X: X, model_y: y})\n",
    "        if i % 100 == 0:\n",
    "            mse = sess.run(model_mse, {model_X: data_vector[, model_y: y})\n",
    "            print(\"Iteration {}. Mean squared error: {:.4f}.\".format(i, mse))\n",
    "\n",
    "    # Sample from the posterior.\n",
    "    n_post = 1000\n",
    "    Y_post = np.zeros((n_post, X_pred.shape[0]))\n",
    "    for i in range(n_post):\n",
    "        Y_post[i] = sess.run(model_pred, {model_X: X_pred})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
