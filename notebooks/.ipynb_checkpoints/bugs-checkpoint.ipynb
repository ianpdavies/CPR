{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import rasterio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import math\n",
    "from zipfile import *\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tifStacker(path, img, feat_list_new, overwrite=False): \n",
    "\n",
    "    \"\"\" Reorders the tifs (i.e. individual bands) downloaded from GEE according to feature order in feat_list_new, \n",
    "    then stacks them all into one multiband image called 'stack.tif' located in input path. Requires rasterio, \n",
    "    os, from zipfile import *\n",
    "    \n",
    "    Ideally want to have this function in another notebook and call it, but running into problems - ZipFile not found \n",
    "    \n",
    "    from ipynb.fs.full.useful_funcs import tifStacker\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str \n",
    "        Path to image folder\n",
    "    img :str \n",
    "        Name of image file (without file extension)\n",
    "    feat_list_new : list\n",
    "        List of feature names (str) to be the desired order of the output stacked .tif - target feature must be last\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    \"stacked.tif\" in 'path' location \n",
    "    feat_list_files : list \n",
    "        Not sure what that is or what it's for \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    file_list = []\n",
    "    imgPath = path+'images/'+img\n",
    "    \n",
    "    # This gets the name of all files in the zip folder, and formats them into a full path readable by rasterio.open()\n",
    "    with ZipFile(imgPath + '/' + img + '.zip', 'r') as f:\n",
    "        names = f.namelist()\n",
    "        names = ['zip://'+ imgPath + '/' + img + '.zip!' +name for name in names]\n",
    "        for file in names:\n",
    "            if file.endswith('.tif'):\n",
    "                file_list.append(file)\n",
    "    \n",
    "    feat_list_files = list(map(lambda x: x.split('.')[-2], file_list)) # Grabs a list of features in file order        \n",
    "    \n",
    "    if overwrite==False:\n",
    "            if os.path.exists(imgPath + '/stack/stack.tif') == True:\n",
    "                print('\"stack.tif\" already exists for '+ img)\n",
    "                return\n",
    "            else:\n",
    "                print('No existing \"stack.tif\" for '+img+', creating one')\n",
    "        \n",
    "    if overwrite==True:\n",
    "        # Remove stack file if already exists\n",
    "        try:\n",
    "            os.remove(imgPath + '/stack/stack.tif')\n",
    "            print('Removing existing \"stack.tif\" and creating new one')\n",
    "        except FileNotFoundError:\n",
    "            print('No existing \"stack.tif\" for '+img+', creating one')\n",
    "            \n",
    "    # Create 1 row df of file names where each col is a feature name, in the order files are stored locally\n",
    "    file_arr = pd.DataFrame(data=[file_list], columns=feat_list_files)\n",
    "\n",
    "    # Then index the file list by the ordered list of feature names used in training\n",
    "    file_arr = file_arr.loc[:, feat_list_new]\n",
    "\n",
    "    # The take this re-ordered row as a list - the new file_list\n",
    "    file_list = list(file_arr.iloc[0,:])\n",
    "\n",
    "    # Read metadata of first file. This needs to be a band in float32 dtype, because it sets the metadata for the entire stack\n",
    "    # and we are converting the other bands to float64\n",
    "    with rasterio.open(file_list[1]) as src0:\n",
    "        meta = src0.meta\n",
    "        meta['dtype'] = 'float32'\n",
    "    #         print(meta)\n",
    "\n",
    "    # Update meta to reflect the number of layers\n",
    "    meta.update(count = len(file_list))\n",
    "\n",
    "    # Read each layer, convert to float, and write it to stack\n",
    "    # There's also a gdal way to do this, but unsure how to convert to float: https://gis.stackexchange.com/questions/223910/using-rasterio-or-gdal-to-stack-multiple-bands-without-using-subprocess-commands\n",
    "\n",
    "    # Make new directory for stacked tif if it doesn't already exist\n",
    "    try:\n",
    "        os.mkdir(imgPath +'/stack')\n",
    "    except FileExistsError:\n",
    "        print('Stack directory already exists') \n",
    "\n",
    "    with rasterio.open(imgPath + '/stack/stack.tif', 'w', **meta) as dst:\n",
    "        for id, layer in enumerate(file_list, start=0):\n",
    "            with rasterio.open(layer) as src1:\n",
    "                dst.write_band(id+1, src1.read(1).astype('float32'))\n",
    "\n",
    "    return feat_list_files\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "def preprocessing(path, img, pctl):\n",
    "    \"\"\"\n",
    "    Masks stacked image with cloudmask by converting cloudy values to NaN\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str \n",
    "        Path to image folder\n",
    "    img :str \n",
    "        Name of image file (without file extension)\n",
    "    pctl : list of int\n",
    "        List of integers of cloud cover percentages to mask image with (10, 20, 30, etc.)\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    data : array\n",
    "        3D array identical to input stacked image but with cloudy pixels masked\n",
    "    data_ind : list?\n",
    "        List? of indices in 'data' where cloudy pixels were masked. Used for reconstructing the image later \n",
    "    \"\"\"\n",
    "    \n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'clouds'\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds.npy')\n",
    "    cloudMask = cloudMask < np.percentile(cloudMask, pctl)\n",
    "    \n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "        \n",
    "    return data, data_ind\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "def trainVal(data):\n",
    "    \n",
    "    HOLDOUT_FRACTION = 0.1\n",
    "\n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "    data_vector.shape\n",
    "\n",
    "    # Select only the valid data and shuffle it.\n",
    "    # valid_data = data_vector[numpy.equal(data_vector[:,8], 1)]\n",
    "    # np.random.shuffle(data_vector)\n",
    "\n",
    "    # Hold out a fraction of the labeled data for validation.\n",
    "    training_size = int(data_vector.shape[0] * (1 - HOLDOUT_FRACTION))\n",
    "    training_data = data_vector[0:training_size,:]\n",
    "    validation_data = data_vector[training_size:-1,:]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = training_data[:,0:14].mean(0)\n",
    "    data_std = training_data[:,0:14].std(0)\n",
    "    \n",
    "    # Normalize data - only the non-binary variables\n",
    "    data_vector[:,0:14] = (data_vector[:,0:14] - data_mean) / data_std\n",
    "    \n",
    "    return [data_vector, training_data, validation_data, training_size]\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "# CNN layer builder\n",
    "# Function to train CNN on image, save model, and return performance metrics\n",
    "def make_nn_layer(input, output_size):\n",
    "    input_size = input.get_shape().as_list()[1]\n",
    "    weights = tf.Variable(tf.truncated_normal(\n",
    "        [input_size, output_size],\n",
    "        stddev=1.0 / math.sqrt(float(input_size))))\n",
    "    biases = tf.Variable(tf.zeros([output_size]))\n",
    "    return tf.matmul(input, weights) + biases\n",
    "\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "\n",
    "def CNNtrainer(data_vector, training_data, validation_data, model_path, img, pctl):\n",
    "\n",
    "    model_path = path+'models/cnn_vary_clouds/'+img+'/'+img+'_clouds_'+str(pctl)\n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    checkpoint_filename = model_name+'_checkpoint'\n",
    "    \n",
    "    # Make a new directory for the model\n",
    "    try:\n",
    "        os.makedirs(model_path)\n",
    "    except FileExistsError:\n",
    "        print('Model directory already exists')\n",
    "\n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "    # flooded = feat_list_new.index('flooded')\n",
    "    \n",
    "    # ------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    NUM_INPUT_BANDS = 14\n",
    "    NUM_HIDDEN_1 = 15\n",
    "    NUM_HIDDEN_2 = 15\n",
    "    NUM_CLASSES = 2\n",
    "    BATCH_SIZE = 1000\n",
    "    NUM_BATCHES = 1000\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "        \n",
    "    input = tf.placeholder(tf.float32, shape=[None, NUM_INPUT_BANDS], name='input')\n",
    "    labels = tf.placeholder(tf.float32, shape=[None], name='labels')\n",
    "\n",
    "    hidden1 = tf.nn.relu(make_nn_layer(input, NUM_HIDDEN_1), name='hidden1')\n",
    "    hidden2 = tf.nn.relu(make_nn_layer(hidden1, NUM_HIDDEN_2), name='hidden2')\n",
    "    logits = make_nn_layer(hidden2, NUM_CLASSES)\n",
    "    outputs = tf.argmax(logits, 1, name='outputs')\n",
    "\n",
    "    int_labels = tf.to_int64(labels)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, labels = int_labels, name='xentropy')\n",
    "    train_step = tf.train.AdamOptimizer().minimize(cross_entropy) # should we minimize something else?\n",
    "\n",
    "    # Define metrics\n",
    "    acc, acc_update = tf.metrics.accuracy(int_labels, outputs, name='accuracy')\n",
    "    recall, recall_update = tf.metrics.recall(int_labels, outputs, name='recall')\n",
    "    correct_prediction = tf.equal(outputs, int_labels, name='correct_prediction')\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')\n",
    "\n",
    "    # Isolate metric variables\n",
    "    running_vars = tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope='accuracy') + tf.get_collection(tf.GraphKeys.LOCAL_VARIABLES, scope='recall')\n",
    "    \n",
    "    # Define initializer to initialize/reset running variables\n",
    "    running_vars_initializer = tf.variables_initializer(var_list=running_vars)\n",
    "    # ------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    mySaver = tf.train.Saver(save_relative_paths=True)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        \n",
    "        sess.run(init_op, options=run_options)\n",
    "        \n",
    "        # Initialize/reset the running metrics variables\n",
    "        sess.run(running_vars_initializer)\n",
    "        \n",
    "        training_dict = {\n",
    "            input: training_data[:,0:14],\n",
    "            labels: training_data[:,14],\n",
    "        }\n",
    "\n",
    "        validation_dict = {\n",
    "            input: validation_data[:,0:14],\n",
    "            labels: validation_data[:,14],\n",
    "        }\n",
    "\n",
    "        for i in range(NUM_BATCHES):\n",
    "            batch = training_data[np.random.choice(training_size, BATCH_SIZE, False),:]\n",
    "            train_step.run({input: batch[:,0:14], labels: batch[:,14]})\n",
    "\n",
    "            if i % 100 == 0 or i == NUM_BATCHES - 1:\n",
    "                sess.run(acc_update, feed_dict=training_dict)\n",
    "                sess.run(recall_update, feed_dict=training_dict)\n",
    "                acc_score_train = sess.run(acc)\n",
    "                recall_score_train = sess.run(recall)\n",
    "                \n",
    "                sess.run(acc_update, feed_dict=validation_dict)\n",
    "                sess.run(recall_update, feed_dict=validation_dict)\n",
    "                acc_score_val = sess.run(acc)\n",
    "                recall_score_val = sess.run(recall)\n",
    "                \n",
    "                print(\"Acc train: {0:.2f}%, Acc val: {1:.2f}%, Recall train: {2:.2f}%, Recall val: {3:.2f}%, at step {4:d}\".format(acc_score_train * 100,\n",
    "                         acc_score_val * 100,\n",
    "                         recall_score_train * 100,\n",
    "                         recall_score_val * 100,\n",
    "                         i))\n",
    "\n",
    "        output_data = outputs.eval({input: data_vector[:,0:14]})\n",
    "\n",
    "        # Save the model\n",
    "#         mySaver.save(sess, model_path+'/'+model_name+'.ckpt',\n",
    "        mySaver.save(sess, './tftcp.model')\n",
    "#                     latest_filename=checkpoint_filename)\n",
    "\n",
    "    print('CNN training runtime for ' + str(pctl) + '% cloud cover: ' + timer(start_time, time.time()))\n",
    "    \n",
    "    return output_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"stack.tif\" already exists for 4115_LC08_021033_20131227_test\n",
      "Cloud image already exists for 4115_LC08_021033_20131227_test\n"
     ]
    }
   ],
   "source": [
    "%run cloud_generation.ipynb # Gets cloudGenerator function from the other ipynb\n",
    "\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "\n",
    "# Order in which features should be stacked to create stacked tif\n",
    "feat_list_new = ['aspect','curve', 'developed', 'GSW_distExtent', 'elevation', 'forest',\n",
    " 'GSW_maxExtent', 'hand', 'other_landcover', 'planted', 'slope', 'spi', 'twi', 'wetlands', 'flooded']\n",
    "\n",
    "img_list = ['4115_LC08_021033_20131227_test']\n",
    "# img_list= ['4101_LC08_027038_20131103_1']\n",
    "\n",
    "for j, img in enumerate(img_list):\n",
    "    #  Stack all the flood imagery\n",
    "    tifStacker(path, img, feat_list_new, overwrite=False)\n",
    "    cloudGenerator(img, path, overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4101_LC08_027038_20131103_1\n",
      "Model directory already exists\n",
      "Acc train: 31.09%, Acc val: 29.09%, Recall train: 30.47%, Recall val: 30.90%, at step 0\n",
      "Acc train: 61.78%, Acc val: 63.68%, Recall train: 15.52%, Recall val: 15.45%, at step 100\n",
      "Acc train: 74.68%, Acc val: 75.52%, Recall train: 34.58%, Recall val: 34.56%, at step 200\n",
      "Acc train: 80.98%, Acc val: 81.45%, Recall train: 45.36%, Recall val: 45.34%, at step 300\n",
      "Acc train: 84.70%, Acc val: 85.01%, Recall train: 51.64%, Recall val: 51.61%, at step 400\n",
      "Acc train: 87.17%, Acc val: 87.38%, Recall train: 56.20%, Recall val: 56.18%, at step 500\n",
      "Acc train: 88.92%, Acc val: 89.08%, Recall train: 59.40%, Recall val: 59.38%, at step 600\n",
      "Acc train: 90.23%, Acc val: 90.35%, Recall train: 61.78%, Recall val: 61.76%, at step 700\n",
      "Acc train: 91.25%, Acc val: 91.35%, Recall train: 63.69%, Recall val: 63.67%, at step 800\n",
      "Acc train: 92.06%, Acc val: 92.14%, Recall train: 65.09%, Recall val: 65.07%, at step 900\n",
      "Acc train: 92.73%, Acc val: 92.79%, Recall train: 66.54%, Recall val: 66.52%, at step 999\n",
      "CNN training runtime for 10% cloud cover: 00:42:47.81\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-154-e8ac2b7597a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m         \u001b[0mf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mrecall_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m   1365\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1368\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m     \u001b[0mpresent_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'binary'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[1;34m(*ys)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# Check that we don't mix label format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mys_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m# Check that we don't mix label format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0mys_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mys_types\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mys_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'continuous'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;34m'multiclass'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msuffix\u001b[0m  \u001b[1;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    262\u001b[0m     \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_inverse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\arraysetops.py\u001b[0m in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m         \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0maux\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAINING\n",
    "\n",
    "# Cloud cover %s to use\n",
    "# pctls = [10,20,30,40,50,60,70,80,90]\n",
    "pctls = [10, 20]\n",
    "\n",
    "# To put training metric dfs into for plotting afterwards\n",
    "valMetricsList = []\n",
    "\n",
    "import time\n",
    "def timer(start,end, formatted = True):\n",
    "    if formatted == True: # Returns full formated time in hours, minutes, seconds\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    else: # Returns minutes + fraction of minute\n",
    "        minutes, seconds = divmod(time.time() - start_time, 60)\n",
    "        seconds = seconds/60\n",
    "        minutes = minutes + seconds\n",
    "        return str(minutes)\n",
    "\n",
    "for j, img in enumerate(img_list):\n",
    "\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    times = []\n",
    "\n",
    "    # Load stacked image, preprocess\n",
    "    for i, pctl in enumerate(pctls):\n",
    "\n",
    "        data, data_ind = preprocessing(path, img, pctl)\n",
    "\n",
    "        data_vector, training_data, validation_data, training_size = trainVal(data)\n",
    "\n",
    "        start_time = time.time() # Start timer for CNN training\n",
    "\n",
    "        print(img)\n",
    "        \n",
    "        y_pred = CNNtrainer(data_vector, training_data, validation_data, path, img, pctl)\n",
    "\n",
    "        times.append(timer(start_time, time.time(), False)) # Elapsed time in minutes\n",
    "\n",
    "        y_true = data_vector[:,14]\n",
    "\n",
    "        precision.append(sklearn.metrics.precision_score(y_true, y_pred))\n",
    "        recall.append(sklearn.metrics.recall_score(y_true, y_pred))\n",
    "        f1.append(sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        accuracy.append(sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    times = [float(i) for i in times] # Need to convert time objects to float, otherwise valMetrics will be non-numeric\n",
    "\n",
    "    valMetrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, times]),\n",
    "                          columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n",
    "    \n",
    "    valMetrics.to_csv(path+'/models/cnn_vary_clouds/'+img+'/valMetrics.csv', index=False)\n",
    "    \n",
    "    valMetricsList.append(valMetrics)\n",
    "\n",
    "# valMetrics.plot(x='cloud_cover', y=['recall', 'precision','f1','accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_gaps(path, img, pctl):\n",
    "\n",
    "    # Get local image\n",
    "    with rasterio.open(path + 'images/'+ img + '/stack/stack.tif', 'r') as ds:\n",
    "        data = ds.read()\n",
    "        data = data.transpose((1, -1, 0)) # Not sure why the rasterio.read output is originally (D, W, H)\n",
    "    \n",
    "    # load cloudmasks\n",
    "    cloudMaskDir = path+'clouds'\n",
    "    \n",
    "    cloudMask = np.load(cloudMaskDir+'/'+img+'_clouds.npy')\n",
    "    # Note how the sign is >=, not <, we want inverse of training data\n",
    "    cloudMask = cloudMask >= np.percentile(cloudMask, pctl)\n",
    "\n",
    "    # Need to remove NaNs because any arithmetic operation involving an NaN will result in NaN\n",
    "    data[cloudMask] = -999999\n",
    "    \n",
    "    # Convert -999999 to None\n",
    "    data[data == -999999] = np.nan\n",
    "\n",
    "    # Get indices of non-nan values. These are the indices of the original image array\n",
    "    data_ind = np.where(~np.isnan(data[:,:,1]))\n",
    "    \n",
    "    # Reshape into a single vector of pixels.\n",
    "    data_vector = data.reshape([data.shape[0] * data.shape[1], data.shape[2]])\n",
    "\n",
    "    # Remove NaNs\n",
    "    data_vector = data_vector[~np.isnan(data_vector).any(axis=1)]\n",
    "\n",
    "    # Compute per-band means and standard deviations of the input bands.\n",
    "    data_mean = data_vector[:,0:14].mean(0)\n",
    "    data_std = data_vector[:,0:14].std(0)\n",
    "\n",
    "    # Normalize features\n",
    "    data_vector[:,0:14] = (data_vector[:,0:14] - data_mean) / data_std\n",
    "    \n",
    "    return data_vector, data_mean, data_std, data_ind\n",
    "\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "# =============================================================\n",
    "\n",
    "def gapFill(data_vector, data_mean, data_std, img, pctl):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    model_path = path+'models/cnn_vary_clouds/'+img+'/'+img+'_clouds_'+str(pctl)\n",
    "    model_name = img+'_clouds_'+str(pctl)\n",
    "    checkpoint_filename = model_name+'_checkpoint'\n",
    "    \n",
    "    # Had to alter some config and runoptions because kept running into OOM at last step during eval \n",
    "    config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "    config.gpu_options.allow_growth = True\n",
    "    run_options=tf.RunOptions(report_tensor_allocations_upon_oom=True)\n",
    "\n",
    "    \n",
    "    with tf.Session(config=config) as sess:\n",
    "        graph = tf.get_default_graph()\n",
    "        mySaver = tf.train.import_meta_graph(model_path+'/'+model_name+'.ckpt-1000.meta') # Get metadata of saved graph\n",
    "        mySaver.restore(sess, tf.train.latest_checkpoint(checkpoint_dir=model_path+'./')) # Restore checkpoint\n",
    "#         input = graph.get_tensor_by_name(\"input:0\") # Get inputs placeholder\n",
    "        outputs = graph.get_tensor_by_name('outputs:0') # Get outputs\n",
    "        hidden1 = graph.get_tensor_by_name('hidden1:0')\n",
    "        hidden2 = graph.get_tensor_by_name('hidden2:0')\n",
    "        \n",
    "        tf.local_variables_initializer()\n",
    "\n",
    "#         y_pred = outputs.eval({input: data_vector[:,0:14]})\n",
    "        y_pred = sess.run(outputs, feed_dict = {input: data_vector[:,0:14]})\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4115_LC08_021033_20131227_test\n",
      "INFO:tensorflow:Restoring parameters from C:/Users/ipdavies/CPR/data/models/cnn_vary_clouds/4115_LC08_021033_20131227_test/4115_LC08_021033_20131227_test_clouds_50./4115_LC08_021033_20131227_test_clouds_50.ckpt-1000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'normalized' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-14b5ebb3975f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgapFill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_vector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_std\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpctl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Elapsed time in minutes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-101-dfbe66fdfc49>\u001b[0m in \u001b[0;36mgapFill\u001b[1;34m(data_vector, data_mean, data_std, img, pctl)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#         y_pred = outputs.eval({input: data_vector[:,0:14]})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m#         y_pred = sess.run(outputs, feed_dict = {input: data_vector[:,0:14]})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnormalized\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'normalized' is not defined"
     ]
    }
   ],
   "source": [
    "# TESTING\n",
    "\n",
    "path = 'C:/Users/ipdavies/CPR/data/'\n",
    "# pctls = [10,20,30,40,50,60,70,80,90]\n",
    "pctls = [50]\n",
    "\n",
    "import math\n",
    "\n",
    "# img_list = ['4101_LC08_027038_20131103_1']\n",
    "img_list = ['4115_LC08_021033_20131227_test']\n",
    "\n",
    "import time\n",
    "def timer(start,end, formatted = True):\n",
    "    if formatted == True: # Returns full formated time in hours, minutes, seconds\n",
    "        hours, rem = divmod(end-start, 3600)\n",
    "        minutes, seconds = divmod(rem, 60)\n",
    "        return str(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "    else: # Returns minutes + fraction of minute\n",
    "        minutes, seconds = divmod(time.time() - start_time, 60)\n",
    "        seconds = seconds/60\n",
    "        minutes = minutes + seconds\n",
    "        return str(minutes)\n",
    "    \n",
    "for j, img in enumerate(img_list):\n",
    "    \n",
    "    print(img)\n",
    "    \n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    accuracy = []\n",
    "    times = []\n",
    "#     predictions []\n",
    "    gapMetricsList = []\n",
    "    \n",
    "    for i, pctl in enumerate(pctls):\n",
    "\n",
    "        data_vector, data_mean, data_std, data_ind = preprocessing_gaps(path, img, pctl)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        y_pred = gapFill(data_vector, data_mean, data_std, img, pctl)\n",
    "        \n",
    "        times.append(timer(start_time, time.time(), False)) # Elapsed time in minutes\n",
    "        \n",
    "        y_true = data_vector[:,14]\n",
    "\n",
    "        accuracy.append(sklearn.metrics.accuracy_score(y_true, y_pred))\n",
    "        precision.append(sklearn.metrics.precision_score(y_true, y_pred))\n",
    "        recall.append(sklearn.metrics.recall_score(y_true, y_pred))\n",
    "        f1.append(sklearn.metrics.f1_score(y_true, y_pred))\n",
    "        \n",
    "#         predictions.append(y_pred)\n",
    "        \n",
    "    times = [float(i) for i in times] # Need to convert time objects to float, otherwise valMetrics will be non-numeric\n",
    "        \n",
    "    gapMetrics = pd.DataFrame(np.column_stack([pctls, accuracy, precision, recall, f1, times]),\n",
    "                          columns=['cloud_cover','accuracy','precision','recall','f1', 'time'])\n",
    "    \n",
    "    gapMetrics.to_csv(path+'/models/cnn_vary_clouds/'+img+'/gapMetrics.csv', index=False)\n",
    "    \n",
    "    gapMetricsList.append(gapMetrics)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ipdavies\\AppData\\Local\\Continuum\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\matplotlib\\cbook\\deprecation.py:107: MatplotlibDeprecationWarning: Passing one of 'on', 'true', 'off', 'false' as a boolean is deprecated; use an actual boolean (True/False) instead.\n",
      "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "columns = 2\n",
    "    \n",
    "# Create list of axes\n",
    "fig, axes = plt.subplots(nrows = int(len(gapMetricsList) / columns + 1), ncols = columns, \n",
    "                         sharex = True, figsize = (10,5), squeeze = False)\n",
    "\n",
    "axes_list = [item for sublist in axes for item in sublist] \n",
    "\n",
    "for i in range(len(gapMetricsList)):\n",
    "    ax = axes_list.pop(0) # Pop each axis out then put data into it\n",
    "    valMetricsList[i].plot(ax = ax, x='cloud_cover', y=['recall', 'precision','f1','accuracy']) \n",
    "    ax.tick_params(\n",
    "        which='both',\n",
    "        bottom='off',\n",
    "        left='off',\n",
    "        right='off',\n",
    "        top='off'\n",
    "    )\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
